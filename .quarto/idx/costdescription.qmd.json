{"title":"Describing the cost function","markdown":{"yaml":{"title":"Describing the cost function","subtitle":"And its derivatives (gradient, Hessian)","toc":true,"toc-depth":3,"toc-expand":2,"sidebar":"tutorial","aliases":["tutorial.html#costdescription"]},"headingText":"General philosophy ![](images/icon_salute.gif)","containsRefs":false,"markdown":"\n\n\n\nAn optimization problem in Manopt is represented as a `problem` structure.\nThe latter must include a field `problem.M` which contains a structure describing a manifold, as obtained from [a factory](manifolds.qmd).\nOn top of this, the problem structure must include some fields that describe the cost function $f$ to be minimized and, possibly, its derivatives.\nThis is done with function handles.\n\nThe solvers do _not_ query these function handles directly.\nInstead, they call core (internal) tools such as `getCost`, `getGradient`, `getHessian`, etc.\nThese tools consider the available fields in the problem structure and \"do their best\" to return the requested object.\n\nAs a result, we gain great flexibility in the cost function description.\nIndeed, as the needs grow during the life-cycle of the toolbox and new ways of describing the cost function become necessary, it suffices to update the core `get*` tools to take these new ways into account.\nThis has made it much easier over time to incorporate (and improve) caching.\nAlso, if a solver requests an object that is not available, then Manopt can automatically fall back to an approximation. <!-- (e.g., finite differences for Hessians).-->\n\n\n:::{.callout-note}\n## Try to provide the gradient\nIf you do not provide the gradient and a solver queries it, then Manopt falls back to finite differences of the cost function to approximate the Riemannian gradient.\nThis requires building an orthonormal basis for the tangent space (that's expensive) and then querying the cost function value along each basis vector (that's $\\dim \\mathcal{M}$ calls).\nSolvers will still run, but this feature is included only for convenience when prototyping.\n:::\n\n:::{.callout-note}\n## It's fine to omit the Hessian\nIf you do not provide the Hessian and a solver queries it, then Manopt falls back to finite differences of the gradient to approximate the Hessian.\nThis is typically good enough, and often has a computational cost similar to evaluating the true Hessian.\nYou can control this further with [`approxhessianFD`](https://github.com/NicolasBoumal/manopt/blob/master/manopt/solvers/hessianapproximations/approxhessianFD.m).\n:::\n\n:::{.callout-note}\n## Check your derivatives\nRegardless of how you implement the gradient, make sure to check that it is correct by running `checkgradient(problem)` at least once.\nLikewise, check the Hessian with `checkhessian(problem)`.\nSee the [tools](tools.qmd) page for more.\n:::\n\n\n## One example, five ways\n\nSimilarly to the [first example](firstexample.qmd), consider minimizing\n$$\n  f(x) = \\frac{1}{2} x^\\top A x\n$$\nfor $x$ on the unit sphere in $\\mathbb{R}^n$, where $A$ is a symmetric matrix.\nThe base code could look something like this:\n\n```matlab\nn = 1000;\nA = randsym(n);\nproblem.M = spherefactory(n);\n\n% ... define the cost: see below\n\nx = trustregions(problem);\n```\n\nThe cost function can be specified by adding fields to the `problem` structure.\nLet us go through a few different ways to do that.\n\n### The common way: via Euclidean extension\n\nIf we think of $f$ as a function on $\\mathbb{R}^n$ (ignoring the restriction to the sphere), then the gradient and Hessian of $f$ are easily derived:\n$$\n\\begin{align}\n  \\nabla f(x) = Ax, && \\nabla^2 f(x)[u] = Au.\n\\end{align}\n$$\nWe think of this approach as \"extending\" the function from the sphere to the embedding space, which is the Euclidean space $\\mathbb{R}^n$.\nYou can tell Manopt what the gradient and Hessian for that Euclidean extension are using the fields `egrad` and `ehess`, as follows (mind the `e` for Euclidean or embedding):\n\n```matlab\nproblem.cost = @(x) .5*x'*A*x;\nproblem.egrad = @(x) A*x;\nproblem.ehess = @(x, u) A*u; % optional\n```\n\nManopt takes care of converting these to the Riemannian gradient and Hessian of $f$ on the sphere, using `problem.M.egrad2rgrad` and `problem.M.ehess2rhess`: this is automatic.\n\nA few comments:\n\n* It is fine to omit `ehess`, but try not to omit `egrad` (see earlier comments).\n* The computation `A*x` is redundant between `cost` and `egrad`: more on this later.\n* The input to `egrad` is a point $x$. The output is a vector in the _embedding space_, corresponding to $\\nabla f(x)$.\n* The inputs to `ehess` are a point $x$ and a _tangent vector_ $u$ at $x$. The output is a vector in the _embedding space_, corresponding to $\\nabla^2 f(x)[u]$. <!--Make sure to use the corresponding numerical representations.-->\n\nMind the distinction between tangent vectors and vectors in the embedding space.\nFor many manifolds, these are numerically represented in the same way, so the distinction does not matter (e.g., for `spherefactory` and `stiefelfactory`).\nHowever, some manifolds use different numerical representations (e.g., `rotationsfactory`).\nFor those, you may want to call `M.tangent2ambient(x, u)` to obtain the embedding space equivalent of `u`.\nRead the `help` section of your manifold factory to make sure.\n\n### Coding the Riemannian derivatives manually\n\nThere are instances where it is more natural or more efficient to describe the Riemannian derivatives directly (as opposed to the Euclidean extension approach), though this is not common.\n\nOne example where this is preferred is when computing an [intrinsic mean](https://github.com/NicolasBoumal/manopt/blob/master/examples/positive_definite_intrinsic_mean.m).\nThere, the cost function involves the squared Riemannian distance, whose Riemannian gradient is the logarithmic map.\n\nIn our running example, the sphere is a _Riemannian submanifold_ of $\\mathbb{R}^n$.\nTherefore,\n\n* The Riemannian gradient is the orthogonal projection of $\\nabla f(x)$ to the tangent space at $x$ (see Proposition 3.61 in [this book](https://www.nicolasboumal.net/book)). The projector is available in `problem.M.proj`: $$\\grad f(x) = \\Proj_x(\\nabla f(x)).$$\n* The Riemannian Hessian at $x$ along $u$ is the projection of the derivative of the _Riemannian_ gradient at $x$ along $u$ (see Corollary 5.16 in [the same book](https://www.nicolasboumal.net/book)): $$\\Hess f(x)[u] = \\Proj_x(\\D\\grad f(x)[u]).$$\n\nFor the unit sphere, $\\Proj_x(u) = u - (x^\\top u)x$.\nIt is then an exercise to work out the expressions above.\n\n<!--\nso $\\grad f(x) = Ax - (x^\\top Ax)x$ and $\\D\\grad f(x)[u] = Au - (x^\\top Ax)u - (\\textrm{some number}) x$.\n-->\n\nYou can specify the Riemannian gradient and Hessian using the fields `grad` and `hess` (no `e`), as follows:\n\n```matlab\nproblem.cost = @(x) .5*x'*A*x;\nproblem.grad = @(x) problem.M.proj(x, A*x);\nproblem.hess = @(x, u) problem.M.proj(x, A*u - (x'*A*x)*u); % optional\n```\n\nSome comments:\n \n* Again, it is fine to omit `hess`, but try not to omit `grad` (see earlier comments).\n* The input to `grad` is a point $x$. The output is a _tangent vector_ at $x$, corresponding to $\\grad f(x)$.\n* The inputs to `hess` are a point $x$ and a _tangent vector_ $u$ at $x$. The output is a _tangent vector_ at $x$, corresponding to $\\Hess f(x)[u]$.\n\n\n### Using automatic differentiation\n\nAutomatic differentiation (AD) is a means to obtain gradients and Hessians automatically, without the need to derive and implement formulas for them.\nThis is usually slower than (good) hand-written code, but it can drastically reduce coding time, making it great (at least) for prototyping.\n\nManopt 7.0 added support for AD by building on Matlab's [Deep Learning Toolbox](https://ch.mathworks.com/products/deep-learning.html).\nTo use it, simply define the cost and call `manoptAD`:\n\n```matlab\nproblem.cost = @(x) .5*x'*A*x;\nproblem = manoptAD(problem);\n```\n\nIf it works, then the problem structure now includes access to the gradient and Hessian.\nIf it does not work, check the following:\n\n* Do you have the Deep Learning Toolbox? Type `help dlarray`.\n* Is your Matlab version 2019 or later? Type `version`.\n* Is your Manopt version 7.0 or later? Type `manopt_version`.\n* Was there an error message? AD does not work for all functions. Check out:\n  * The list of [dlarray supported functions](https://ch.mathworks.com/help/deeplearning/ug/list-of-functions-with-dlarray-support.html), and\n  * The docs for AD in Manopt, specifically: `help manoptAD` and `help manoptADhelp`.\n* Keep in mind that `dlarray` support also depends on your versions of Matlab and the DL toolbox (e.g., support for AD with complex numbers was added in Matlab R2021b).\n* If a function you need is not supported (e.g., `diag`), see `help manoptADhelp` for a possible replacement (e.g., `cdiag`), or try to replace it with a direct implementation (e.g., `A(1:size(A,1)+1:end).'`).\n\n[Xiaowen Jiang](https://scholar.google.com/citations?user=g_MNvxwAAAAJ&hl=en) implemented `manoptAD` (and the system behind it) during an internship in 2021.\n\n\n### Fewer redundant computations with `costgrad`\n\nComputing the gradient at $x$ often requires going through some of the computations that are also necessary to compute $f(x).$\nIn our example, both $f(x) = \\frac{1}{2}x^\\top Ax$ and $\\grad f(x) = Ax - (x^\\top Ax)x$ require computing $Ax$.\n\nSince solvers tend to query both $f$ and its gradient at the same point $x$, it is beneficial to offer solvers the option to query both at the same time.\nYou can do so with the field `costgrad`, as follows:\n\n```matlab\nproblem.costgrad = @(x) mycostgrad(A, x);\nfunction [f, g] = mycostgrad(A, x)\n    Ax = A*x; % this product is computed only once\n    f = .5*x'*Ax;\n    if nargout == 2 % compute gradient only if requested\n        g = Ax - 2*f*x;\n    end\nend\n```\n\nThe input of `costgrad` is a point $x$.\nThe outputs are the cost and (if requested) the _Riemannian_ gradient at $x$.\nIf you prefer to define the _Euclidean_ gradient (as we often do) but still want to avoid redundant computations, read on.\n\nWe might also want to provide the Riemannian Hessian with\n\n```matlab\nproblem.hess = @(x, u) problem.M.proj(x, A*u - (x'*A*x)*u); % optional\n```\n\nHowever, now we see that the product `A*x` could also be reused there.\nThe next section provides a more sophisticated approach which gives users full control over which computations to cache for reuse.\n\n\n### Using the `store` caching system\n\n<!--As discussed above, it is often the case that computing $f(x)$ produces intermediate results (such as the product $Ax$) that can be reused in order to compute other quantities such as the gradient and Hessian at $x$.-->\nComputing anything at a point $x$ (e.g., $f(x)$) may produce intermediate results that could be reused for other computations at $x$ (e.g., the gradient).\n<!--Furthermore, it may happen that a solver calls cost-related functions more than once at the same point $x$. For those cases, -->\nIt may be beneficial to cache (that is, to store) some of those intermediate calculations.\n\nFor that purpose, within the run of a solver, Manopt manages a database of `store` structures, with a class called [StoreDB](https://github.com/NicolasBoumal/manopt/blob/master/manopt/core/StoreDB.m).\nFor each visited point $x$, a `store` structure is created in that database.\nStoreDB labels the points visited on the manifold with a `key` (an integer).\nThis `key` uniquely identifies $x$: that is how the toolbox links $x$ with its associated `store`.\n<!--With it, we can read and write to the `store` for $x$.-->\nOnly the stores pertaining to the most recently used points are kept in memory. <!--  (see the `options.storedepth` [option](solvers.qmd)). -->\n\nWhenever a solver calls, say, the `cost` function at some point $x$, the toolbox searches for a `store` structure associated to that $x$ in the database (using its `key`).\nIf there is one and if `problem.cost` (for example) admits `store` as an input and as an output, the `store` is passed to the `cost` function.\nThe `cost` function then performs its duty and gets to modify the `store` structure at will.\n\nThe next time a function is called at the _same_ point $x$ (say, `problem.egrad`), the _same_ `store` structure is passed along, possibly modified, and stored again.\n\nAs soon as the solver goes on to explore a _new_ point $x'$, a _different_ `store` structure is created and maintained in the same way.\nIf the solver later decides to return to the previous $x$, we get access to that earlier `store` again (unless it was purged from memory).\n\nFor our running example, the code below shows how we can use the caching system to implement the cost, gradient and Hessian without redundant computations.\nThe principle is this:\n\n* Write a function `prepare` which computes all the things you want to cache at a given point.\n* Have `cost`, `egrad`, `ehess` etc. call `prepare` before they proceed with their own computations.\n\nThe code is given in two versions (use the tabs to switch):\n\n* One version nests the functions `prepare`, `cost`, `egrad` and `ehess` within a top function (with a common scope).\n* One version allows for those functions to be defined in independent scopes.\n\nYou may prefer one or the other depending on your use case.\n\n::: {.panel-tabset}\n\n## As a function with nested functions\n\n```matlab\nfunction x = rayleighmin(A)\n\n    problem.M = spherefactory(size(A, 1));\n\n    problem.cost = @cost;\n    problem.egrad = @egrad;\n    problem.ehess = @ehess; % optional\n\n    x = trustregions(problem);\n\n    % The functions below are nested:\n    % they can see the matrix A from the top scope.\n\n    function store = prepare(x, store)\n        if ~isfield(store, 'Ax')\n            store.Ax = A*x;\n        end\n    end\n    function [f, store] = cost(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        f = .5*x'*Ax;\n    end\n    function [g, store] = egrad(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        g = Ax;\n    end\n    function [h, store] = ehess(x, u, store)\n        % In general we would call prepare()\n        % here too, but for this example the\n        % Hessian is so simple that we don't\n        % need to.\n        % store = prepare(x, store);\n        h = A*u;\n    end\n\nend\n```\n\n## As a script with function handles\n\n```matlab\nclear; clc; clf;\n\nn = 1000;\nA = randsym(n);\nproblem.M = spherefactory(n);\n\nproblem.cost = @(x, store) cost(A, x, store);\nproblem.egrad = @(x, store) egrad(A, x, store);\nproblem.ehess = @(x, u, store) ehess(A, x, u, store); % optional\n\nx = trustregions(problem);\n\n% The functions below appear at the end of the script\n% (they could also be defined in separate files).\n% They do not see A, so they need to receive it as an input.\n% The function handles above are created in a part of the\n% script that can see A.\n\nfunction store = prepare(A, x, store)\n    if ~isfield(store, 'Ax')\n        store.Ax = A*x;\n    end\nend\nfunction [f, store] = cost(A, x, store)\n    store = prepare(A, x, store);\n    Ax = store.Ax;\n    f = .5*x'*Ax;\nend\nfunction [g, store] = egrad(A, x, store)\n    store = prepare(A, x, store);\n    Ax = store.Ax;\n    g = Ax;\nend\nfunction [h, store] = ehess(A, x, u, store)\n    % In general we would call prepare()\n    % here too, but for this example the\n    % Hessian is so simple that we don't\n    % need to.\n    % store = prepare(A, x, store);\n    h = A*u;\nend\n```\n\n:::\n\nIt is instructive to execute such code with [the profiler](https://blogs.mathworks.com/community/2010/02/01/speeding-up-your-program-through-profiling/) activated and to look at how many times each line of code is executed.\nYou should find that the matrix-vector products $Ax$ (computed only in `prepare`) are executed exactly as often as they should be.\nYou can use [Manopt counters](tools.qmd#counters-to-track-computations) to track these products and more.\n\n<!--As of Manopt 5.0, by default, the cost value $f(x)$ is cached at every visited point (for as long as the memory associated to that point is retained.) This means that calling `getCost(problem, x, storedb, key)` multiple times with the same inputs only actually calls the cost function the first time. In practice, this provides good speed-ups for line-search algorithms. Similarly, the gradient and Euclidean gradient are cached by default, which provides speed-ups for a number of solvers. This is made practical by the new store managment system that allows solvers to more quickly discard irrelevant stores, thus minimizing memory usage. THIS WAS MOVED TO A NOTE-->\n\n<!--As of Manopt 1.0.8,-->\nThe store structure also includes a field `store.shared`.\nThe contents of that field are shared among all points the solver visited so far.\n\n:::{.callout-note}\n## Cache reusable computations only\nManopt automatically caches the value and the gradient of $f$ (both Euclidean and Riemannian) at each queried point $x$.\nThere is no need to cache those manually.\nRather, use the `store` to cache the most expensive (and reusable) intermediate computations.\n<!--\nAs of Manopt 5.0, by default, the cost value $f(x)$ is cached at every visited point (for as long as the memory associated to that point is retained.) This means that calling `getCost(problem, x, storedb, key)` multiple times with the same inputs only actually calls the cost function the first time. In practice, this provides good speed-ups for line-search algorithms. Similarly, the gradient and Euclidean gradient are cached by default, which provides speed-ups for a number of solvers. This is made practical by the new store management system that allows solvers to more quickly discard irrelevant stores, thus minimizing memory usage.\n-->\n:::\n\n:::{.callout-note}\n## Caching and the Hessian\nEach `store` is associated to a point $x$.\nThus, calls to `ehess(x, u, store)`and `ehess(x, v, store)` with the same `x` and two different tangent vectors `u`, `v` receive access to the same `store`.\nTherefore, only cache quantities that depend on `x`, not on `u`.\n:::\n\n<!--I removed this note because the `prepare` idiom makes this natural.-->\n<!--You should never assume that the gradient function, for example, will be called after the cost function (even though this is usually the case).\nAlways check that the fields you use in the store structure are populated; and if they are not, call the appropriate functions to make up for it, as in the example above.-->\n\n:::{.callout-note}\n## Lifespan of the cache\nSolvers take care of deleting older information when it is no longer relevant.\nThis should be good enough, but you can also cap the maximum number of `store` structures kept in memory with `options.storedepth`.\n:::\n\n:::{.callout-note}\n## Caching and `statsfun`\nThe `store` structure is readable (but not writable) by [`options.statsfun`](solvers.qmd#statsfun-option-for-recording-info-at-each-iteration).\nThe `store.shared` mechanism was originally used together with `statsfun` to keep track of function calls.\nAs of Manopt 5.0, it is much better to use [Manopt counters](tools.qmd#counters-to-track-computations) for this purpose.\n:::\n\n\n## All the ways to describe the cost\n\nManopt offers many ways to implement $f$, its gradient, its Hessian and more.\nThis is done by adding function handles as fields in the `problem` structure.\nWe list them all below.\n\nYou can mix and match what you include.\nIf you provide more than one way to compute, say, the gradient, then the toolbox may use any and all of them: it makes an educated guess of which may be most efficient in context.\nStill, it is good practice to avoid redundancies.\n\n<!--\nYou may specify as many of the following fields as you wish in the `problem` structure.\nIf you specify some function more than once (for example, if you define `diff` _and_ `grad`, both of which could be used to compute directional derivatives), the toolbox does not specify which is called (hence, it is better not to, or to be really sure about consistency).\nProbably, the toolbox would assume the code for `diff` is more efficient than the code for `grad` when only a directional derivative is needed, but there is no guarantee.\nBottom line: they should be consistent.\n(Use Matlab's `profile` if you want to trace what is called when.)\n-->\n\nEach function can be provided with one of three different calling patterns, as indicated below.\nThe first one is the simplest and is perfectly fine for prototyping.\nThe other calling patterns give explicit access to Manopt's caching system, in two flavors:\n\n* The normal way, with the `store` structure of the point `x` as an input and (possibly after modifications) as an output.\n* The advanced way, with the `storedb` database and the `key` associated to `x`: see the note down below.\n\n\n| Field name (`problem.\"...\"`)  | Description  |\n|-|---|\n| `cost` | $f = f(x)$ <br> `f = cost(x)` <br> `[f, store] = cost(x, store)` <br> `f = cost(x, storedb, key)` |\n| `grad` | $g = \\grad f(x)$ <br> `g = grad(x)` <br> `[g, store] = grad(x, store)` <br> `g = grad(x, storedb, key)` |\n| `costgrad` | Computes both $f = f(x)$ and $g = \\grad f(x)$. <br> `[f, g] = costgrad(x)` <br> `[f, g, store] = costgrad(x, store)` <br> `[f, g] = costgrad(x, storedb, key)` |\n| `egrad` | For submanifolds of a Euclidean space and for quotient spaces with a total space embedded in a Euclidean space, computes $eg = \\nabla f(x)$: the gradient of $f$ \"as if\" it were defined in that Euclidean space. This is passed to `M.egrad2rgrad`and is automatically cached for use with `ehess`. <br> `eg = egrad(x)` <br> `[eg, store] = egrad(x, store)` <br> `eg = egrad(x, storedb, key)` |\n| `partialgrad` | Assume the cost function `problem.cost` is a sum of many terms, as $f(x) = \\sum_{i=1}^{d} f_i(x)$ where $d$ is specified as `problem.ncostterms = d`. For a subset $I$ of $1\\ldots d$, `partialgrad(x, I)` computes the Riemannian gradient of the partial cost function $f_I(x) = \\sum_{i \\in I} f_i(x)$. <br> `pg = partialgrad(x, I)` <br> `[pg, store] = partialgrad(x, I, store)` <br> `pg = partialgrad(x, I, storedb, key)` |\n| `partialegrad` | Same as `partialgrad` but computes the Euclidean partial gradient. This is automatically transformed into a Riemannian partial gradient by Manopt. <br> `peg = partialegrad(x, I)` <br> `[peg, store] = partialegrad(x, I, store)` <br> `peg = partialegrad(x, I, storedb, key)` |\n| `approxgrad` | Approximation for the gradient of the cost at $x$. Solvers asking for the gradient when one is not provided automatically fall back to this approximation. If it is not provided either, a standard finite-difference approximation of the gradient based on the cost is built-in. This is slow because it involves generating an orthonormal basis of the tangent space at $x$ and computing a finite difference of the cost along each basis vector. This is useful almost exclusively for prototyping. Because of the limited accuracy, it may be necessary to increase `options.tolgradnorm` when using this feature. See [/solvers/gradientapproximations](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/gradientapproximations). <br> `g = approxgrad(x)` <br> `[g, store] = approxgrad(x, store)` <br> `g = approxgrad(x, storedb, key)` |\n| `subgrad` | Returns a Riemannian subgradient of the cost function at $x$, with a tolerance `tol` which is a nonnegative real number. If you wish to return the minimal norm subgradient (which may help solvers), see `smallestinconvexhull` on the [tools](tools.qmd) page. <br> `g = subgrad(x, tol)` <br> `[g, store] = subgrad(x, tol, store)` <br> `g = subgrad(x, tol, storedb, key)` |\n| `diff` | $d = \\D f(x)[u]$ defines directional derivatives. If the gradient exists, it can be computed from this too (slowly.) <br> `d = diff(x, u)` <br> `[d, store] = diff(x, u, store)` <br> `d = diff(x, u, storedb, key)` |\n| `hess` | $h = \\Hess f(x)[u]$, where $u$ represents a tangent vector. <br> `h = hess(x, u)` <br> `[h, store] = hess(x, u, store)` <br> `h = hess(x, u, storedb, key)` |\n| `ehess` | For the same settings as with `egrad`, this computes $eh = \\nabla^2 f(x)[u]$: the Hessian of $f$ along $u$ \"as if\" it were defined in the embedding Euclidean space. This is passed to `M.ehess2rhess` and thus requires the Euclidean gradient to be accessible too (`egrad`). Input $u$ is a representation of the tangent vector. You may want to call `M.tangent2ambient(x, u)` to obtain the ambient space equivalent of $u$. The output `eh` should be a vector in the ambient space. <br> `eh = ehess(x, u)` <br> `[eh, store] = ehess(x, u, store)` <br> `eh = ehess(x, u, storedb, key)` |\n| `approxhess` | This can be any mapping from the tangent space at $x$ to itself. Often, one would like for it to be a linear, symmetric operator. Solvers asking for the Hessian when one is not provided automatically fall back to this approximate Hessian. If it is not provided either, a standard finite-difference approximation of the Hessian based on the gradient is built-in. See [/solvers/hessianapproximations](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/hessianapproximations). <br> `h = approxhess(x, u)` <br> `[h, store] = approxhess(x, u, store)` <br> `h = approxhess(x, u, storedb, key)` |\n| `precon` | $v = \\operatorname{Prec}(x)[u]$, where $\\operatorname{Prec}(x)$ is a preconditioner for the Hessian $\\Hess f(x)$, that is, $\\operatorname{Prec}(x)$ is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at $x$. Ideally, it is cheap to compute and such that solving a linear system in $$\\operatorname{Prec}^{1/2}(x) \\circ \\Hess f(x) \\circ \\operatorname{Prec}^{1/2}(x)$$ is easier than without the preconditioner, i.e., it should approximate the inverse of the Hessian. See [/solvers/preconditioners](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/preconditioners). <br> `v = precon(x, u)` <br> `[v, store] = precon(x, u, store)` <br> `v = precon(x, u, storedb, key)` |\n| `sqrtprecon` | $v = \\operatorname{Prec}^{1/2}(x)[u]$, where $\\operatorname{Prec}^{1/2}(x)$ is an (operator) square root of a preconditioner for the Hessian $\\Hess f(x)$, that is, $\\operatorname{Prec}^{1/2}(x)$ is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at $x$, and applying it twice should amount to applying $\\operatorname{Prec}(x)$ once. Solvers typically use `precon` rather than `sqrtprecon`, but some tools (such as `hessianspectrum`) can use `sqrtprecon` to speed up computations. <br> `v = sqrtprecon(x, u)` <br> `[v, store] = sqrtprecon(x, u, store)` <br> `v = sqrtprecon(x, u, storedb, key)` |\n| `linesearch` | Given a point $x$ and a tangent vector $u$ at $x$, assume $u$ is a descent direction. This means there exists $t > 0$ such that $\\phi(t) < \\phi(0)$ with $$\\phi(t) = f(\\Retr_x(td)).$$ Line-search algorithms, which are used by some solvers such as `steepestdescent` and `conjugategradient` are designed to (approximately) minimize $\\phi$ at each iteration. There are built-in, generic ways of doing this. If you have additional structure in your problem that enables you to take a good guess at what $t$ should be, then you can specify it here, in this function handle. This (very much optional) function should return a positive $t > 0$ such that $t$ is a good guess of where to look for a minimizer of $\\phi$. The line-search algorithm (if it decides to use this information) starts by looking at the step $td$, and decides to accept it or not based on its internal rules. See the `linesearch` option on the [solvers](solvers.qmd) page for details on available line-search algorithms and how to pick one. See [`low_rank_matrix_completion`](https://github.com/NicolasBoumal/manopt/blob/master/examples/low_rank_matrix_completion.m) for an example from the literature. <br> `t = linesearch(x, u)` <br> `[t, store] = linesearch(x, u, store)` <br> `t = linesearch(x, u, storedb, key)` | \n\n: Table of all the ways one can describe the cost function in Manopt, including its derivatives, approximations, preconditioners and a line-search hint. {.striped}\n\n:::{.callout-note}\n## StoreDB and `key`, for solver developers and advanced users\nWhen given access to `storedb` and a `key` associated to $x$ rather than to a specific store, the store of $x$ can be obtained as `store = storedb.getStore(key)`.\nPut the modified `store` back into the database with `storedb.set(store, key)`.\n\nAccess the shared memory directly as `storedb.shared`, _not_ via `store.shared`.\nThis is important: `store` might have a `store.shared` field, but when `storedb` and `key` are explicitly used, `store.shared` will not be populated or read on get/set.\n\nEach point $x$ should be associated to a `key`, which is obtained by calling `storedb.getNewKey()`.\nFrom time to time, call `storedb.purge()` to reduce memory usage.\nEven better, as soon as you know that the `store` associated to a certain point is no longer useful, call `storedb.remove(key)` or `storedb.removefirstifdifferent(key1, key2)`.\n\nStoreDB is a [handle class](https://ch.mathworks.com/help/matlab/matlab_oop/comparing-handle-and-value-classes.html): its instances are passed by reference.\nThis means that when a `storedb` object is passed as input to a function, and that function modifies the `storedb` object, the calling function sees the changes too (without the need to explicitly return the `storedb` object).\nThus, each `storedb` object exists only once in memory.\nThis makes for cleaner calling patterns and avoids unnecessary copies.\nThis is not the case for the `store` structures though, which are passed by copy and thus must be returned if the changes are to be permanent.\n:::\n\n\n\n<!-- TODO: remove this whole section?\n## Generic Hessian approximations and preconditioners\n\n_This is from the old documentation._\n\nIf the Hessian is complicated or costly to compute, it may be advantageous to resort to an approximation for it.\nLikewise, if the Hessian is poorly conditioned, it may be advantageous to provide a preconditioner for it (a cheap, approximate and positive definite inverse of the Hessian).\nManopt allows for the definition of generic Hessian approximations and generic preconditioners.\nCheck out these folders if you are interested:\n\n*   [/solvers/hessianapproximations](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/hessianapproximations).\n*   [/solvers/preconditioners](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/preconditioners).\n\nIn any case, the `trustregions` solver by default works with a finite-difference approximation of the Hessian based on the gradient which has proven effective and robust over the years.\nSee [this paper](https://link.springer.com/chapter/10.1007/978-3-319-25040-3_50#) for a proof of global convergence with this approximation.\nThis finite difference approximation is also covered by the analysis in [that paper](https://academic.oup.com/imajna/advance-article/doi/10.1093/imanum/drx080/4836777).\n-->\n\n\n## Accessing the cost, gradient and Hessian\n\nGiven a `problem` structure with a manifold `problem.M` and some description of the cost function $f$, Manopt provides access to $f$ and its derivatives with the tools `getCost`, `getGradient` and `getHessian`.\nHere is an example:\n\n```matlab\nA = randsym(10);\nproblem.M = spherefactory(10);\nproblem.cost = @(x) .5*x'*A*x;\nproblem = manoptAD(problem);\n\n% For illustration, pick a random point on M\nx = problem.M.rand();\n% Compute f(x)\nf = getCost(problem, x);\n% Compute grad f(x) (Riemannian)\ng = getGradient(problem, x);\n% The Riemannian norm of the gradient is:\nproblem.M.norm(x, g)\n\n% Pick a random tangent vector at x\nu = problem.M.randvec(x);\n% Compute Hess f(x)[u] (Riemannian)\nHu = getHessian(problem, x, u);\n% The Hessian quadratic form <u, Hess f(x)[u]>_x is:\nproblem.M.inner(x, u, Hu)\n```\n\nThere are more functions of this type: see the [core tools](core.qmd) page.\n\nAll of these tools also accept calls with `store` and `(storedb, key)` (from the caching system described above).\nThis is mostly useful inside the code for a solver.\n\nTo compute the eigenvalues of the Hessian, check out the tools `hessianspectrum`, `hessianextreme` and `hessianmatrix` on the [tools](tools.qmd) page.\n\n","srcMarkdownNoYaml":"\n\n\n## General philosophy ![](images/icon_salute.gif)\n\nAn optimization problem in Manopt is represented as a `problem` structure.\nThe latter must include a field `problem.M` which contains a structure describing a manifold, as obtained from [a factory](manifolds.qmd).\nOn top of this, the problem structure must include some fields that describe the cost function $f$ to be minimized and, possibly, its derivatives.\nThis is done with function handles.\n\nThe solvers do _not_ query these function handles directly.\nInstead, they call core (internal) tools such as `getCost`, `getGradient`, `getHessian`, etc.\nThese tools consider the available fields in the problem structure and \"do their best\" to return the requested object.\n\nAs a result, we gain great flexibility in the cost function description.\nIndeed, as the needs grow during the life-cycle of the toolbox and new ways of describing the cost function become necessary, it suffices to update the core `get*` tools to take these new ways into account.\nThis has made it much easier over time to incorporate (and improve) caching.\nAlso, if a solver requests an object that is not available, then Manopt can automatically fall back to an approximation. <!-- (e.g., finite differences for Hessians).-->\n\n\n:::{.callout-note}\n## Try to provide the gradient\nIf you do not provide the gradient and a solver queries it, then Manopt falls back to finite differences of the cost function to approximate the Riemannian gradient.\nThis requires building an orthonormal basis for the tangent space (that's expensive) and then querying the cost function value along each basis vector (that's $\\dim \\mathcal{M}$ calls).\nSolvers will still run, but this feature is included only for convenience when prototyping.\n:::\n\n:::{.callout-note}\n## It's fine to omit the Hessian\nIf you do not provide the Hessian and a solver queries it, then Manopt falls back to finite differences of the gradient to approximate the Hessian.\nThis is typically good enough, and often has a computational cost similar to evaluating the true Hessian.\nYou can control this further with [`approxhessianFD`](https://github.com/NicolasBoumal/manopt/blob/master/manopt/solvers/hessianapproximations/approxhessianFD.m).\n:::\n\n:::{.callout-note}\n## Check your derivatives\nRegardless of how you implement the gradient, make sure to check that it is correct by running `checkgradient(problem)` at least once.\nLikewise, check the Hessian with `checkhessian(problem)`.\nSee the [tools](tools.qmd) page for more.\n:::\n\n\n## One example, five ways\n\nSimilarly to the [first example](firstexample.qmd), consider minimizing\n$$\n  f(x) = \\frac{1}{2} x^\\top A x\n$$\nfor $x$ on the unit sphere in $\\mathbb{R}^n$, where $A$ is a symmetric matrix.\nThe base code could look something like this:\n\n```matlab\nn = 1000;\nA = randsym(n);\nproblem.M = spherefactory(n);\n\n% ... define the cost: see below\n\nx = trustregions(problem);\n```\n\nThe cost function can be specified by adding fields to the `problem` structure.\nLet us go through a few different ways to do that.\n\n### The common way: via Euclidean extension\n\nIf we think of $f$ as a function on $\\mathbb{R}^n$ (ignoring the restriction to the sphere), then the gradient and Hessian of $f$ are easily derived:\n$$\n\\begin{align}\n  \\nabla f(x) = Ax, && \\nabla^2 f(x)[u] = Au.\n\\end{align}\n$$\nWe think of this approach as \"extending\" the function from the sphere to the embedding space, which is the Euclidean space $\\mathbb{R}^n$.\nYou can tell Manopt what the gradient and Hessian for that Euclidean extension are using the fields `egrad` and `ehess`, as follows (mind the `e` for Euclidean or embedding):\n\n```matlab\nproblem.cost = @(x) .5*x'*A*x;\nproblem.egrad = @(x) A*x;\nproblem.ehess = @(x, u) A*u; % optional\n```\n\nManopt takes care of converting these to the Riemannian gradient and Hessian of $f$ on the sphere, using `problem.M.egrad2rgrad` and `problem.M.ehess2rhess`: this is automatic.\n\nA few comments:\n\n* It is fine to omit `ehess`, but try not to omit `egrad` (see earlier comments).\n* The computation `A*x` is redundant between `cost` and `egrad`: more on this later.\n* The input to `egrad` is a point $x$. The output is a vector in the _embedding space_, corresponding to $\\nabla f(x)$.\n* The inputs to `ehess` are a point $x$ and a _tangent vector_ $u$ at $x$. The output is a vector in the _embedding space_, corresponding to $\\nabla^2 f(x)[u]$. <!--Make sure to use the corresponding numerical representations.-->\n\nMind the distinction between tangent vectors and vectors in the embedding space.\nFor many manifolds, these are numerically represented in the same way, so the distinction does not matter (e.g., for `spherefactory` and `stiefelfactory`).\nHowever, some manifolds use different numerical representations (e.g., `rotationsfactory`).\nFor those, you may want to call `M.tangent2ambient(x, u)` to obtain the embedding space equivalent of `u`.\nRead the `help` section of your manifold factory to make sure.\n\n### Coding the Riemannian derivatives manually\n\nThere are instances where it is more natural or more efficient to describe the Riemannian derivatives directly (as opposed to the Euclidean extension approach), though this is not common.\n\nOne example where this is preferred is when computing an [intrinsic mean](https://github.com/NicolasBoumal/manopt/blob/master/examples/positive_definite_intrinsic_mean.m).\nThere, the cost function involves the squared Riemannian distance, whose Riemannian gradient is the logarithmic map.\n\nIn our running example, the sphere is a _Riemannian submanifold_ of $\\mathbb{R}^n$.\nTherefore,\n\n* The Riemannian gradient is the orthogonal projection of $\\nabla f(x)$ to the tangent space at $x$ (see Proposition 3.61 in [this book](https://www.nicolasboumal.net/book)). The projector is available in `problem.M.proj`: $$\\grad f(x) = \\Proj_x(\\nabla f(x)).$$\n* The Riemannian Hessian at $x$ along $u$ is the projection of the derivative of the _Riemannian_ gradient at $x$ along $u$ (see Corollary 5.16 in [the same book](https://www.nicolasboumal.net/book)): $$\\Hess f(x)[u] = \\Proj_x(\\D\\grad f(x)[u]).$$\n\nFor the unit sphere, $\\Proj_x(u) = u - (x^\\top u)x$.\nIt is then an exercise to work out the expressions above.\n\n<!--\nso $\\grad f(x) = Ax - (x^\\top Ax)x$ and $\\D\\grad f(x)[u] = Au - (x^\\top Ax)u - (\\textrm{some number}) x$.\n-->\n\nYou can specify the Riemannian gradient and Hessian using the fields `grad` and `hess` (no `e`), as follows:\n\n```matlab\nproblem.cost = @(x) .5*x'*A*x;\nproblem.grad = @(x) problem.M.proj(x, A*x);\nproblem.hess = @(x, u) problem.M.proj(x, A*u - (x'*A*x)*u); % optional\n```\n\nSome comments:\n \n* Again, it is fine to omit `hess`, but try not to omit `grad` (see earlier comments).\n* The input to `grad` is a point $x$. The output is a _tangent vector_ at $x$, corresponding to $\\grad f(x)$.\n* The inputs to `hess` are a point $x$ and a _tangent vector_ $u$ at $x$. The output is a _tangent vector_ at $x$, corresponding to $\\Hess f(x)[u]$.\n\n\n### Using automatic differentiation\n\nAutomatic differentiation (AD) is a means to obtain gradients and Hessians automatically, without the need to derive and implement formulas for them.\nThis is usually slower than (good) hand-written code, but it can drastically reduce coding time, making it great (at least) for prototyping.\n\nManopt 7.0 added support for AD by building on Matlab's [Deep Learning Toolbox](https://ch.mathworks.com/products/deep-learning.html).\nTo use it, simply define the cost and call `manoptAD`:\n\n```matlab\nproblem.cost = @(x) .5*x'*A*x;\nproblem = manoptAD(problem);\n```\n\nIf it works, then the problem structure now includes access to the gradient and Hessian.\nIf it does not work, check the following:\n\n* Do you have the Deep Learning Toolbox? Type `help dlarray`.\n* Is your Matlab version 2019 or later? Type `version`.\n* Is your Manopt version 7.0 or later? Type `manopt_version`.\n* Was there an error message? AD does not work for all functions. Check out:\n  * The list of [dlarray supported functions](https://ch.mathworks.com/help/deeplearning/ug/list-of-functions-with-dlarray-support.html), and\n  * The docs for AD in Manopt, specifically: `help manoptAD` and `help manoptADhelp`.\n* Keep in mind that `dlarray` support also depends on your versions of Matlab and the DL toolbox (e.g., support for AD with complex numbers was added in Matlab R2021b).\n* If a function you need is not supported (e.g., `diag`), see `help manoptADhelp` for a possible replacement (e.g., `cdiag`), or try to replace it with a direct implementation (e.g., `A(1:size(A,1)+1:end).'`).\n\n[Xiaowen Jiang](https://scholar.google.com/citations?user=g_MNvxwAAAAJ&hl=en) implemented `manoptAD` (and the system behind it) during an internship in 2021.\n\n\n### Fewer redundant computations with `costgrad`\n\nComputing the gradient at $x$ often requires going through some of the computations that are also necessary to compute $f(x).$\nIn our example, both $f(x) = \\frac{1}{2}x^\\top Ax$ and $\\grad f(x) = Ax - (x^\\top Ax)x$ require computing $Ax$.\n\nSince solvers tend to query both $f$ and its gradient at the same point $x$, it is beneficial to offer solvers the option to query both at the same time.\nYou can do so with the field `costgrad`, as follows:\n\n```matlab\nproblem.costgrad = @(x) mycostgrad(A, x);\nfunction [f, g] = mycostgrad(A, x)\n    Ax = A*x; % this product is computed only once\n    f = .5*x'*Ax;\n    if nargout == 2 % compute gradient only if requested\n        g = Ax - 2*f*x;\n    end\nend\n```\n\nThe input of `costgrad` is a point $x$.\nThe outputs are the cost and (if requested) the _Riemannian_ gradient at $x$.\nIf you prefer to define the _Euclidean_ gradient (as we often do) but still want to avoid redundant computations, read on.\n\nWe might also want to provide the Riemannian Hessian with\n\n```matlab\nproblem.hess = @(x, u) problem.M.proj(x, A*u - (x'*A*x)*u); % optional\n```\n\nHowever, now we see that the product `A*x` could also be reused there.\nThe next section provides a more sophisticated approach which gives users full control over which computations to cache for reuse.\n\n\n### Using the `store` caching system\n\n<!--As discussed above, it is often the case that computing $f(x)$ produces intermediate results (such as the product $Ax$) that can be reused in order to compute other quantities such as the gradient and Hessian at $x$.-->\nComputing anything at a point $x$ (e.g., $f(x)$) may produce intermediate results that could be reused for other computations at $x$ (e.g., the gradient).\n<!--Furthermore, it may happen that a solver calls cost-related functions more than once at the same point $x$. For those cases, -->\nIt may be beneficial to cache (that is, to store) some of those intermediate calculations.\n\nFor that purpose, within the run of a solver, Manopt manages a database of `store` structures, with a class called [StoreDB](https://github.com/NicolasBoumal/manopt/blob/master/manopt/core/StoreDB.m).\nFor each visited point $x$, a `store` structure is created in that database.\nStoreDB labels the points visited on the manifold with a `key` (an integer).\nThis `key` uniquely identifies $x$: that is how the toolbox links $x$ with its associated `store`.\n<!--With it, we can read and write to the `store` for $x$.-->\nOnly the stores pertaining to the most recently used points are kept in memory. <!--  (see the `options.storedepth` [option](solvers.qmd)). -->\n\nWhenever a solver calls, say, the `cost` function at some point $x$, the toolbox searches for a `store` structure associated to that $x$ in the database (using its `key`).\nIf there is one and if `problem.cost` (for example) admits `store` as an input and as an output, the `store` is passed to the `cost` function.\nThe `cost` function then performs its duty and gets to modify the `store` structure at will.\n\nThe next time a function is called at the _same_ point $x$ (say, `problem.egrad`), the _same_ `store` structure is passed along, possibly modified, and stored again.\n\nAs soon as the solver goes on to explore a _new_ point $x'$, a _different_ `store` structure is created and maintained in the same way.\nIf the solver later decides to return to the previous $x$, we get access to that earlier `store` again (unless it was purged from memory).\n\nFor our running example, the code below shows how we can use the caching system to implement the cost, gradient and Hessian without redundant computations.\nThe principle is this:\n\n* Write a function `prepare` which computes all the things you want to cache at a given point.\n* Have `cost`, `egrad`, `ehess` etc. call `prepare` before they proceed with their own computations.\n\nThe code is given in two versions (use the tabs to switch):\n\n* One version nests the functions `prepare`, `cost`, `egrad` and `ehess` within a top function (with a common scope).\n* One version allows for those functions to be defined in independent scopes.\n\nYou may prefer one or the other depending on your use case.\n\n::: {.panel-tabset}\n\n## As a function with nested functions\n\n```matlab\nfunction x = rayleighmin(A)\n\n    problem.M = spherefactory(size(A, 1));\n\n    problem.cost = @cost;\n    problem.egrad = @egrad;\n    problem.ehess = @ehess; % optional\n\n    x = trustregions(problem);\n\n    % The functions below are nested:\n    % they can see the matrix A from the top scope.\n\n    function store = prepare(x, store)\n        if ~isfield(store, 'Ax')\n            store.Ax = A*x;\n        end\n    end\n    function [f, store] = cost(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        f = .5*x'*Ax;\n    end\n    function [g, store] = egrad(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        g = Ax;\n    end\n    function [h, store] = ehess(x, u, store)\n        % In general we would call prepare()\n        % here too, but for this example the\n        % Hessian is so simple that we don't\n        % need to.\n        % store = prepare(x, store);\n        h = A*u;\n    end\n\nend\n```\n\n## As a script with function handles\n\n```matlab\nclear; clc; clf;\n\nn = 1000;\nA = randsym(n);\nproblem.M = spherefactory(n);\n\nproblem.cost = @(x, store) cost(A, x, store);\nproblem.egrad = @(x, store) egrad(A, x, store);\nproblem.ehess = @(x, u, store) ehess(A, x, u, store); % optional\n\nx = trustregions(problem);\n\n% The functions below appear at the end of the script\n% (they could also be defined in separate files).\n% They do not see A, so they need to receive it as an input.\n% The function handles above are created in a part of the\n% script that can see A.\n\nfunction store = prepare(A, x, store)\n    if ~isfield(store, 'Ax')\n        store.Ax = A*x;\n    end\nend\nfunction [f, store] = cost(A, x, store)\n    store = prepare(A, x, store);\n    Ax = store.Ax;\n    f = .5*x'*Ax;\nend\nfunction [g, store] = egrad(A, x, store)\n    store = prepare(A, x, store);\n    Ax = store.Ax;\n    g = Ax;\nend\nfunction [h, store] = ehess(A, x, u, store)\n    % In general we would call prepare()\n    % here too, but for this example the\n    % Hessian is so simple that we don't\n    % need to.\n    % store = prepare(A, x, store);\n    h = A*u;\nend\n```\n\n:::\n\nIt is instructive to execute such code with [the profiler](https://blogs.mathworks.com/community/2010/02/01/speeding-up-your-program-through-profiling/) activated and to look at how many times each line of code is executed.\nYou should find that the matrix-vector products $Ax$ (computed only in `prepare`) are executed exactly as often as they should be.\nYou can use [Manopt counters](tools.qmd#counters-to-track-computations) to track these products and more.\n\n<!--As of Manopt 5.0, by default, the cost value $f(x)$ is cached at every visited point (for as long as the memory associated to that point is retained.) This means that calling `getCost(problem, x, storedb, key)` multiple times with the same inputs only actually calls the cost function the first time. In practice, this provides good speed-ups for line-search algorithms. Similarly, the gradient and Euclidean gradient are cached by default, which provides speed-ups for a number of solvers. This is made practical by the new store managment system that allows solvers to more quickly discard irrelevant stores, thus minimizing memory usage. THIS WAS MOVED TO A NOTE-->\n\n<!--As of Manopt 1.0.8,-->\nThe store structure also includes a field `store.shared`.\nThe contents of that field are shared among all points the solver visited so far.\n\n:::{.callout-note}\n## Cache reusable computations only\nManopt automatically caches the value and the gradient of $f$ (both Euclidean and Riemannian) at each queried point $x$.\nThere is no need to cache those manually.\nRather, use the `store` to cache the most expensive (and reusable) intermediate computations.\n<!--\nAs of Manopt 5.0, by default, the cost value $f(x)$ is cached at every visited point (for as long as the memory associated to that point is retained.) This means that calling `getCost(problem, x, storedb, key)` multiple times with the same inputs only actually calls the cost function the first time. In practice, this provides good speed-ups for line-search algorithms. Similarly, the gradient and Euclidean gradient are cached by default, which provides speed-ups for a number of solvers. This is made practical by the new store management system that allows solvers to more quickly discard irrelevant stores, thus minimizing memory usage.\n-->\n:::\n\n:::{.callout-note}\n## Caching and the Hessian\nEach `store` is associated to a point $x$.\nThus, calls to `ehess(x, u, store)`and `ehess(x, v, store)` with the same `x` and two different tangent vectors `u`, `v` receive access to the same `store`.\nTherefore, only cache quantities that depend on `x`, not on `u`.\n:::\n\n<!--I removed this note because the `prepare` idiom makes this natural.-->\n<!--You should never assume that the gradient function, for example, will be called after the cost function (even though this is usually the case).\nAlways check that the fields you use in the store structure are populated; and if they are not, call the appropriate functions to make up for it, as in the example above.-->\n\n:::{.callout-note}\n## Lifespan of the cache\nSolvers take care of deleting older information when it is no longer relevant.\nThis should be good enough, but you can also cap the maximum number of `store` structures kept in memory with `options.storedepth`.\n:::\n\n:::{.callout-note}\n## Caching and `statsfun`\nThe `store` structure is readable (but not writable) by [`options.statsfun`](solvers.qmd#statsfun-option-for-recording-info-at-each-iteration).\nThe `store.shared` mechanism was originally used together with `statsfun` to keep track of function calls.\nAs of Manopt 5.0, it is much better to use [Manopt counters](tools.qmd#counters-to-track-computations) for this purpose.\n:::\n\n\n## All the ways to describe the cost\n\nManopt offers many ways to implement $f$, its gradient, its Hessian and more.\nThis is done by adding function handles as fields in the `problem` structure.\nWe list them all below.\n\nYou can mix and match what you include.\nIf you provide more than one way to compute, say, the gradient, then the toolbox may use any and all of them: it makes an educated guess of which may be most efficient in context.\nStill, it is good practice to avoid redundancies.\n\n<!--\nYou may specify as many of the following fields as you wish in the `problem` structure.\nIf you specify some function more than once (for example, if you define `diff` _and_ `grad`, both of which could be used to compute directional derivatives), the toolbox does not specify which is called (hence, it is better not to, or to be really sure about consistency).\nProbably, the toolbox would assume the code for `diff` is more efficient than the code for `grad` when only a directional derivative is needed, but there is no guarantee.\nBottom line: they should be consistent.\n(Use Matlab's `profile` if you want to trace what is called when.)\n-->\n\nEach function can be provided with one of three different calling patterns, as indicated below.\nThe first one is the simplest and is perfectly fine for prototyping.\nThe other calling patterns give explicit access to Manopt's caching system, in two flavors:\n\n* The normal way, with the `store` structure of the point `x` as an input and (possibly after modifications) as an output.\n* The advanced way, with the `storedb` database and the `key` associated to `x`: see the note down below.\n\n\n| Field name (`problem.\"...\"`)  | Description  |\n|-|---|\n| `cost` | $f = f(x)$ <br> `f = cost(x)` <br> `[f, store] = cost(x, store)` <br> `f = cost(x, storedb, key)` |\n| `grad` | $g = \\grad f(x)$ <br> `g = grad(x)` <br> `[g, store] = grad(x, store)` <br> `g = grad(x, storedb, key)` |\n| `costgrad` | Computes both $f = f(x)$ and $g = \\grad f(x)$. <br> `[f, g] = costgrad(x)` <br> `[f, g, store] = costgrad(x, store)` <br> `[f, g] = costgrad(x, storedb, key)` |\n| `egrad` | For submanifolds of a Euclidean space and for quotient spaces with a total space embedded in a Euclidean space, computes $eg = \\nabla f(x)$: the gradient of $f$ \"as if\" it were defined in that Euclidean space. This is passed to `M.egrad2rgrad`and is automatically cached for use with `ehess`. <br> `eg = egrad(x)` <br> `[eg, store] = egrad(x, store)` <br> `eg = egrad(x, storedb, key)` |\n| `partialgrad` | Assume the cost function `problem.cost` is a sum of many terms, as $f(x) = \\sum_{i=1}^{d} f_i(x)$ where $d$ is specified as `problem.ncostterms = d`. For a subset $I$ of $1\\ldots d$, `partialgrad(x, I)` computes the Riemannian gradient of the partial cost function $f_I(x) = \\sum_{i \\in I} f_i(x)$. <br> `pg = partialgrad(x, I)` <br> `[pg, store] = partialgrad(x, I, store)` <br> `pg = partialgrad(x, I, storedb, key)` |\n| `partialegrad` | Same as `partialgrad` but computes the Euclidean partial gradient. This is automatically transformed into a Riemannian partial gradient by Manopt. <br> `peg = partialegrad(x, I)` <br> `[peg, store] = partialegrad(x, I, store)` <br> `peg = partialegrad(x, I, storedb, key)` |\n| `approxgrad` | Approximation for the gradient of the cost at $x$. Solvers asking for the gradient when one is not provided automatically fall back to this approximation. If it is not provided either, a standard finite-difference approximation of the gradient based on the cost is built-in. This is slow because it involves generating an orthonormal basis of the tangent space at $x$ and computing a finite difference of the cost along each basis vector. This is useful almost exclusively for prototyping. Because of the limited accuracy, it may be necessary to increase `options.tolgradnorm` when using this feature. See [/solvers/gradientapproximations](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/gradientapproximations). <br> `g = approxgrad(x)` <br> `[g, store] = approxgrad(x, store)` <br> `g = approxgrad(x, storedb, key)` |\n| `subgrad` | Returns a Riemannian subgradient of the cost function at $x$, with a tolerance `tol` which is a nonnegative real number. If you wish to return the minimal norm subgradient (which may help solvers), see `smallestinconvexhull` on the [tools](tools.qmd) page. <br> `g = subgrad(x, tol)` <br> `[g, store] = subgrad(x, tol, store)` <br> `g = subgrad(x, tol, storedb, key)` |\n| `diff` | $d = \\D f(x)[u]$ defines directional derivatives. If the gradient exists, it can be computed from this too (slowly.) <br> `d = diff(x, u)` <br> `[d, store] = diff(x, u, store)` <br> `d = diff(x, u, storedb, key)` |\n| `hess` | $h = \\Hess f(x)[u]$, where $u$ represents a tangent vector. <br> `h = hess(x, u)` <br> `[h, store] = hess(x, u, store)` <br> `h = hess(x, u, storedb, key)` |\n| `ehess` | For the same settings as with `egrad`, this computes $eh = \\nabla^2 f(x)[u]$: the Hessian of $f$ along $u$ \"as if\" it were defined in the embedding Euclidean space. This is passed to `M.ehess2rhess` and thus requires the Euclidean gradient to be accessible too (`egrad`). Input $u$ is a representation of the tangent vector. You may want to call `M.tangent2ambient(x, u)` to obtain the ambient space equivalent of $u$. The output `eh` should be a vector in the ambient space. <br> `eh = ehess(x, u)` <br> `[eh, store] = ehess(x, u, store)` <br> `eh = ehess(x, u, storedb, key)` |\n| `approxhess` | This can be any mapping from the tangent space at $x$ to itself. Often, one would like for it to be a linear, symmetric operator. Solvers asking for the Hessian when one is not provided automatically fall back to this approximate Hessian. If it is not provided either, a standard finite-difference approximation of the Hessian based on the gradient is built-in. See [/solvers/hessianapproximations](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/hessianapproximations). <br> `h = approxhess(x, u)` <br> `[h, store] = approxhess(x, u, store)` <br> `h = approxhess(x, u, storedb, key)` |\n| `precon` | $v = \\operatorname{Prec}(x)[u]$, where $\\operatorname{Prec}(x)$ is a preconditioner for the Hessian $\\Hess f(x)$, that is, $\\operatorname{Prec}(x)$ is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at $x$. Ideally, it is cheap to compute and such that solving a linear system in $$\\operatorname{Prec}^{1/2}(x) \\circ \\Hess f(x) \\circ \\operatorname{Prec}^{1/2}(x)$$ is easier than without the preconditioner, i.e., it should approximate the inverse of the Hessian. See [/solvers/preconditioners](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/preconditioners). <br> `v = precon(x, u)` <br> `[v, store] = precon(x, u, store)` <br> `v = precon(x, u, storedb, key)` |\n| `sqrtprecon` | $v = \\operatorname{Prec}^{1/2}(x)[u]$, where $\\operatorname{Prec}^{1/2}(x)$ is an (operator) square root of a preconditioner for the Hessian $\\Hess f(x)$, that is, $\\operatorname{Prec}^{1/2}(x)$ is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at $x$, and applying it twice should amount to applying $\\operatorname{Prec}(x)$ once. Solvers typically use `precon` rather than `sqrtprecon`, but some tools (such as `hessianspectrum`) can use `sqrtprecon` to speed up computations. <br> `v = sqrtprecon(x, u)` <br> `[v, store] = sqrtprecon(x, u, store)` <br> `v = sqrtprecon(x, u, storedb, key)` |\n| `linesearch` | Given a point $x$ and a tangent vector $u$ at $x$, assume $u$ is a descent direction. This means there exists $t > 0$ such that $\\phi(t) < \\phi(0)$ with $$\\phi(t) = f(\\Retr_x(td)).$$ Line-search algorithms, which are used by some solvers such as `steepestdescent` and `conjugategradient` are designed to (approximately) minimize $\\phi$ at each iteration. There are built-in, generic ways of doing this. If you have additional structure in your problem that enables you to take a good guess at what $t$ should be, then you can specify it here, in this function handle. This (very much optional) function should return a positive $t > 0$ such that $t$ is a good guess of where to look for a minimizer of $\\phi$. The line-search algorithm (if it decides to use this information) starts by looking at the step $td$, and decides to accept it or not based on its internal rules. See the `linesearch` option on the [solvers](solvers.qmd) page for details on available line-search algorithms and how to pick one. See [`low_rank_matrix_completion`](https://github.com/NicolasBoumal/manopt/blob/master/examples/low_rank_matrix_completion.m) for an example from the literature. <br> `t = linesearch(x, u)` <br> `[t, store] = linesearch(x, u, store)` <br> `t = linesearch(x, u, storedb, key)` | \n\n: Table of all the ways one can describe the cost function in Manopt, including its derivatives, approximations, preconditioners and a line-search hint. {.striped}\n\n:::{.callout-note}\n## StoreDB and `key`, for solver developers and advanced users\nWhen given access to `storedb` and a `key` associated to $x$ rather than to a specific store, the store of $x$ can be obtained as `store = storedb.getStore(key)`.\nPut the modified `store` back into the database with `storedb.set(store, key)`.\n\nAccess the shared memory directly as `storedb.shared`, _not_ via `store.shared`.\nThis is important: `store` might have a `store.shared` field, but when `storedb` and `key` are explicitly used, `store.shared` will not be populated or read on get/set.\n\nEach point $x$ should be associated to a `key`, which is obtained by calling `storedb.getNewKey()`.\nFrom time to time, call `storedb.purge()` to reduce memory usage.\nEven better, as soon as you know that the `store` associated to a certain point is no longer useful, call `storedb.remove(key)` or `storedb.removefirstifdifferent(key1, key2)`.\n\nStoreDB is a [handle class](https://ch.mathworks.com/help/matlab/matlab_oop/comparing-handle-and-value-classes.html): its instances are passed by reference.\nThis means that when a `storedb` object is passed as input to a function, and that function modifies the `storedb` object, the calling function sees the changes too (without the need to explicitly return the `storedb` object).\nThus, each `storedb` object exists only once in memory.\nThis makes for cleaner calling patterns and avoids unnecessary copies.\nThis is not the case for the `store` structures though, which are passed by copy and thus must be returned if the changes are to be permanent.\n:::\n\n\n\n<!-- TODO: remove this whole section?\n## Generic Hessian approximations and preconditioners\n\n_This is from the old documentation._\n\nIf the Hessian is complicated or costly to compute, it may be advantageous to resort to an approximation for it.\nLikewise, if the Hessian is poorly conditioned, it may be advantageous to provide a preconditioner for it (a cheap, approximate and positive definite inverse of the Hessian).\nManopt allows for the definition of generic Hessian approximations and generic preconditioners.\nCheck out these folders if you are interested:\n\n*   [/solvers/hessianapproximations](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/hessianapproximations).\n*   [/solvers/preconditioners](https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/preconditioners).\n\nIn any case, the `trustregions` solver by default works with a finite-difference approximation of the Hessian based on the gradient which has proven effective and robust over the years.\nSee [this paper](https://link.springer.com/chapter/10.1007/978-3-319-25040-3_50#) for a proof of global convergence with this approximation.\nThis finite difference approximation is also covered by the analysis in [that paper](https://academic.oup.com/imajna/advance-article/doi/10.1093/imanum/drx080/4836777).\n-->\n\n\n## Accessing the cost, gradient and Hessian\n\nGiven a `problem` structure with a manifold `problem.M` and some description of the cost function $f$, Manopt provides access to $f$ and its derivatives with the tools `getCost`, `getGradient` and `getHessian`.\nHere is an example:\n\n```matlab\nA = randsym(10);\nproblem.M = spherefactory(10);\nproblem.cost = @(x) .5*x'*A*x;\nproblem = manoptAD(problem);\n\n% For illustration, pick a random point on M\nx = problem.M.rand();\n% Compute f(x)\nf = getCost(problem, x);\n% Compute grad f(x) (Riemannian)\ng = getGradient(problem, x);\n% The Riemannian norm of the gradient is:\nproblem.M.norm(x, g)\n\n% Pick a random tangent vector at x\nu = problem.M.randvec(x);\n% Compute Hess f(x)[u] (Riemannian)\nHu = getHessian(problem, x, u);\n% The Hessian quadratic form <u, Hess f(x)[u]>_x is:\nproblem.M.inner(x, u, Hu)\n```\n\nThere are more functions of this type: see the [core tools](core.qmd) page.\n\nAll of these tools also accept calls with `store` and `(storedb, key)` (from the caching system described above).\nThis is mostly useful inside the code for a solver.\n\nTo compute the eigenvalues of the Hessian, check out the tools `hessianspectrum`, `hessianextreme` and `hessianmatrix` on the [tools](tools.qmd) page.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","include-in-header":{"file":"_header.html"},"highlight-style":"pygments","css":["styles.css"],"toc":true,"html-math-method":"mathjax","strip-comments":true,"toc-depth":3,"output-file":"costdescription.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","crossref":{"eq-prefix":"Eq."},"theme":{"dark":["darkly","custom_darkly.scss"],"light":"sandstone"},"grid":{"sidebar-width":"230px","body-width":"800px","margin-width":"270px","gutter-width":"1.5rem"},"anchor-sections":true,"smooth-scroll":true,"title":"Describing the cost function","subtitle":"And its derivatives (gradient, Hessian)","toc-expand":2,"sidebar":"tutorial","aliases":["tutorial.html#costdescription"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}