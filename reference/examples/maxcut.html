<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of maxcut</title>
  <meta name="keywords" content="maxcut">
  <meta name="description" content="Algorithm to (try to) compute a maximum cut of a graph, via SDP approach.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">examples</a> &gt; maxcut.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for examples&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>maxcut
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>Algorithm to (try to) compute a maximum cut of a graph, via SDP approach.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [x, cutvalue, cutvalue_upperbound, Y] = maxcut(L, r) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Algorithm to (try to) compute a maximum cut of a graph, via SDP approach.
 
 function x = maxcut(L)
 function [x cutvalue cutvalue_upperbound Y] = maxcut(L, r)

 L is the Laplacian matrix describing the graph to cut. The Laplacian of a
 graph is L = D - A, where D is the diagonal degree matrix (D(i, i) is the
 sum of the weights of the edges adjacent to node i) and A is the
 symmetric adjacency matrix of the graph (A(i, j) = A(j, i) is the weight
 of the edge joining nodes i and j). If L is sparse, this will be
 exploited.

 If the graph has n nodes, then L is nxn and the output x is a vector of
 length n such that x(i) is +1 or -1. This partitions the nodes of the
 graph in two classes, in an attempt to maximize the sum of the weights of
 the edges that go from one class to the other (MAX CUT problem).

 cutvalue is the sum of the weights of the edges 'cut' by the partition x.

 If the algorithm reached the global optimum of the underlying SDP
 problem, then it produces an upperbound on the maximum cut value. This
 value is returned in cutvalue_upperbound if it is found. Otherwise, that
 output is set to NaN.

 If r is specified (by default, r = n), the algorithm will stop at rank r.
 This may prevent the algorithm from reaching a globally optimal solution
 for the underlying SDP problem (but can greatly help in keeping the
 execution time under control). If a global optimum of the SDP is reached
 before rank r, the algorithm will stop of course.

 Y is a matrix of size nxp, with p &lt;= r, such that X = Y*Y' is the best
 solution found for the underlying SDP problem. If cutvalue_upperbound is
 not NaN, then Y*Y' is optimal for the SDP and cutvalue_upperbound is its
 cut value.
 
 By Goemans and Williamson 1995, it is known that if the optimal value of
 the SDP is reached, then the returned cut, in expectation, is at most at
 a fraction 0.878 of the optimal cut. (This is not exactly valid because
 we do not use random projection here; sign(Y*randn(size(Y, 2), 1)) will
 give a cut that respects this statement -- it's usually worse though).

 The algorithm is essentially that of:
 Journee, Bach, Absil and Sepulchre, 2010
 Low-rank optimization on the code of positive semidefinite matrices.

 It is itself based on the famous SDP relaxation of MAX CUT:
 Goemans and Williamson, 1995
 Improved approximation algorithms for maximum cut and satisfiability
 problems using semidefinite programming.</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="../manopt/manifolds/symfixedrank/elliptopefactory.html" class="code" title="function M = elliptopefactory(n, k)">elliptopefactory</a>	Manifold of n-by-n psd matrices of rank k with unit diagonal elements.</li><li><a href="../manopt/solvers/trustregions/trustregions.html" class="code" title="function [x, cost, info, options] = trustregions(problem, x, options)">trustregions</a>	Riemannian trust-regions solver for optimization on manifolds.</li><li><a href="../manopt/tools/statsfunhelper.html" class="code" title="function statsfun = statsfunhelper(inp1, inp2)">statsfunhelper</a>	Helper tool to create a statsfun for the options structure of solvers.</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
</ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [Y, info] = maxcut_fixedrank(L, Y)</a></li><li><a href="#_sub2" class="code">function store = prepare(Y, store)</a></li><li><a href="#_sub3" class="code">function [f, store] = cost(Y, store)</a></li><li><a href="#_sub4" class="code">function [g, store] = egrad(Y, store)</a></li><li><a href="#_sub5" class="code">function [h, store] = ehess(Y, U, store)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [x, cutvalue, cutvalue_upperbound, Y] = maxcut(L, r)</a>
0002 <span class="comment">% Algorithm to (try to) compute a maximum cut of a graph, via SDP approach.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function x = maxcut(L)</span>
0005 <span class="comment">% function [x cutvalue cutvalue_upperbound Y] = maxcut(L, r)</span>
0006 <span class="comment">%</span>
0007 <span class="comment">% L is the Laplacian matrix describing the graph to cut. The Laplacian of a</span>
0008 <span class="comment">% graph is L = D - A, where D is the diagonal degree matrix (D(i, i) is the</span>
0009 <span class="comment">% sum of the weights of the edges adjacent to node i) and A is the</span>
0010 <span class="comment">% symmetric adjacency matrix of the graph (A(i, j) = A(j, i) is the weight</span>
0011 <span class="comment">% of the edge joining nodes i and j). If L is sparse, this will be</span>
0012 <span class="comment">% exploited.</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% If the graph has n nodes, then L is nxn and the output x is a vector of</span>
0015 <span class="comment">% length n such that x(i) is +1 or -1. This partitions the nodes of the</span>
0016 <span class="comment">% graph in two classes, in an attempt to maximize the sum of the weights of</span>
0017 <span class="comment">% the edges that go from one class to the other (MAX CUT problem).</span>
0018 <span class="comment">%</span>
0019 <span class="comment">% cutvalue is the sum of the weights of the edges 'cut' by the partition x.</span>
0020 <span class="comment">%</span>
0021 <span class="comment">% If the algorithm reached the global optimum of the underlying SDP</span>
0022 <span class="comment">% problem, then it produces an upperbound on the maximum cut value. This</span>
0023 <span class="comment">% value is returned in cutvalue_upperbound if it is found. Otherwise, that</span>
0024 <span class="comment">% output is set to NaN.</span>
0025 <span class="comment">%</span>
0026 <span class="comment">% If r is specified (by default, r = n), the algorithm will stop at rank r.</span>
0027 <span class="comment">% This may prevent the algorithm from reaching a globally optimal solution</span>
0028 <span class="comment">% for the underlying SDP problem (but can greatly help in keeping the</span>
0029 <span class="comment">% execution time under control). If a global optimum of the SDP is reached</span>
0030 <span class="comment">% before rank r, the algorithm will stop of course.</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% Y is a matrix of size nxp, with p &lt;= r, such that X = Y*Y' is the best</span>
0033 <span class="comment">% solution found for the underlying SDP problem. If cutvalue_upperbound is</span>
0034 <span class="comment">% not NaN, then Y*Y' is optimal for the SDP and cutvalue_upperbound is its</span>
0035 <span class="comment">% cut value.</span>
0036 <span class="comment">%</span>
0037 <span class="comment">% By Goemans and Williamson 1995, it is known that if the optimal value of</span>
0038 <span class="comment">% the SDP is reached, then the returned cut, in expectation, is at most at</span>
0039 <span class="comment">% a fraction 0.878 of the optimal cut. (This is not exactly valid because</span>
0040 <span class="comment">% we do not use random projection here; sign(Y*randn(size(Y, 2), 1)) will</span>
0041 <span class="comment">% give a cut that respects this statement -- it's usually worse though).</span>
0042 <span class="comment">%</span>
0043 <span class="comment">% The algorithm is essentially that of:</span>
0044 <span class="comment">% Journee, Bach, Absil and Sepulchre, 2010</span>
0045 <span class="comment">% Low-rank optimization on the code of positive semidefinite matrices.</span>
0046 <span class="comment">%</span>
0047 <span class="comment">% It is itself based on the famous SDP relaxation of MAX CUT:</span>
0048 <span class="comment">% Goemans and Williamson, 1995</span>
0049 <span class="comment">% Improved approximation algorithms for maximum cut and satisfiability</span>
0050 <span class="comment">% problems using semidefinite programming.</span>
0051 
0052 <span class="comment">% This file is part of Manopt and is copyrighted. See the license file.</span>
0053 <span class="comment">%</span>
0054 <span class="comment">% Main author: Nicolas Boumal, July 18, 2013</span>
0055 <span class="comment">% Contributors:</span>
0056 <span class="comment">%</span>
0057 <span class="comment">% Change log:</span>
0058 <span class="comment">%</span>
0059 <span class="comment">%   April 3, 2015 (NB):</span>
0060 <span class="comment">%       L products now counted with the new shared memory system. This is</span>
0061 <span class="comment">%       more reliable and more flexible than using a global variable.</span>
0062 
0063 
0064     <span class="comment">% If no inputs are provided, generate a random graph Laplacian.</span>
0065     <span class="comment">% This is for illustration purposes only.</span>
0066     <span class="keyword">if</span> ~exist(<span class="string">'L'</span>, <span class="string">'var'</span>) || isempty(L)
0067         n = 20;
0068         A = triu(randn(n) &lt;= .4, 1);
0069         A = A+A';
0070         D = diag(sum(A, 2));
0071         L = D-A;
0072     <span class="keyword">end</span>
0073 
0074 
0075     n = size(L, 1);
0076     assert(size(L, 2) == n, <span class="string">'L must be square.'</span>);
0077 
0078     <span class="keyword">if</span> ~exist(<span class="string">'r'</span>, <span class="string">'var'</span>) || isempty(r) || r &gt; n
0079         r = n;
0080     <span class="keyword">end</span>
0081     
0082     <span class="comment">% We will let the rank increase. Each rank value will generate a cut.</span>
0083     <span class="comment">% We have to go up in the rank to eventually find a certificate of SDP</span>
0084     <span class="comment">% optimality. This in turn will provide an upperbound on the MAX CUT</span>
0085     <span class="comment">% value and ensure that we're doing well, according to Goemans and</span>
0086     <span class="comment">% Williamson's argument. In practice though, the good cuts often come</span>
0087     <span class="comment">% up for low rank values, so we better keep track of the best one.</span>
0088     best_x = ones(n, 1);
0089     best_cutvalue = 0;
0090     cutvalue_upperbound = NaN;
0091     
0092     time = [];
0093     <a href="#_sub3" class="code" title="subfunction [f, store] = cost(Y, store)">cost</a> = [];
0094     
0095     <span class="keyword">for</span> rr = 2 : r
0096         
0097         manifold = <a href="../manopt/manifolds/symfixedrank/elliptopefactory.html" class="code" title="function M = elliptopefactory(n, k)">elliptopefactory</a>(n, rr);
0098         
0099         <span class="keyword">if</span> rr == 2
0100             
0101             <span class="comment">% At first, for rank 2, generate a random point.</span>
0102             Y0 = manifold.rand();
0103              
0104         <span class="keyword">else</span>
0105             
0106             <span class="comment">% To increase the rank, we could just add a column of zeros to</span>
0107             <span class="comment">% the Y matrix. Unfortunately, this lands us in a saddle point.</span>
0108             <span class="comment">% To escape from the saddle, we may compute an eigenvector of</span>
0109             <span class="comment">% Sy associated to a negative eigenvalue: that will yield a</span>
0110             <span class="comment">% (second order) descent direction Z. See Journee et al ; Sy is</span>
0111             <span class="comment">% linked to dual certificates for the SDP.</span>
0112             Y0 = [Y zeros(n, 1)];
0113             LY0 = L*Y0;
0114             Dy = spdiags(sum(LY0.*Y0, 2), 0, n, n);
0115             Sy = (Dy - L)/4;
0116             <span class="comment">% Find the smallest (the &quot;most negative&quot;) eigenvalue of Sy.</span>
0117             eigsopts.issym = true;
0118             eigsopts.isreal = true;
0119             [v, s] = eigs(Sy, 1, <span class="string">'SA'</span>, eigsopts);
0120             <span class="comment">% If there is no negative eigenvalue for Sy, than we are not at</span>
0121             <span class="comment">% a saddle point: we're actually done!</span>
0122             <span class="keyword">if</span> s &gt;= -1e-8
0123                 <span class="comment">% We can stop here: we found the global optimum of the SDP,</span>
0124                 <span class="comment">% and hence the reached cost is a valid upper bound on the</span>
0125                 <span class="comment">% maximum cut value.</span>
0126                 cutvalue_upperbound = max(-[info.cost]);
0127                 <span class="keyword">break</span>;
0128             <span class="keyword">end</span>
0129             
0130             <span class="comment">% This is our escape direction.</span>
0131             Z = manifold.proj(Y0, [zeros(n, rr-1) v]);
0132             
0133             <span class="comment">% % These instructions can be uncommented to see what the cost</span>
0134             <span class="comment">% % function looks like at a saddle point. But will require the</span>
0135             <span class="comment">% % problem structure which is not defined here: see the helper</span>
0136             <span class="comment">% % function.</span>
0137             <span class="comment">% plotprofile(problem, Y0, Z, linspace(-1, 1, 101));</span>
0138             <span class="comment">% drawnow; pause;</span>
0139             
0140             <span class="comment">% Now make a step in the Z direction to escape from the saddle.</span>
0141             <span class="comment">% It is not obvious that it is ok to do a unit step ... perhaps</span>
0142             <span class="comment">% need to be cautious here with the stepsize. It's not too</span>
0143             <span class="comment">% critical though: the important point is to leave the saddle</span>
0144             <span class="comment">% point. But it's nice to guarantee monotone decrease of the</span>
0145             <span class="comment">% cost, and we can't do that with a constant step (at least,</span>
0146             <span class="comment">% not without a proper argument to back it up).</span>
0147             stepsize = 1;
0148             Y0 = manifold.retr(Y0, Z, stepsize);
0149             
0150         <span class="keyword">end</span>
0151         
0152         <span class="comment">% Use the Riemannian optimization based algorithm lower in this</span>
0153         <span class="comment">% file to reach a critical point (typically a local optimizer) of</span>
0154         <span class="comment">% the max cut cost with fixed rank, starting from Y0.</span>
0155         [Y, info] = <a href="#_sub1" class="code" title="subfunction [Y, info] = maxcut_fixedrank(L, Y)">maxcut_fixedrank</a>(L, Y0);
0156         
0157         <span class="comment">% Some info logging.</span>
0158         thistime = [info.time];
0159         <span class="keyword">if</span> ~isempty(time)
0160             thistime = time(end) + thistime;
0161         <span class="keyword">end</span>
0162         time = [time thistime]; <span class="comment">%#ok&lt;AGROW&gt;</span>
0163         <a href="#_sub3" class="code" title="subfunction [f, store] = cost(Y, store)">cost</a> = [<a href="#_sub3" class="code" title="subfunction [f, store] = cost(Y, store)">cost</a> [info.cost]]; <span class="comment">%#ok&lt;AGROW&gt;</span>
0164 
0165         <span class="comment">% Time to turn the matrix Y into a cut.</span>
0166         <span class="comment">% We can either do the random rounding as follows:</span>
0167         <span class="comment">% x = sign(Y*randn(rr, 1));</span>
0168         <span class="comment">% or extract the &quot;PCA direction&quot; of the points in Y and cut</span>
0169         <span class="comment">% orthogonally to that direction, as follows (seems faster than</span>
0170         <span class="comment">% calling svds):</span>
0171         [U, ~, ~] = svd(Y, 0);
0172         u = U(:, 1);
0173         x = sign(u);
0174 
0175         cutvalue = (x'*L*x)/4;
0176         <span class="keyword">if</span> cutvalue &gt; best_cutvalue
0177             best_x = x;
0178             best_cutvalue = cutvalue;
0179         <span class="keyword">end</span>
0180         
0181     <span class="keyword">end</span>
0182     
0183     x = best_x;
0184     cutvalue = best_cutvalue;
0185     
0186     plot(time, -<a href="#_sub3" class="code" title="subfunction [f, store] = cost(Y, store)">cost</a>, <span class="string">'.-'</span>);
0187     xlabel(<span class="string">'Time [s]'</span>);
0188     ylabel(<span class="string">'Relaxed cut value'</span>);
0189     title(<span class="string">'The relaxed cut value is an upper bound on the optimal cut value.'</span>);
0190 
0191 <span class="keyword">end</span>
0192 
0193 
0194 <a name="_sub1" href="#_subfunctions" class="code">function [Y, info] = maxcut_fixedrank(L, Y)</a>
0195 <span class="comment">% Try to solve the (fixed) rank r relaxed max cut program, based on the</span>
0196 <span class="comment">% Laplacian of the graph L and an initial guess Y. L is nxn and Y is nxr.</span>
0197 
0198     [n, r] = size(Y);
0199     assert(all(size(L) == n));
0200     
0201     <span class="comment">% The fixed rank elliptope geometry describes symmetric, positive</span>
0202     <span class="comment">% semidefinite matrices of size n with rank r and all diagonal entries</span>
0203     <span class="comment">% are 1.</span>
0204     manifold = <a href="../manopt/manifolds/symfixedrank/elliptopefactory.html" class="code" title="function M = elliptopefactory(n, k)">elliptopefactory</a>(n, r);
0205     
0206     <span class="comment">% % If you want to compare the performance of the elliptope geometry</span>
0207     <span class="comment">% % against the (conceptually simpler) oblique manifold geometry,</span>
0208     <span class="comment">% % uncomment this line.</span>
0209     <span class="comment">% manifold = obliquefactory(r, n, true);</span>
0210     
0211     problem.M = manifold;
0212     
0213     <span class="comment">% % For rapid prototyping, these lines suffice to describe the cost</span>
0214     <span class="comment">% % function and its gradient and Hessian (here expressed using the</span>
0215     <span class="comment">% % Euclidean gradient and Hessian).</span>
0216     <span class="comment">% problem.cost  = @(Y)  -trace(Y'*L*Y)/4;</span>
0217     <span class="comment">% problem.egrad = @(Y) -(L*Y)/2;</span>
0218     <span class="comment">% problem.ehess = @(Y, U) -(L*U)/2;</span>
0219     
0220     <span class="comment">% Instead of the prototyping version, the functions below describe the</span>
0221     <span class="comment">% cost, gradient and Hessian using the caching system (the store</span>
0222     <span class="comment">% structure). This alows to execute exactly the required number of</span>
0223     <span class="comment">% multiplications with the matrix L. These multiplications are counted</span>
0224     <span class="comment">% using the shared memory in the store structure: that memory is</span>
0225     <span class="comment">% shared , so we get access to the same data, regardless of the</span>
0226     <span class="comment">% point Y currently visited.</span>
0227 
0228     <span class="comment">% For every visited point Y, we will need L*Y. This function makes sure</span>
0229     <span class="comment">% the quantity L*Y is available, but only computes it if it wasn't</span>
0230     <span class="comment">% already computed.</span>
0231     <a name="_sub2" href="#_subfunctions" class="code">function store = prepare(Y, store)</a>
0232         <span class="keyword">if</span> ~isfield(store, <span class="string">'LY'</span>)
0233             <span class="comment">% Compute and store the product for the current point Y.</span>
0234             store.LY = L*Y;
0235             <span class="comment">% Create / increment the shared counter (independent of Y).</span>
0236             <span class="keyword">if</span> isfield(store.shared, <span class="string">'counter'</span>)
0237                 store.shared.counter = store.shared.counter + 1;
0238             <span class="keyword">else</span>
0239                 store.shared.counter = 1;
0240             <span class="keyword">end</span>
0241         <span class="keyword">end</span>
0242     <span class="keyword">end</span>
0243 
0244     problem.cost = @<a href="#_sub3" class="code" title="subfunction [f, store] = cost(Y, store)">cost</a>;
0245     <a name="_sub3" href="#_subfunctions" class="code">function [f, store] = cost(Y, store)</a>
0246         store = <a href="#_sub2" class="code" title="subfunction store = prepare(Y, store)">prepare</a>(Y, store);
0247         LY = store.LY;
0248         f = -(Y(:)'*LY(:))/4; <span class="comment">% = -trace(Y'*LY)/4; but faster</span>
0249     <span class="keyword">end</span>
0250 
0251     problem.egrad = @<a href="#_sub4" class="code" title="subfunction [g, store] = egrad(Y, store)">egrad</a>;
0252     <a name="_sub4" href="#_subfunctions" class="code">function [g, store] = egrad(Y, store)</a>
0253         store = <a href="#_sub2" class="code" title="subfunction store = prepare(Y, store)">prepare</a>(Y, store);
0254         LY = store.LY;
0255         g = -LY/2;
0256     <span class="keyword">end</span>
0257 
0258     problem.ehess = @<a href="#_sub5" class="code" title="subfunction [h, store] = ehess(Y, U, store)">ehess</a>;
0259     <a name="_sub5" href="#_subfunctions" class="code">function [h, store] = ehess(Y, U, store)</a>
0260         store = <a href="#_sub2" class="code" title="subfunction store = prepare(Y, store)">prepare</a>(Y, store); <span class="comment">% this line is not strictly necessary</span>
0261         LU = L*U;
0262         store.shared.counter = store.shared.counter + 1;
0263         h = -LU/2;
0264     <span class="keyword">end</span>
0265 
0266     <span class="comment">% statsfun is called exactly once after each iteration (including after</span>
0267     <span class="comment">% the evaluation of the cost at the initial guess). We then register</span>
0268     <span class="comment">% the value of the L-products counter (which counts how many products</span>
0269     <span class="comment">% were needed so far).</span>
0270     <span class="comment">% options.statsfun = @statsfun;</span>
0271     <span class="comment">% function stats = statsfun(problem, Y, stats, store) %#ok</span>
0272     <span class="comment">%     stats.Lproducts = store.shared.counter;</span>
0273     <span class="comment">% end</span>
0274     <span class="comment">% Equivalent, but simpler syntax:</span>
0275     options.statsfun = <a href="../manopt/tools/statsfunhelper.html" class="code" title="function statsfun = statsfunhelper(inp1, inp2)">statsfunhelper</a>(<span class="string">'Lproducts'</span>, <span class="keyword">...</span>
0276                      @(problem, Y, stats, store) store.shared.counter );
0277     
0278 
0279     <span class="comment">% % Diagnostics tools: to make sure the gradient and Hessian are</span>
0280     <span class="comment">% % correct during the prototyping stage.</span>
0281     <span class="comment">% checkgradient(problem); pause;</span>
0282     <span class="comment">% checkhessian(problem); pause;</span>
0283     
0284     <span class="comment">% % To investigate the effect of the rotational invariance when using</span>
0285     <span class="comment">% % the oblique or the elliptope geometry, or to study the saddle point</span>
0286     <span class="comment">% % issue mentioned above, it is sometimes interesting to look at the</span>
0287     <span class="comment">% % spectrum of the Hessian. For large dimensions, this is slow!</span>
0288     <span class="comment">% stairs(sort(hessianspectrum(problem, Y)));</span>
0289     <span class="comment">% drawnow; pause;</span>
0290     
0291     
0292     <span class="comment">% % When facing a saddle point issue as described in the master</span>
0293     <span class="comment">% % function, and when no sure mechanism exists to find an escape</span>
0294     <span class="comment">% % direction, it may be helpful to set useRand to true and raise</span>
0295     <span class="comment">% % miniter to more than 1, when using trustregions. This will tell the</span>
0296     <span class="comment">% % solver to not stop before at least miniter iterations were</span>
0297     <span class="comment">% % accomplished (thus disregarding the zero gradient at the saddle</span>
0298     <span class="comment">% % point) and to use random search directions to kick start the inner</span>
0299     <span class="comment">% % solve (tCG) step. It is not as efficient as finding a sure escape</span>
0300     <span class="comment">% % direction, but sometimes it's the best we have.</span>
0301     <span class="comment">% options.useRand = true;</span>
0302     <span class="comment">% options.miniter = 5;</span>
0303     
0304     options.verbosity = 2;
0305     [Y, Ycost, info] = <a href="../manopt/solvers/trustregions/trustregions.html" class="code" title="function [x, cost, info, options] = trustregions(problem, x, options)">trustregions</a>(problem, Y, options); <span class="comment">%#ok&lt;ASGLU&gt;</span>
0306     
0307     fprintf(<span class="string">'Products with L: %d\n'</span>, max([info.Lproducts]));
0308 
0309 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Tue 07-Jul-2015 09:52:38 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>