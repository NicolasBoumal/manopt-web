<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of packing_on_the_sphere</title>
  <meta name="keywords" content="packing_on_the_sphere">
  <meta name="description" content="Return a set of points spread out on the sphere.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">examples</a> &gt; packing_on_the_sphere.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for examples&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>packing_on_the_sphere
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>Return a set of points spread out on the sphere.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [X, maxdot] = packing_on_the_sphere(d, n, epsilon, X0) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Return a set of points spread out on the sphere.

 function [X, maxdot] = packing_on_the_sphere(d, n, epsilon, X0)

 Using optimization on the oblique manifold, that is, the product of
 spheres, this function returns a set of n points with unit norm in R^d in
 the form of a matrix X of size nxd, such that the points are spread out
 on the sphere. Ideally, we would minimize the maximum inner product
 between any two points X(i, :) and X(j, :), i~=j, but that is a nonsmooth
 cost function. Instead, we replace the max function by a classical
 log-sum-exp approximation and (attempt to) solve:

 min_{X in OB(d, n)} log( .5*sum_{i~=j} exp( xi'*xj/epsilon ) ),

 with xi = X(:, i) and epsilon is some &quot;diffusion constant&quot;. As epsilon
 goes to zero, the cost function is a sharper approximation of the max
 function (under some assumptions), but the cost function becomes stiffer
 and hence harder to optimize.

 The second output, maxdot, is the maximum inner product between any two
 points in the returned X. This number is the one we truly are trying to
 minimize.

 Notice that this cost function is invariant under rotation of X:
 f(X) = f(XQ) for all orthogonal Q in O(d).
 This calls for optimization over the set of symmetric positive
 semidefinite matrices of size n and rank d with unit diagonal, which can
 be thought of as the quotient of the oblique manifold OB(d, n) by O(d):
 See elliptopefactory.

 This is known as the Thomson or, more specifically, the Tammes problem:
 http://en.wikipedia.org/wiki/Tammes_problem
 An interesting page by Neil Sloane collecting best known packings is
 available here http://neilsloane.com/packings/</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="../manopt/manifolds/oblique/obliquefactory.html" class="code" title="function M = obliquefactory(n, m, transposed)">obliquefactory</a>	Returns a manifold struct to optimize over matrices w/ unit-norm columns.</li><li><a href="../manopt/solvers/conjugategradient/conjugategradient.html" class="code" title="function [x, cost, info, options] = conjugategradient(problem, x, options)">conjugategradient</a>	Conjugate gradient minimization algorithm for Manopt.</li><li><a href="../manopt/tools/hessianspectrum.html" class="code" title="function lambdas = hessianspectrum(problem, x, usepreconstr, storedb, key)">hessianspectrum</a>	Returns the eigenvalues of the (preconditioned) Hessian at x.</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
</ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [f, store] = cost(X, store)</a></li><li><a href="#_sub2" class="code">function [g, store] = grad(X, store)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [X, maxdot] = packing_on_the_sphere(d, n, epsilon, X0)</a>
0002 <span class="comment">% Return a set of points spread out on the sphere.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function [X, maxdot] = packing_on_the_sphere(d, n, epsilon, X0)</span>
0005 <span class="comment">%</span>
0006 <span class="comment">% Using optimization on the oblique manifold, that is, the product of</span>
0007 <span class="comment">% spheres, this function returns a set of n points with unit norm in R^d in</span>
0008 <span class="comment">% the form of a matrix X of size nxd, such that the points are spread out</span>
0009 <span class="comment">% on the sphere. Ideally, we would minimize the maximum inner product</span>
0010 <span class="comment">% between any two points X(i, :) and X(j, :), i~=j, but that is a nonsmooth</span>
0011 <span class="comment">% cost function. Instead, we replace the max function by a classical</span>
0012 <span class="comment">% log-sum-exp approximation and (attempt to) solve:</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% min_{X in OB(d, n)} log( .5*sum_{i~=j} exp( xi'*xj/epsilon ) ),</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% with xi = X(:, i) and epsilon is some &quot;diffusion constant&quot;. As epsilon</span>
0017 <span class="comment">% goes to zero, the cost function is a sharper approximation of the max</span>
0018 <span class="comment">% function (under some assumptions), but the cost function becomes stiffer</span>
0019 <span class="comment">% and hence harder to optimize.</span>
0020 <span class="comment">%</span>
0021 <span class="comment">% The second output, maxdot, is the maximum inner product between any two</span>
0022 <span class="comment">% points in the returned X. This number is the one we truly are trying to</span>
0023 <span class="comment">% minimize.</span>
0024 <span class="comment">%</span>
0025 <span class="comment">% Notice that this cost function is invariant under rotation of X:</span>
0026 <span class="comment">% f(X) = f(XQ) for all orthogonal Q in O(d).</span>
0027 <span class="comment">% This calls for optimization over the set of symmetric positive</span>
0028 <span class="comment">% semidefinite matrices of size n and rank d with unit diagonal, which can</span>
0029 <span class="comment">% be thought of as the quotient of the oblique manifold OB(d, n) by O(d):</span>
0030 <span class="comment">% See elliptopefactory.</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% This is known as the Thomson or, more specifically, the Tammes problem:</span>
0033 <span class="comment">% http://en.wikipedia.org/wiki/Tammes_problem</span>
0034 <span class="comment">% An interesting page by Neil Sloane collecting best known packings is</span>
0035 <span class="comment">% available here http://neilsloane.com/packings/</span>
0036 
0037 <span class="comment">% This file is part of Manopt and is copyrighted. See the license file.</span>
0038 <span class="comment">%</span>
0039 <span class="comment">% Main author: Nicolas Boumal, July 2, 2013</span>
0040 <span class="comment">% Contributors:</span>
0041 <span class="comment">%</span>
0042 <span class="comment">% Change log:</span>
0043 <span class="comment">%   Aug. 14, 2013 (NB) : Code now compatible to experiment with both the</span>
0044 <span class="comment">%                        obliquefactory and the elliptopefactory.</span>
0045 <span class="comment">%</span>
0046 <span class="comment">%   Jan.  7, 2014 (NB) : Added reference to Neil Sloane's page and the</span>
0047 <span class="comment">%                        maxdot output.</span>
0048 <span class="comment">%</span>
0049 <span class="comment">%   June 24, 2014 (NB) : Now shifting exponentials to alleviate numerical</span>
0050 <span class="comment">%                        trouble when epsilon is too small.</span>
0051 <span class="comment">%</span>
0052 <span class="comment">%   Aug. 31, 2021 (XJ) : Added AD to compute the gradient</span>
0053 
0054     <span class="keyword">if</span> ~exist(<span class="string">'d'</span>, <span class="string">'var'</span>) || isempty(d)
0055         <span class="comment">% Dimension of the embedding space: R^d</span>
0056         d = 3;
0057     <span class="keyword">end</span>
0058     <span class="keyword">if</span> ~exist(<span class="string">'n'</span>, <span class="string">'var'</span>) || isempty(n)
0059         <span class="comment">% Number n of points to place of the sphere in R^d.</span>
0060         <span class="comment">% For example, n=12 yields an icosahedron:</span>
0061         <span class="comment">% https://en.wikipedia.org/wiki/Icosahedron</span>
0062         <span class="comment">% Notice though that platonic solids are not always optimal.</span>
0063         <span class="comment">% Try for example n = 8: you don't get a cube.</span>
0064         n = 24;
0065     <span class="keyword">end</span>
0066     <span class="keyword">if</span> ~exist(<span class="string">'epsilon'</span>, <span class="string">'var'</span>) || isempty(epsilon)
0067         <span class="comment">% This value should be as close to 0 as affordable.</span>
0068         <span class="comment">% If it is too close to zero, optimization first becomes much</span>
0069         <span class="comment">% slower, than simply doesn't work anymore becomes of floating</span>
0070         <span class="comment">% point overflow errors (NaN's and Inf's start to appear).</span>
0071         <span class="comment">% If it is too large, then log-sum-exp is a poor approximation of</span>
0072         <span class="comment">% the max function, and the spread will be less uniform.</span>
0073         <span class="comment">% An okay value seems to be 0.01 or 0.001 for example. Note that a</span>
0074         <span class="comment">% better strategy than using a small epsilon straightaway is to</span>
0075         <span class="comment">% reduce epsilon bit by bit and to warm-start subsequent</span>
0076         <span class="comment">% optimization in that way. Trustregions will be more appropriate</span>
0077         <span class="comment">% for these fine tunings.</span>
0078         epsilon = 0.0015;
0079     <span class="keyword">end</span>
0080     
0081     <span class="comment">% Pick your manifold (the elliptope factory quotients out the global</span>
0082     <span class="comment">% rotation invariance of the problem, which is more natural but</span>
0083     <span class="comment">% conceptually a bit more complicated --- for usage with the toolbox it</span>
0084     <span class="comment">% is the same though: just uncomment the appropriate line).</span>
0085     manifold = <a href="../manopt/manifolds/oblique/obliquefactory.html" class="code" title="function M = obliquefactory(n, m, transposed)">obliquefactory</a>(d, n, true);
0086     <span class="comment">% manifold = elliptopefactory(n, d);</span>
0087     
0088     <span class="comment">% Generate a random initial guess if none was given.</span>
0089     <span class="keyword">if</span> ~exist(<span class="string">'X0'</span>, <span class="string">'var'</span>) || isempty(X0)
0090         X0 = manifold.rand();
0091     <span class="keyword">end</span>
0092 
0093     <span class="comment">% Define the cost function with caching system used: the store</span>
0094     <span class="comment">% structure we receive as input is tied to the input point X. Everytime</span>
0095     <span class="comment">% this cost function is called at this point X, we will receive the</span>
0096     <span class="comment">% same store structure back. We may modify the store structure inside</span>
0097     <span class="comment">% the function and return it: the changes will be remembered for next</span>
0098     <span class="comment">% time.</span>
0099     <a name="_sub1" href="#_subfunctions" class="code">function [f, store] = cost(X, store)</a>
0100         <span class="keyword">if</span> ~isfield(store, <span class="string">'ready'</span>)
0101             XXt = X*X';
0102             <span class="comment">% Shift the exponentials by the maximum value to reduce</span>
0103             <span class="comment">% numerical trouble due to possible overflows.</span>
0104             s = max(max(triu(XXt, 1)));
0105             expXXt = exp((XXt-s)/epsilon);
0106             <span class="comment">% Zero out the diagonal</span>
0107             expXXt(1:(n+1):end) = 0;
0108             u = sum(sum(triu(expXXt, 1)));
0109             store.XXt = XXt;
0110             store.s = s;
0111             store.expXXt = expXXt;
0112             store.u = u;
0113             store.ready = true;
0114         <span class="keyword">end</span>
0115         u = store.u;
0116         s = store.s;
0117         f = s + epsilon*log(u);
0118     <span class="keyword">end</span>
0119 
0120     <span class="comment">% Define the gradient of the cost. When the gradient is called at a</span>
0121     <span class="comment">% point X for which the cost was already called, the store structure we</span>
0122     <span class="comment">% receive remember everything that the cost function stored in it, so</span>
0123     <span class="comment">% we can reuse previously computed elements.</span>
0124     <a name="_sub2" href="#_subfunctions" class="code">function [g, store] = grad(X, store)</a>
0125         <span class="keyword">if</span> ~isfield(store, <span class="string">'ready'</span>)
0126             [~, store] = <a href="#_sub1" class="code" title="subfunction [f, store] = cost(X, store)">cost</a>(X, store);
0127         <span class="keyword">end</span>
0128         <span class="comment">% Compute the Euclidean gradient</span>
0129         eg = store.expXXt*X / store.u;
0130         <span class="comment">% Convert to the Riemannian gradient (by projection)</span>
0131         g = manifold.egrad2rgrad(X, eg);
0132     <span class="keyword">end</span>
0133 
0134     <span class="comment">% Setup the problem structure with its manifold M and cost+grad</span>
0135     <span class="comment">% functions.</span>
0136     problem.M = manifold;
0137     problem.cost = @<a href="#_sub1" class="code" title="subfunction [f, store] = cost(X, store)">cost</a>;
0138     problem.grad = @<a href="#_sub2" class="code" title="subfunction [g, store] = grad(X, store)">grad</a>;
0139 
0140     <span class="comment">% An alternative way to compute the grad is to use automatic</span>
0141     <span class="comment">% differentiation provided in the deep learning toolbox (slower)</span>
0142     <span class="comment">% Notice that the function triu is not supported for AD so far.</span>
0143     <span class="comment">% Replace it with ctriu described in the file manoptADhelp.m</span>
0144     <span class="comment">% problem.cost = @cost_AD;</span>
0145     <span class="comment">%    function f = cost_AD(X)</span>
0146     <span class="comment">%        XXt = X*X';</span>
0147     <span class="comment">%        s = max(max(ctriu(XXt, 1)));</span>
0148     <span class="comment">%        expXXt = exp((XXt-s)/epsilon);</span>
0149     <span class="comment">%        expXXt(1:(n+1):end) = 0;</span>
0150     <span class="comment">%        u = sum(sum(ctriu(expXXt, 1)));</span>
0151     <span class="comment">%        f = s + epsilon*log(u);</span>
0152     <span class="comment">%    end</span>
0153     <span class="comment">% Call manoptAD to prepare AD for the problem structure</span>
0154     <span class="comment">% problem = manoptAD(problem,'egrad');</span>
0155     
0156     <span class="comment">% For debugging, it's always nice to check the gradient a few times.</span>
0157     <span class="comment">% checkgradient(problem);</span>
0158     <span class="comment">% pause;</span>
0159     
0160     <span class="comment">% Call a solver on our problem with a few options defined. We did not</span>
0161     <span class="comment">% specify the Hessian but it is still okay to call trustregion: Manopt</span>
0162     <span class="comment">% will approximate the Hessian with finite differences of the gradient.</span>
0163     opts.tolgradnorm = 1e-8;
0164     opts.maxtime = 1200;
0165     opts.maxiter = 1e5;
0166     <span class="comment">% X = trustregions(problem, X0, opts);</span>
0167     X = <a href="../manopt/solvers/conjugategradient/conjugategradient.html" class="code" title="function [x, cost, info, options] = conjugategradient(problem, x, options)">conjugategradient</a>(problem, X0, opts);
0168     
0169     <span class="comment">% Evaluate the maximum inner product between any two points of X.</span>
0170     XXt = X*X';
0171     dots = XXt(find(triu(ones(n), 1))); <span class="comment">%#ok&lt;FNDSB&gt;</span>
0172     maxdot = max(dots);
0173     
0174     <span class="comment">% Similarly, even though we did not specify the Hessian, we may still</span>
0175     <span class="comment">% estimate its spectrum at the solution. It should reflect the</span>
0176     <span class="comment">% invariance of the cost function under a global rotatioon of the</span>
0177     <span class="comment">% sphere, which is an invariance under the group O(d) of dimension</span>
0178     <span class="comment">% d(d-1)/2 : this translates into d(d-1)/2 zero eigenvalues in the</span>
0179     <span class="comment">% spectrum of the Hessian.</span>
0180     <span class="comment">% The approximate Hessian is not a linear operator, and is it a</span>
0181     <span class="comment">% fortiori not symmetric. The result of this computation is thus not</span>
0182     <span class="comment">% reliable. It does display the zero eigenvalues as expected though.</span>
0183     <span class="keyword">if</span> manifold.dim() &lt; 300
0184         evs = real(<a href="../manopt/tools/hessianspectrum.html" class="code" title="function lambdas = hessianspectrum(problem, x, usepreconstr, storedb, key)">hessianspectrum</a>(problem, X));
0185         figure;
0186         stem(1:length(evs), sort(evs), <span class="string">'.'</span>);
0187         title([<span class="string">'Eigenvalues of the approximate Hessian of the cost '</span> <span class="keyword">...</span>
0188                <span class="string">'function at the solution'</span>]);
0189     <span class="keyword">end</span>
0190     
0191     
0192     <span class="comment">% Show how the inner products X(:, i)'*X(:, j) are distributed.</span>
0193     figure;
0194     hist(real(acos(dots)), 20);
0195     title(<span class="string">'Histogram of the geodesic distances'</span>);
0196     
0197     <span class="comment">% This is the quantity we actually want to minimize.</span>
0198     fprintf(<span class="string">'Maximum inner product between two points: %g\n'</span>, maxdot);
0199     
0200     
0201     <span class="comment">% Give some visualization if the dimension allows</span>
0202     <span class="keyword">if</span> d == 2
0203         <span class="comment">% For the circle, the optimal solution consists in spreading the</span>
0204         <span class="comment">% points with angles uniformly sampled in (0, 2pi). This</span>
0205         <span class="comment">% corresponds to the following value for the max inner product:</span>
0206         fprintf(<span class="string">'Optimal value for the max inner product: %g\n'</span>, cos(2*pi/n));
0207         figure;
0208         t = linspace(-pi, pi, 201);
0209         plot(cos(t), sin(t), <span class="string">'-'</span>, <span class="string">'LineWidth'</span>, 3, <span class="string">'Color'</span>, [152,186,220]/255);
0210         daspect([1 1 1]);
0211         box off;
0212         axis off;
0213         hold on;
0214         plot(X(:, 1), X(:, 2), <span class="string">'r.'</span>, <span class="string">'MarkerSize'</span>, 25);
0215         hold off;
0216     <span class="keyword">end</span>
0217     <span class="keyword">if</span> d == 3
0218         figure;
0219         <span class="comment">% Plot the sphere</span>
0220         [sphere_x, sphere_y, sphere_z] = sphere(50);
0221         handle = surf(sphere_x, sphere_y, sphere_z);
0222         set(handle, <span class="string">'FaceColor'</span>, [152,186,220]/255);
0223         set(handle, <span class="string">'FaceAlpha'</span>, .5);
0224         set(handle, <span class="string">'EdgeColor'</span>, [152,186,220]/255);
0225         set(handle, <span class="string">'EdgeAlpha'</span>, .5);
0226         daspect([1 1 1]);
0227         box off;
0228         axis off;
0229         hold on;
0230         <span class="comment">% Add the chosen points</span>
0231         Y = 1.02*X';
0232         plot3(Y(1, :), Y(2, :), Y(3, :), <span class="string">'r.'</span>, <span class="string">'MarkerSize'</span>, 25);
0233         <span class="comment">% And connect the points which are at minimal distance,</span>
0234         <span class="comment">% within some tolerance.</span>
0235         min_distance = real(acos(maxdot));
0236         connected = real(acos(XXt)) &lt;= 1.20*min_distance;
0237         [Ic, Jc] = find(triu(connected, 1));
0238         <span class="keyword">for</span> k = 1 : length(Ic)
0239             i = Ic(k); j = Jc(k);
0240             plot3(Y(1, [i j]), Y(2, [i j]), Y(3, [i j]), <span class="string">'k-'</span>);
0241         <span class="keyword">end</span>
0242         hold off;
0243     <span class="keyword">end</span>
0244 
0245 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Fri 30-Sep-2022 13:18:25 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>