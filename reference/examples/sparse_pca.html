<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of sparse_pca</title>
  <meta name="keywords" content="sparse_pca">
  <meta name="description" content="Sparse principal component analysis based on optimization over Stiefel.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">examples</a> &gt; sparse_pca.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for examples&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>sparse_pca
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>Sparse principal component analysis based on optimization over Stiefel.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [Z, P, X, A] = sparse_pca(A, m, gamma) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Sparse principal component analysis based on optimization over Stiefel.

 [Z, P, X] = sparse_pca(A, m, gamma)

 We consider sparse PCA applied to a data matrix A of size pxn, where p is
 the number of samples (observations) and n is the number of variables
 (features). We attempt to extract m different components. The parameter
 gamma, which must lie between 0 and the largest 2-norm of a column of
 A, tunes the balance between best explanation of the variance of the data
 (gamma = 0, mostly corresponds to standard PCA) and best sparsity of the
 principal components Z (gamma maximal, Z is zero). The variables
 contained in the columns of A are assumed centered (zero-mean).

 The output Z of size nxm represents the principal components. There are m
 columns, each one of unit norm and capturing a prefered direction of the
 data, while trying to be sparse. P has the same size as Z and represents
 the sparsity pattern of Z. X is an orthonormal matrix of size pxm
 produced internally by the algorithm.

 With classical PCA, the variability captured by m components is
 sum(svds(A, m))
 With the outputted Z, which should be sparser than normal PCA, it is
 sum(svd(A*Z))

 The method is based on the maximization of a differentiable function over
 the Stiefel manifold of dimension pxm. Notice that this dimension is
 independent of n, making this method particularly suitable for problems
 with many variables but few samples (n much larger than p). The
 complexity of each iteration of the algorithm is linear in n as a result.

 The theory behind this code is available in the paper
 http://jmlr.org/papers/volume11/journee10a/journee10a.pdf
 Generalized Power Method for Sparse Principal Component Analysis, by
 Journee, Nesterov, Richtarik and Sepulchre, JMLR, 2010.
 This implementation is not equivalent to the one described in that paper
 (and is independent from their authors) but is close in spirit
 nonetheless. It is provided with Manopt as an example file but was not
 optimized: please do not judge the quality of the algorithm described by
 the authors of the paper based on this implementation.</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="../manopt/manifolds/stiefel/stiefelfactory.html" class="code" title="function M = stiefelfactory(n, p, k, gpuflag)">stiefelfactory</a>	Returns a manifold structure to optimize over orthonormal matrices.</li><li><a href="../manopt/manifolds/ttfixedrank/TTeMPS_1.1/@TTeMPS/norm.html" class="code" title="function res = norm( x, safe )">norm</a>	NORM Norm of a TT/MPS tensor.</li><li><a href="../manopt/manifolds/ttfixedrank/TTeMPS_1.1/@TTeMPS_block/norm.html" class="code" title="function res = norm( x )">norm</a>	NORM Norm of a TT/MPS block-mu tensor.</li><li><a href="../manopt/solvers/trustregions/trustregions.html" class="code" title="function [x, cost, info, options] = trustregions(problem, x, options)">trustregions</a>	Riemannian trust-regions solver for optimization on manifolds.</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
</ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [P, X] = sparse_pca_stiefel_l1(A, m, gamma)</a></li><li><a href="#_sub2" class="code">function store = prepare(X, store)</a></li><li><a href="#_sub3" class="code">function [f, store] = cost(X, store)</a></li><li><a href="#_sub4" class="code">function [G, store] = egrad(X, store)</a></li><li><a href="#_sub5" class="code">function Z = postprocess(A, P, X)</a></li><li><a href="#_sub6" class="code">function U = ufactor(X)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [Z, P, X, A] = sparse_pca(A, m, gamma)</a>
0002 <span class="comment">% Sparse principal component analysis based on optimization over Stiefel.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% [Z, P, X] = sparse_pca(A, m, gamma)</span>
0005 <span class="comment">%</span>
0006 <span class="comment">% We consider sparse PCA applied to a data matrix A of size pxn, where p is</span>
0007 <span class="comment">% the number of samples (observations) and n is the number of variables</span>
0008 <span class="comment">% (features). We attempt to extract m different components. The parameter</span>
0009 <span class="comment">% gamma, which must lie between 0 and the largest 2-norm of a column of</span>
0010 <span class="comment">% A, tunes the balance between best explanation of the variance of the data</span>
0011 <span class="comment">% (gamma = 0, mostly corresponds to standard PCA) and best sparsity of the</span>
0012 <span class="comment">% principal components Z (gamma maximal, Z is zero). The variables</span>
0013 <span class="comment">% contained in the columns of A are assumed centered (zero-mean).</span>
0014 <span class="comment">%</span>
0015 <span class="comment">% The output Z of size nxm represents the principal components. There are m</span>
0016 <span class="comment">% columns, each one of unit norm and capturing a prefered direction of the</span>
0017 <span class="comment">% data, while trying to be sparse. P has the same size as Z and represents</span>
0018 <span class="comment">% the sparsity pattern of Z. X is an orthonormal matrix of size pxm</span>
0019 <span class="comment">% produced internally by the algorithm.</span>
0020 <span class="comment">%</span>
0021 <span class="comment">% With classical PCA, the variability captured by m components is</span>
0022 <span class="comment">% sum(svds(A, m))</span>
0023 <span class="comment">% With the outputted Z, which should be sparser than normal PCA, it is</span>
0024 <span class="comment">% sum(svd(A*Z))</span>
0025 <span class="comment">%</span>
0026 <span class="comment">% The method is based on the maximization of a differentiable function over</span>
0027 <span class="comment">% the Stiefel manifold of dimension pxm. Notice that this dimension is</span>
0028 <span class="comment">% independent of n, making this method particularly suitable for problems</span>
0029 <span class="comment">% with many variables but few samples (n much larger than p). The</span>
0030 <span class="comment">% complexity of each iteration of the algorithm is linear in n as a result.</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% The theory behind this code is available in the paper</span>
0033 <span class="comment">% http://jmlr.org/papers/volume11/journee10a/journee10a.pdf</span>
0034 <span class="comment">% Generalized Power Method for Sparse Principal Component Analysis, by</span>
0035 <span class="comment">% Journee, Nesterov, Richtarik and Sepulchre, JMLR, 2010.</span>
0036 <span class="comment">% This implementation is not equivalent to the one described in that paper</span>
0037 <span class="comment">% (and is independent from their authors) but is close in spirit</span>
0038 <span class="comment">% nonetheless. It is provided with Manopt as an example file but was not</span>
0039 <span class="comment">% optimized: please do not judge the quality of the algorithm described by</span>
0040 <span class="comment">% the authors of the paper based on this implementation.</span>
0041 
0042 <span class="comment">% This file is part of Manopt and is copyrighted. See the license file.</span>
0043 <span class="comment">%</span>
0044 <span class="comment">% Main author: Nicolas Boumal, Dec. 24, 2013</span>
0045 <span class="comment">% Contributors:</span>
0046 <span class="comment">%</span>
0047 <span class="comment">% Change log:</span>
0048 <span class="comment">%</span>
0049 <span class="comment">%   Aug. 23, 2021 (XJ):</span>
0050 <span class="comment">%       Added AD to compute the egrad</span>
0051 
0052     <span class="comment">% If no input is provided, generate random data for a quick demo</span>
0053     <span class="keyword">if</span> nargin == 0
0054         n = 100;
0055         p = 10;
0056         m = 2;
0057 
0058         <span class="comment">% Data matrix</span>
0059         A = randn(p, n);
0060 
0061         <span class="comment">% Regularization parameter. This should be between 0 and the largest</span>
0062         <span class="comment">% 2-norm of a column of A.</span>
0063         gamma = 1;
0064         
0065     <span class="keyword">elseif</span> nargin ~= 3
0066         error(<span class="string">'Please provide 3 inputs (or none for a demo).'</span>);
0067     <span class="keyword">end</span>
0068     
0069     <span class="comment">% Execute the main algorithm: it will compute a sparsity pattern P.</span>
0070     [P, X] = <a href="#_sub1" class="code" title="subfunction [P, X] = sparse_pca_stiefel_l1(A, m, gamma)">sparse_pca_stiefel_l1</a>(A, m, gamma);
0071     
0072     <span class="comment">% Compute the principal components in accordance with the sparsity.</span>
0073     Z = <a href="#_sub5" class="code" title="subfunction Z = postprocess(A, P, X)">postprocess</a>(A, P, X);
0074 
0075 <span class="keyword">end</span>
0076 
0077 
0078 <span class="comment">% Sparse PCA based on the block sparse PCA algorithm with l1-penalty as</span>
0079 <span class="comment">% featured in the reference paper by Journee et al. This is not the same</span>
0080 <span class="comment">% algorithm but it is the same cost function optimized over the same search</span>
0081 <span class="comment">% space. We force N = eye(m).</span>
0082 <a name="_sub1" href="#_subfunctions" class="code">function [P, X] = sparse_pca_stiefel_l1(A, m, gamma)</a>
0083     
0084     [p, n] = size(A); <span class="comment">%#ok&lt;NASGU&gt;</span>
0085 
0086     <span class="comment">% The optimization takes place over a Stiefel manifold whose dimension</span>
0087     <span class="comment">% is independent of n. This is especially useful when there are many</span>
0088     <span class="comment">% more variables than samples.</span>
0089     St = <a href="../manopt/manifolds/stiefel/stiefelfactory.html" class="code" title="function M = stiefelfactory(n, p, k, gpuflag)">stiefelfactory</a>(p, m);
0090     problem.M = St;
0091 
0092     <span class="comment">% In this helper function, given a point 'X' on the manifold we check</span>
0093     <span class="comment">% whether the caching structure 'store' has been populated with</span>
0094     <span class="comment">% quantities that are useful to compute at X or not. If they were not,</span>
0095     <span class="comment">% then we compute and store them now.</span>
0096     <a name="_sub2" href="#_subfunctions" class="code">function store = prepare(X, store)</a>
0097         <span class="keyword">if</span> ~isfield(store, <span class="string">'ready'</span>) || ~store.ready
0098             store.AtX = A'*X;
0099             store.absAtX = abs(store.AtX);
0100             store.pos = max(0, store.absAtX - gamma);
0101             store.ready = true;
0102         <span class="keyword">end</span>
0103     <span class="keyword">end</span>
0104 
0105     <span class="comment">% Define the cost function here and set it in the problem structure.</span>
0106     problem.cost = @<a href="#_sub3" class="code" title="subfunction [f, store] = cost(X, store)">cost</a>;
0107     <a name="_sub3" href="#_subfunctions" class="code">function [f, store] = cost(X, store)</a>
0108         store = <a href="#_sub2" class="code" title="subfunction store = prepare(X, store)">prepare</a>(X, store);
0109         pos = store.pos;
0110         f = -.5*<a href="../manopt/manifolds/ttfixedrank/TTeMPS_1.1/@TTeMPS/norm.html" class="code" title="function res = norm( x, safe )">norm</a>(pos, <span class="string">'fro'</span>)^2;
0111     <span class="keyword">end</span>
0112 
0113     <span class="comment">% Here, we chose to define the Euclidean gradient (egrad instead of</span>
0114     <span class="comment">% grad) : Manopt will take care of converting it to the Riemannian</span>
0115     <span class="comment">% gradient.</span>
0116     problem.egrad = @<a href="#_sub4" class="code" title="subfunction [G, store] = egrad(X, store)">egrad</a>;
0117     <a name="_sub4" href="#_subfunctions" class="code">function [G, store] = egrad(X, store)</a>
0118         <span class="keyword">if</span> ~isfield(store, <span class="string">'G'</span>)
0119             store = <a href="#_sub2" class="code" title="subfunction store = prepare(X, store)">prepare</a>(X, store);
0120             pos = store.pos;
0121             AtX = store.AtX;
0122             sgAtX = sign(AtX);
0123             factor = pos.*sgAtX;
0124             store.G = -A*factor;
0125         <span class="keyword">end</span>
0126         G = store.G;
0127     <span class="keyword">end</span>
0128 
0129     <span class="comment">% An alternative way to compute the egrad is to use automatic</span>
0130     <span class="comment">% differentiation provided in the deep learning toolbox (slower).</span>
0131     <span class="comment">% Notice that the function norm is not supported for AD so far.</span>
0132     <span class="comment">% Replace norm(...,'fro')^2 with cnormsqfro described in the file</span>
0133     <span class="comment">% manoptADhelp.m. Notice that the abs function is not differentiable</span>
0134     <span class="comment">% mathematically. Instead the subgradient is computed automatically.</span>
0135     <span class="comment">% problem.cost = @cost_AD;</span>
0136     <span class="comment">% function f = cost_AD(X)</span>
0137     <span class="comment">%    AtX = A'*X;</span>
0138     <span class="comment">%    absAtX = abs(AtX);</span>
0139     <span class="comment">%    pos = max(0, absAtX - gamma);</span>
0140     <span class="comment">%    f = -.5*cnormsqfro(pos);</span>
0141     <span class="comment">% end</span>
0142     <span class="comment">% problem = manoptAD(problem,'egrad');</span>
0143 
0144     <span class="comment">% checkgradient(problem);</span>
0145     <span class="comment">% pause;</span>
0146 
0147     <span class="comment">% The optimization happens here. To improve the method, it may be</span>
0148     <span class="comment">% interesting to investigate better-than-random initial iterates and,</span>
0149     <span class="comment">% possibly, to fine tune the parameters of the solver.</span>
0150     X = <a href="../manopt/solvers/trustregions/trustregions.html" class="code" title="function [x, cost, info, options] = trustregions(problem, x, options)">trustregions</a>(problem);
0151 
0152     <span class="comment">% Compute the sparsity pattern by thresholding</span>
0153     P = abs(A'*X) &gt; gamma;
0154     
0155 <span class="keyword">end</span>
0156 
0157 
0158 <span class="comment">% This post-processing algorithm produces a matrix Z of size nxm matching</span>
0159 <span class="comment">% the sparsity pattern P and representing sparse principal components for</span>
0160 <span class="comment">% A. This is to be called with the output of the main algorithm. This</span>
0161 <span class="comment">% algorithm is described in the reference paper by Journee et al.</span>
0162 <a name="_sub5" href="#_subfunctions" class="code">function Z = postprocess(A, P, X)</a>
0163     fprintf(<span class="string">'Post-processing... '</span>);
0164     counter = 0;
0165     maxiter = 1000;
0166     tolerance = 1e-8;
0167     <span class="keyword">while</span> counter &lt; maxiter
0168         Z = A'*X;
0169         Z(~P) = 0;
0170         Z = Z*diag(1./sqrt(diag(Z'*Z)));
0171         X = <a href="#_sub6" class="code" title="subfunction U = ufactor(X)">ufactor</a>(A*Z);
0172         counter = counter + 1;
0173         <span class="keyword">if</span> counter &gt; 1 &amp;&amp; <a href="../manopt/manifolds/ttfixedrank/TTeMPS_1.1/@TTeMPS/norm.html" class="code" title="function res = norm( x, safe )">norm</a>(Z0-Z, <span class="string">'fro'</span>) &lt; tolerance*<a href="../manopt/manifolds/ttfixedrank/TTeMPS_1.1/@TTeMPS/norm.html" class="code" title="function res = norm( x, safe )">norm</a>(Z0, <span class="string">'fro'</span>)
0174             <span class="keyword">break</span>;
0175         <span class="keyword">end</span>
0176         Z0 = Z;
0177     <span class="keyword">end</span>
0178     fprintf(<span class="string">'done, in %d iterations (max = %d).\n'</span>, counter, maxiter);
0179 <span class="keyword">end</span>
0180 
0181 <span class="comment">% Returns the U-factor of the polar decomposition of X</span>
0182 <a name="_sub6" href="#_subfunctions" class="code">function U = ufactor(X)</a>
0183     [W, S, V] = svd(X, 0); <span class="comment">%#ok&lt;ASGLU&gt;</span>
0184     U = W*V';
0185 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Sun 05-Sep-2021 17:57:00 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>