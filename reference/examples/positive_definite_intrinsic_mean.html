<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of positive_definite_intrinsic_mean</title>
  <meta name="keywords" content="positive_definite_intrinsic_mean">
  <meta name="description" content="Computes an intrinsic mean of a collection of positive definite matrices.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">examples</a> &gt; positive_definite_intrinsic_mean.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for examples&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>positive_definite_intrinsic_mean
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>Computes an intrinsic mean of a collection of positive definite matrices.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function X = positive_definite_intrinsic_mean(A) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Computes an intrinsic mean of a collection of positive definite matrices.

 function X = positive_definite_intrinsic_mean(A)

 Input:  A 3D matrix A of size nxnxm such that each slice A(:, :, k) is a
         positive definite matrix of size nxn.
 
 Output: A positive definite matrix X of size nxn which is an intrinsic mean
         of the m matrices in A, that is, X minimizes the sum of squared
         Riemannian distances to the matrices in A:
            f(X) = sum_k=1^m .5*dist^2(X, A(:, :, k))
         The distance is defined by the natural metric on the set of
         positive definite matrices: see sympositivedefinitefactory.
 
 This simple example is not the best way to compute intrinsic means. Its
 purpose it to serve as base code to explore other algorithms. In
 particular, in the presence of large noise, this algorithm seems not to
 be able to reach points with a very small gradient norm. This may be
 caused by insufficient accuracy in the gradient computation.

 See also: sympositivedefinitefactory</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="../manopt/manifolds/symfixedrank/sympositivedefinitefactory.html" class="code" title="function M = sympositivedefinitefactory(n)">sympositivedefinitefactory</a>	Manifold of n-by-n symmetric positive definite matrices with</li><li><a href="../manopt/solvers/bfgs/rlbfgs.html" class="code" title="function [x, cost, info, options] = rlbfgs(problem, x0, options)">rlbfgs</a>	Riemannian limited memory BFGS solver for smooth objective functions.</li><li><a href="../manopt/solvers/hessianapproximations/approxhessianFD.html" class="code" title="function hessfun = approxhessianFD(problem, options)">approxhessianFD</a>	Hessian approx. fnctn handle based on finite differences of the gradient.</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="positive_definite_karcher_mean.html" class="code" title="function X = positive_definite_karcher_mean(A)">positive_definite_karcher_mean</a>	</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="#_sub1" class="code">function f = cost(X)</a></li><li><a href="#_sub2" class="code">function g = grad(X)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function X = positive_definite_intrinsic_mean(A)</a>
0002 <span class="comment">% Computes an intrinsic mean of a collection of positive definite matrices.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function X = positive_definite_intrinsic_mean(A)</span>
0005 <span class="comment">%</span>
0006 <span class="comment">% Input:  A 3D matrix A of size nxnxm such that each slice A(:, :, k) is a</span>
0007 <span class="comment">%         positive definite matrix of size nxn.</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% Output: A positive definite matrix X of size nxn which is an intrinsic mean</span>
0010 <span class="comment">%         of the m matrices in A, that is, X minimizes the sum of squared</span>
0011 <span class="comment">%         Riemannian distances to the matrices in A:</span>
0012 <span class="comment">%            f(X) = sum_k=1^m .5*dist^2(X, A(:, :, k))</span>
0013 <span class="comment">%         The distance is defined by the natural metric on the set of</span>
0014 <span class="comment">%         positive definite matrices: see sympositivedefinitefactory.</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% This simple example is not the best way to compute intrinsic means. Its</span>
0017 <span class="comment">% purpose it to serve as base code to explore other algorithms. In</span>
0018 <span class="comment">% particular, in the presence of large noise, this algorithm seems not to</span>
0019 <span class="comment">% be able to reach points with a very small gradient norm. This may be</span>
0020 <span class="comment">% caused by insufficient accuracy in the gradient computation.</span>
0021 <span class="comment">%</span>
0022 <span class="comment">% See also: sympositivedefinitefactory</span>
0023 
0024 <span class="comment">% This file is part of Manopt and is copyrighted. See the license file.</span>
0025 <span class="comment">%</span>
0026 <span class="comment">% Main author: Nicolas Boumal, Sept. 3, 2013</span>
0027 <span class="comment">% Contributors:</span>
0028 <span class="comment">%</span>
0029 <span class="comment">% Change log:</span>
0030 <span class="comment">%     Sep. 15, 2022 (NB):</span>
0031 <span class="comment">%         Changed name from positive_definite_karcher_mean, clarified</span>
0032 <span class="comment">%         some comments.</span>
0033     
0034     <span class="comment">% Generate some random data to test the function if none is given.</span>
0035     <span class="keyword">if</span> ~exist(<span class="string">'A'</span>, <span class="string">'var'</span>) || isempty(A)
0036         n = 5;
0037         m = 50;
0038         A = zeros(n, n, m);
0039         ref = diag(max(.1, 1+.1*randn(n, 1)));
0040         <span class="keyword">for</span> i = 1 : m
0041             noise = 0.01*randn(n);
0042             noise = (noise + noise')/2;
0043             [V, D] = eig(ref + noise);
0044             A(:, :, i) = V*diag(max(.01, diag(D)))*V';
0045         <span class="keyword">end</span>
0046     <span class="keyword">end</span>
0047     
0048     <span class="comment">% Retrieve the size of the problem:</span>
0049     <span class="comment">% There are m matrices of size nxn to average.</span>
0050     n = size(A, 1);
0051     m = size(A, 3);
0052     assert(n == size(A, 2), <span class="keyword">...</span>
0053            [<span class="string">'The slices of A must be square, i.e., the '</span> <span class="keyword">...</span>
0054             <span class="string">'first and second dimensions of A must be equal.'</span>]);
0055     
0056     <span class="comment">% Our search space is the set of positive definite matrices of size n.</span>
0057     <span class="comment">% Notice that this is the only place we specify on which manifold we</span>
0058     <span class="comment">% wish to compute Karcher means. Replacing this factory for another</span>
0059     <span class="comment">% geometry will yield code to compute Karcher means on that other</span>
0060     <span class="comment">% manifold, provided that manifold is equipped with a dist function and</span>
0061     <span class="comment">% a logarithmic map log.</span>
0062     M = <a href="../manopt/manifolds/symfixedrank/sympositivedefinitefactory.html" class="code" title="function M = sympositivedefinitefactory(n)">sympositivedefinitefactory</a>(n);
0063     
0064     <span class="comment">% Define a problem structure, specifying the manifold M, the cost</span>
0065     <span class="comment">% function and its gradient.</span>
0066     problem.M = M;
0067     problem.cost = @<a href="#_sub1" class="code" title="subfunction f = cost(X)">cost</a>;
0068     problem.grad = @<a href="#_sub2" class="code" title="subfunction g = grad(X)">grad</a>;
0069     
0070     <span class="comment">% Explicitly pick an approximate Hessian for the trust-region method.</span>
0071     <span class="comment">% (This is only to show an example of how it can be done; the solver</span>
0072     <span class="comment">% below, rlbfgs, does not use the approximate Hessian; trustregions</span>
0073     <span class="comment">% would, but it would figure it out automatically with default</span>
0074     <span class="comment">% stepsize if the line below is omitted.)</span>
0075     problem.approxhess = <a href="../manopt/solvers/hessianapproximations/approxhessianFD.html" class="code" title="function hessfun = approxhessianFD(problem, options)">approxhessianFD</a>(problem, struct(<span class="string">'stepsize'</span>, 1e-4));
0076     
0077     <span class="comment">% The functions below make many redundant computations. This</span>
0078     <span class="comment">% performance hit can be alleviated by using the caching system. We go</span>
0079     <span class="comment">% for a simple implementation here, as a tutorial example.</span>
0080     
0081     <span class="comment">% Cost function</span>
0082     <a name="_sub1" href="#_subfunctions" class="code">function f = cost(X)</a>
0083         f = 0;
0084         <span class="keyword">for</span> k = 1 : m
0085             f = f + M.dist(X, A(:, :, k))^2;
0086         <span class="keyword">end</span>
0087         f = f/(2*m);
0088     <span class="keyword">end</span>
0089 
0090     <span class="comment">% Riemannian gradient of the cost function</span>
0091     <a name="_sub2" href="#_subfunctions" class="code">function g = grad(X)</a>
0092         g = M.zerovec(X);
0093         <span class="keyword">for</span> k = 1 : m
0094             <span class="comment">% Update g in a linear combination of the form</span>
0095             <span class="comment">% g = g - [something]/m.</span>
0096             g = M.lincomb(X, 1, g, -1/m, M.log(X, A(:, :, k)));
0097         <span class="keyword">end</span>
0098     <span class="keyword">end</span>
0099     
0100     <span class="comment">% Execute some checks on the derivatives for early debugging.</span>
0101     <span class="comment">% These things can be commented out of course.</span>
0102     <span class="comment">% The slopes should agree on part of the plot at least. In this case,</span>
0103     <span class="comment">% it is sometimes necessary to inspect the plot visually to make the</span>
0104     <span class="comment">% call, but it is indeed correct.</span>
0105     <span class="comment">% checkgradient(problem);</span>
0106     <span class="comment">% pause;</span>
0107     
0108     <span class="comment">% Execute this if you want to force using a proper parallel vector</span>
0109     <span class="comment">% transport. This is not necessary. If you omit this, the default</span>
0110     <span class="comment">% vector transport is the identity map, which is (of course) cheaper</span>
0111     <span class="comment">% and seems to perform well in practice.</span>
0112     <span class="comment">% M.transp = M.paralleltransp;</span>
0113     
0114     <span class="comment">% Issue a call to a solver. Default options are selected.</span>
0115     <span class="comment">% Our initial guess is the first data point. Most solvers work well</span>
0116     <span class="comment">% with this problem. Limited-memory BFGS is one good example:</span>
0117     X = <a href="../manopt/solvers/bfgs/rlbfgs.html" class="code" title="function [x, cost, info, options] = rlbfgs(problem, x0, options)">rlbfgs</a>(problem, A(:, :, 1));
0118 
0119 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Fri 30-Sep-2022 13:18:25 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>