<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of getHessianFD</title>
  <meta name="keywords" content="getHessianFD">
  <meta name="description" content="Computes an approx. of the Hessian w/ finite differences of the gradient.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="index.html">core</a> &gt; getHessianFD.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\core&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>getHessianFD
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Computes an approx. of the Hessian w/ finite differences of the gradient.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function hessfd = getHessianFD(problem, x, d, storedb, key) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Computes an approx. of the Hessian w/ finite differences of the gradient.

 function hessfd = getHessianFD(problem, x, d)
 function hessfd = getHessianFD(problem, x, d, storedb)
 function hessfd = getHessianFD(problem, x, d, storedb, key)

 Returns a finite difference approximation of the Hessian at x along d of
 the cost function described in the problem structure. The finite
 difference is based on computations of the gradient.

 storedb is a StoreDB object, key is the StoreDB key to point x.

 If the gradient cannot be computed, an exception is thrown.

 See also: approxhessianFD</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>	Computes the gradient of the cost function at x.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="getApproxHessian.html" class="code" title="function approxhess = getApproxHessian(problem, x, d, storedb, key)">getApproxHessian</a>	Computes an approximation of the Hessian of the cost fun. at x along d.</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function hessfd = getHessianFD(problem, x, d, storedb, key)</a>
0002 <span class="comment">% Computes an approx. of the Hessian w/ finite differences of the gradient.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function hessfd = getHessianFD(problem, x, d)</span>
0005 <span class="comment">% function hessfd = getHessianFD(problem, x, d, storedb)</span>
0006 <span class="comment">% function hessfd = getHessianFD(problem, x, d, storedb, key)</span>
0007 <span class="comment">%</span>
0008 <span class="comment">% Returns a finite difference approximation of the Hessian at x along d of</span>
0009 <span class="comment">% the cost function described in the problem structure. The finite</span>
0010 <span class="comment">% difference is based on computations of the gradient.</span>
0011 <span class="comment">%</span>
0012 <span class="comment">% storedb is a StoreDB object, key is the StoreDB key to point x.</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% If the gradient cannot be computed, an exception is thrown.</span>
0015 <span class="comment">%</span>
0016 <span class="comment">% See also: approxhessianFD</span>
0017 
0018 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0019 <span class="comment">% Original author: Nicolas Boumal, Dec. 30, 2012.</span>
0020 <span class="comment">% Contributors:</span>
0021 <span class="comment">% Change log:</span>
0022 <span class="comment">%</span>
0023 <span class="comment">%   Feb. 19, 2015 (NB):</span>
0024 <span class="comment">%       It is sufficient to ensure positive radial linearity to guarantee</span>
0025 <span class="comment">%       (together with other assumptions) that this approximation of the</span>
0026 <span class="comment">%       Hessian will confer global convergence to the trust-regions method.</span>
0027 <span class="comment">%       Formerly, in-code comments referred to the necessity of having</span>
0028 <span class="comment">%       complete radial linearity, and that this was harder to achieve.</span>
0029 <span class="comment">%       This appears not to be necessary after all, which simplifies the</span>
0030 <span class="comment">%       code.</span>
0031 <span class="comment">%</span>
0032 <span class="comment">%   April 3, 2015 (NB):</span>
0033 <span class="comment">%       Works with the new StoreDB class system.</span>
0034 <span class="comment">%</span>
0035 <span class="comment">%   Nov. 1, 2016 (NB):</span>
0036 <span class="comment">%       Removed exception in case of unavailable gradient, as getGradient</span>
0037 <span class="comment">%       now knows to fall back to an approximate gradient if need be.</span>
0038 <span class="comment">%</span>
0039 <span class="comment">%   March 17, 2020 (NB):</span>
0040 <span class="comment">%       Following a bug report by Marco Sutti, added the instruction</span>
0041 <span class="comment">%           storedb.remove(key1);</span>
0042 <span class="comment">%       to avoid memory usage ramping up when many inner iterations are</span>
0043 <span class="comment">%       needed inside of tCG for trustregions. The deciding factor is that</span>
0044 <span class="comment">%       there is no need to cache the gradient at the artificially produced</span>
0045 <span class="comment">%       point used here for finite differencing, as this point is not</span>
0046 <span class="comment">%       visible outside of this function: there is no reason we would visit</span>
0047 <span class="comment">%       it again.</span>
0048 
0049     <span class="comment">% Allow omission of the key, and even of storedb.</span>
0050     <span class="keyword">if</span> ~exist(<span class="string">'key'</span>, <span class="string">'var'</span>)
0051         <span class="keyword">if</span> ~exist(<span class="string">'storedb'</span>, <span class="string">'var'</span>)
0052             storedb = <a href="StoreDB.html" class="code" title="">StoreDB</a>();
0053         <span class="keyword">end</span>
0054         key = storedb.getNewKey();
0055     <span class="keyword">end</span>
0056 
0057     <span class="comment">% Step size</span>
0058     norm_d = problem.M.norm(x, d);
0059     
0060     <span class="comment">% First, check whether the step d is not too small</span>
0061     <span class="keyword">if</span> norm_d &lt; eps
0062         hessfd = problem.M.zerovec(x);
0063         <span class="keyword">return</span>;
0064     <span class="keyword">end</span>
0065     
0066     <span class="comment">% Parameter: how far do we look?</span>
0067     <span class="comment">% If you need to change this parameter, use approxhessianFD explicitly.</span>
0068     <span class="comment">% A power of 2 is chosen so that scaling by epsilon does not incur any</span>
0069     <span class="comment">% round-off error in IEEE arithmetic.</span>
0070     epsilon = 2^-14;
0071         
0072     c = epsilon/norm_d;
0073     
0074     <span class="comment">% Compute the gradient at the current point.</span>
0075     grad = <a href="getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>(problem, x, storedb, key);
0076     
0077     <span class="comment">% Compute a point a little further along d and the gradient there.</span>
0078     <span class="comment">% Since this is a new point, we need a new key for it, for the storedb.</span>
0079     x1 = problem.M.retr(x, d, c);
0080     key1 = storedb.getNewKey();
0081     grad1 = <a href="getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>(problem, x1, storedb, key1);
0082     
0083     <span class="comment">% Remove any caching associated to that new point, since there is no</span>
0084     <span class="comment">% reason we would be visiting it again.</span>
0085     storedb.remove(key1);
0086     
0087     <span class="comment">% Transport grad1 back from x1 to x.</span>
0088     grad1 = problem.M.transp(x1, x, grad1);
0089     
0090     <span class="comment">% Return the finite difference of them.</span>
0091     hessfd = problem.M.lincomb(x, 1/c, grad1, -1/c, grad);
0092     
0093     <span class="comment">% Note: if grad and grad1 are relatively large vectors, then computing</span>
0094     <span class="comment">% their difference to obtain hessfd can result in large errors due to</span>
0095     <span class="comment">% floating point arithmetic. As a result, even though grad and grad1</span>
0096     <span class="comment">% are supposed to be tangent up to machine precision, the resulting</span>
0097     <span class="comment">% vector hessfd can be significantly further from being tangent. If so,</span>
0098     <span class="comment">% this will show in the 'residual check' in checkhessian. Thus, when</span>
0099     <span class="comment">% using a finite difference approximation, the residual should be</span>
0100     <span class="comment">% judged as compared to the norm of the gradient at the point under</span>
0101     <span class="comment">% consideration. This seems not to have caused trouble. If this should</span>
0102     <span class="comment">% become an issue for some application, the easy fix is to project the</span>
0103     <span class="comment">% result of the FD approximation: hessfd = problem.M.proj(x, hessfd).</span>
0104     
0105 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Fri 30-Sep-2022 13:18:25 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>