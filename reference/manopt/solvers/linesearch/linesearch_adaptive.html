<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of linesearch_adaptive</title>
  <meta name="keywords" content="linesearch_adaptive">
  <meta name="description" content="Adaptive line search algorithm (step size selection) for descent methods.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="#">solvers</a> &gt; <a href="index.html">linesearch</a> &gt; linesearch_adaptive.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../index.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\solvers\linesearch&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>linesearch_adaptive
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>Adaptive line search algorithm (step size selection) for descent methods.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function [stepsize, newx, newkey, lsstats] =linesearch_adaptive(problem, x, d, f0, df0, options, storedb, key) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Adaptive line search algorithm (step size selection) for descent methods.

 function [stepsize, newx, newkey, lsstats] = 
        linesearch_adaptive(problem, x, d, f0, df0, options, storedb, key)

 Adaptive linesearch algorithm for descent methods, based on a simple
 backtracking method. Contrary to linesearch.m, this function is not
 invariant under rescaling of the search direction d. These two line
 search methods vary mainly in their strategy to pick the initial step
 size.
 
 Below, the step is constructed as alpha*d, and the step size is the norm
 of that vector, thus: stepsize = alpha*norm_d. The step is executed by
 retracting the vector alpha*d from the current point x, giving newx.

 This line-search may create and maintain a structure called lsmem inside
 storedb.internal. This gives the linesearch the opportunity to remember
 what happened in the previous calls. This is typically used to make a
 first guess at the step size, based on previous events.

 Inputs/Outputs : see help for linesearch

 See also: steepestdescent conjugategradients <a href="linesearch.html" class="code" title="function [stepsize, newx, newkey, lsstats] =linesearch(problem, x, d, f0, df0, options, storedb, key)">linesearch</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../../manopt/core/getCost.html" class="code" title="function cost = getCost(problem, x, storedb, key)">getCost</a>	Computes the cost function at x.</li><li><a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>	Merges two options structures with one having precedence over the other.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/solvers/conjugategradient/conjugategradient.html" class="code" title="function [x, cost, info, options] = conjugategradient(problem, x, options)">conjugategradient</a>	Conjugate gradient minimization algorithm for Manopt.</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [stepsize, newx, newkey, lsstats] = </a><span class="keyword">...</span>
0002   linesearch_adaptive(problem, x, d, f0, df0, options, storedb, key)
0003 <span class="comment">% Adaptive line search algorithm (step size selection) for descent methods.</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% function [stepsize, newx, newkey, lsstats] =</span>
0006 <span class="comment">%        linesearch_adaptive(problem, x, d, f0, df0, options, storedb, key)</span>
0007 <span class="comment">%</span>
0008 <span class="comment">% Adaptive linesearch algorithm for descent methods, based on a simple</span>
0009 <span class="comment">% backtracking method. Contrary to linesearch.m, this function is not</span>
0010 <span class="comment">% invariant under rescaling of the search direction d. These two line</span>
0011 <span class="comment">% search methods vary mainly in their strategy to pick the initial step</span>
0012 <span class="comment">% size.</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% Below, the step is constructed as alpha*d, and the step size is the norm</span>
0015 <span class="comment">% of that vector, thus: stepsize = alpha*norm_d. The step is executed by</span>
0016 <span class="comment">% retracting the vector alpha*d from the current point x, giving newx.</span>
0017 <span class="comment">%</span>
0018 <span class="comment">% This line-search may create and maintain a structure called lsmem inside</span>
0019 <span class="comment">% storedb.internal. This gives the linesearch the opportunity to remember</span>
0020 <span class="comment">% what happened in the previous calls. This is typically used to make a</span>
0021 <span class="comment">% first guess at the step size, based on previous events.</span>
0022 <span class="comment">%</span>
0023 <span class="comment">% Inputs/Outputs : see help for linesearch</span>
0024 <span class="comment">%</span>
0025 <span class="comment">% See also: steepestdescent conjugategradients linesearch</span>
0026 
0027 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0028 <span class="comment">% Original author: Bamdev Mishra, Dec. 30, 2012.</span>
0029 <span class="comment">% Contributors: Nicolas Boumal</span>
0030 <span class="comment">% Change log:</span>
0031 <span class="comment">%</span>
0032 <span class="comment">%   Sept. 13, 2013 (NB) :</span>
0033 <span class="comment">%       The automatic direction reversal feature was removed (it triggered</span>
0034 <span class="comment">%       when df0 &gt; 0). Direction reversal is a decision that needs to be</span>
0035 <span class="comment">%       made by the solver, so it can know about it.</span>
0036 <span class="comment">%</span>
0037 <span class="comment">%    Nov. 7, 2013 (NB) :</span>
0038 <span class="comment">%       The whole function has been recoded to mimick more closely the new</span>
0039 <span class="comment">%       version of linesearch.m. The parameters are available through the</span>
0040 <span class="comment">%       options structure passed to the solver and have the same names and</span>
0041 <span class="comment">%       same meaning as for the base linesearch. The information is logged</span>
0042 <span class="comment">%       more reliably.</span>
0043 <span class="comment">%</span>
0044 <span class="comment">%   April 3, 2015 (NB):</span>
0045 <span class="comment">%       Works with the new StoreDB class system.</span>
0046 <span class="comment">%</span>
0047 <span class="comment">%   April 8, 2015 (NB):</span>
0048 <span class="comment">%       Got rid of lsmem input/output: now maintained in storedb.internal.</span>
0049 <span class="comment">%</span>
0050 <span class="comment">%   Aug. 2, 2018 (NB):</span>
0051 <span class="comment">%       Now using storedb.remove() to keep the cache lean.</span>
0052 
0053 
0054     <span class="comment">% Allow omission of the key, and even of storedb.</span>
0055     <span class="keyword">if</span> ~exist(<span class="string">'key'</span>, <span class="string">'var'</span>)
0056         <span class="keyword">if</span> ~exist(<span class="string">'storedb'</span>, <span class="string">'var'</span>)
0057             storedb = <a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>();
0058         <span class="keyword">end</span>
0059         key = storedb.getNewKey();
0060     <span class="keyword">end</span>
0061 
0062     <span class="comment">% Backtracking default parameters. These can be overwritten in the</span>
0063     <span class="comment">% options structure which is passed to the solver.</span>
0064     default_options.ls_contraction_factor = .5;
0065     default_options.ls_suff_decr = .5;
0066     default_options.ls_max_steps = 10;
0067     default_options.ls_initial_stepsize = 1;
0068     
0069     <span class="keyword">if</span> ~exist(<span class="string">'options'</span>, <span class="string">'var'</span>) || isempty(options)
0070         options = struct();
0071     <span class="keyword">end</span>
0072     options = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>(default_options, options);
0073     
0074     contraction_factor = options.ls_contraction_factor;
0075     suff_decr = options.ls_suff_decr;
0076     max_ls_steps = options.ls_max_steps;
0077     initial_stepsize = options.ls_initial_stepsize;
0078     
0079     <span class="comment">% Compute the norm of the search direction.</span>
0080     norm_d = problem.M.norm(x, d);
0081     
0082     <span class="comment">% If this is not the first iteration, then lsmem should have been</span>
0083     <span class="comment">% filled with a suggestion for the initial step.</span>
0084     <span class="keyword">if</span> isfield(storedb.internal, <span class="string">'lsmem'</span>)
0085         lsmem = storedb.internal.lsmem;
0086         <span class="keyword">if</span> isfield(lsmem, <span class="string">'init_alpha'</span>)
0087             <span class="comment">% Pick initial step size based on where we were last time,</span>
0088             alpha = lsmem.init_alpha;
0089         <span class="keyword">end</span>
0090     <span class="comment">% Otherwise, fall back to a user supplied suggestion.</span>
0091     <span class="keyword">else</span>
0092         alpha = initial_stepsize / norm_d;
0093     <span class="keyword">end</span>
0094 
0095     <span class="comment">% Make the chosen step and compute the cost there.</span>
0096     newx = problem.M.retr(x, d, alpha);
0097     newkey = storedb.getNewKey();
0098     newf = <a href="../../../manopt/core/getCost.html" class="code" title="function cost = getCost(problem, x, storedb, key)">getCost</a>(problem, newx, storedb, newkey);
0099     cost_evaluations = 1;
0100     
0101     <span class="comment">% Backtrack while the Armijo criterion is not satisfied</span>
0102     <span class="keyword">while</span> newf &gt; f0 + suff_decr*alpha*df0
0103         
0104         <span class="comment">% Reduce the step size,</span>
0105         alpha = contraction_factor * alpha;
0106         
0107         <span class="comment">% and look closer down the line.</span>
0108         storedb.remove(newkey);              <span class="comment">% we no longer need this cache</span>
0109         newx = problem.M.retr(x, d, alpha);
0110         newkey = storedb.getNewKey();
0111         newf = <a href="../../../manopt/core/getCost.html" class="code" title="function cost = getCost(problem, x, storedb, key)">getCost</a>(problem, newx, storedb, newkey);
0112         cost_evaluations = cost_evaluations + 1;
0113         
0114         <span class="comment">% Make sure we don't run out of budget.</span>
0115         <span class="keyword">if</span> cost_evaluations &gt;= max_ls_steps
0116             <span class="keyword">break</span>;
0117         <span class="keyword">end</span>
0118         
0119     <span class="keyword">end</span>
0120     
0121     <span class="comment">% If we got here without obtaining a decrease, we reject the step.</span>
0122     <span class="keyword">if</span> newf &gt; f0
0123         alpha = 0;
0124         newx = x;
0125         newkey = key;
0126         newf = f0; <span class="comment">%#ok&lt;NASGU&gt;</span>
0127     <span class="keyword">end</span>
0128     
0129     <span class="comment">% As seen outside this function, stepsize is the size of the vector we</span>
0130     <span class="comment">% retract to make the step from x to newx. Since the step is alpha*d:</span>
0131     stepsize = alpha * norm_d;
0132 
0133     <span class="comment">% Fill lsmem with a suggestion for what the next initial step size</span>
0134     <span class="comment">% trial should be. On average we intend to do only one extra cost</span>
0135     <span class="comment">% evaluation. Notice how the suggestion is not about stepsize but about</span>
0136     <span class="comment">% alpha. This is the reason why this line search is not invariant under</span>
0137     <span class="comment">% rescaling of the search direction d.</span>
0138     <span class="keyword">switch</span> cost_evaluations
0139         <span class="keyword">case</span> 1
0140             <span class="comment">% If things go very well, push your luck.</span>
0141             init_alpha = 2 * alpha;
0142         <span class="keyword">case</span> 2
0143             <span class="comment">% If things go reasonably well, try to keep pace.</span>
0144             init_alpha = alpha;
0145         <span class="keyword">otherwise</span>
0146             <span class="comment">% If we backtracked a lot, the new stepsize is probably quite</span>
0147             <span class="comment">% small: try to recover.</span>
0148             init_alpha = 2 * alpha;
0149     <span class="keyword">end</span>
0150     storedb.internal.lsmem.init_alpha = init_alpha;
0151     
0152     <span class="comment">% Return some statistics also, for possible analysis.</span>
0153     lsstats.costevals = cost_evaluations;
0154     lsstats.stepsize = stepsize;
0155     lsstats.alpha = alpha;
0156     
0157 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Mon 10-Sep-2018 11:48:06 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>