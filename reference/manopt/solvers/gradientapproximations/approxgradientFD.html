<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of approxgradientFD</title>
  <meta name="keywords" content="approxgradientFD">
  <meta name="description" content="Gradient approx. fnctn handle based on finite differences of the cost.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="#">solvers</a> &gt; <a href="index.html">gradientapproximations</a> &gt; approxgradientFD.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../index.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\solvers\gradientapproximations&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>approxgradientFD
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>Gradient approx. fnctn handle based on finite differences of the cost.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function gradfun = approxgradientFD(problem, options) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Gradient approx. fnctn handle based on finite differences of the cost.

 function gradfun = approxgradientFD(problem)
 function gradfun = approxgradientFD(problem, options)

 Input:

 A Manopt problem structure (already containing the manifold and enough
 information to compute the cost) and an options structure (optional),
 containing one option:
    options.stepsize (positive double; default: 2^-23).
    options.subspacedim (positive integer; default: [], for M.dim()).

 If the cost cannot be computed on 'problem', a warning is issued.

 Output:
 
 Returns a function handle, encapsulating a generic finite difference
 approximation of the gradient of the problem cost. The finite difference
 is based on M.dim()+1 computations of the cost.
 
 The returned gradfun has this calling pattern:
 
   function gradfd = gradfun(x)
   function gradfd = gradfun(x, storedb)
   function gradfd = gradfun(x, storedb, key)
 
 x is a point on the manifold problem.M, storedb is a StoreDB object,
 and key is the StoreDB key to point x.

 Usage:

 Typically, the user will set problem.M and other fields to define the
 cost (typically, problem.cost). Then, to use this generic purpose
 gradient approximation:

   problem.approxgrad = approxgradientFD(problem, options);

 See also: steepestdescent conjugategradient</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../../manopt/core/canGetCost.html" class="code" title="function candoit = canGetCost(problem)">canGetCost</a>	Checks whether the cost function can be computed for a problem structure.</li><li><a href="../../../manopt/core/getCost.html" class="code" title="function cost = getCost(problem, x, storedb, key)">getCost</a>	Computes the cost function at x.</li><li><a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts1, opts2)">mergeOptions</a>	Merges two options structures with one having precedence over the other.</li><li><a href="../../../manopt/tools/lincomb.html" class="code" title="function vec = lincomb(M, x, vecs, coeffs)">lincomb</a>	Computes a linear combination of tangent vectors in the Manopt framework.</li><li><a href="../../../manopt/tools/tangentorthobasis.html" class="code" title="function orthobasis = tangentorthobasis(M, x, n)">tangentorthobasis</a>	Returns an orthonormal basis of tangent vectors in the Manopt framework.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/solvers/conjugategradient/conjugategradient.html" class="code" title="function [x, cost, info, options] = conjugategradient(problem, x, options)">conjugategradient</a>	Conjugate gradient minimization algorithm for Manopt.</li><li><a href="../../../manopt/solvers/steepestdescent/steepestdescent.html" class="code" title="function [x, cost, info, options] = steepestdescent(problem, x, options)">steepestdescent</a>	Steepest descent (gradient descent) minimization algorithm for Manopt.</li><li><a href="../../../manopt/solvers/trustregions/trustregions.html" class="code" title="function [x, cost, info, options] = trustregions(problem, x, options)">trustregions</a>	Riemannian trust-regions solver for optimization on manifolds.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function gradfd = funhandle(x, storedb, key)</a></li><li><a href="#_sub2" class="code">function gradfd = gradientFD(stepsize, subspacedim, problem, x, storedb, key)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function gradfun = approxgradientFD(problem, options)</a>
0002 <span class="comment">% Gradient approx. fnctn handle based on finite differences of the cost.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function gradfun = approxgradientFD(problem)</span>
0005 <span class="comment">% function gradfun = approxgradientFD(problem, options)</span>
0006 <span class="comment">%</span>
0007 <span class="comment">% Input:</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% A Manopt problem structure (already containing the manifold and enough</span>
0010 <span class="comment">% information to compute the cost) and an options structure (optional),</span>
0011 <span class="comment">% containing one option:</span>
0012 <span class="comment">%    options.stepsize (positive double; default: 2^-23).</span>
0013 <span class="comment">%    options.subspacedim (positive integer; default: [], for M.dim()).</span>
0014 <span class="comment">%</span>
0015 <span class="comment">% If the cost cannot be computed on 'problem', a warning is issued.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">% Output:</span>
0018 <span class="comment">%</span>
0019 <span class="comment">% Returns a function handle, encapsulating a generic finite difference</span>
0020 <span class="comment">% approximation of the gradient of the problem cost. The finite difference</span>
0021 <span class="comment">% is based on M.dim()+1 computations of the cost.</span>
0022 <span class="comment">%</span>
0023 <span class="comment">% The returned gradfun has this calling pattern:</span>
0024 <span class="comment">%</span>
0025 <span class="comment">%   function gradfd = gradfun(x)</span>
0026 <span class="comment">%   function gradfd = gradfun(x, storedb)</span>
0027 <span class="comment">%   function gradfd = gradfun(x, storedb, key)</span>
0028 <span class="comment">%</span>
0029 <span class="comment">% x is a point on the manifold problem.M, storedb is a StoreDB object,</span>
0030 <span class="comment">% and key is the StoreDB key to point x.</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% Usage:</span>
0033 <span class="comment">%</span>
0034 <span class="comment">% Typically, the user will set problem.M and other fields to define the</span>
0035 <span class="comment">% cost (typically, problem.cost). Then, to use this generic purpose</span>
0036 <span class="comment">% gradient approximation:</span>
0037 <span class="comment">%</span>
0038 <span class="comment">%   problem.approxgrad = approxgradientFD(problem, options);</span>
0039 <span class="comment">%</span>
0040 <span class="comment">% See also: steepestdescent conjugategradient</span>
0041 
0042 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0043 <span class="comment">% Original author: Nicolas Boumal, Nov. 1, 2016.</span>
0044 <span class="comment">% Contributors:</span>
0045 <span class="comment">% Change log:</span>
0046 
0047     <span class="comment">% This gradient approximation is based on the cost:</span>
0048     <span class="comment">% check availability.</span>
0049     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetCost.html" class="code" title="function candoit = canGetCost(problem)">canGetCost</a>(problem)
0050         warning(<span class="string">'manopt:approxgradFD:nocost'</span>, <span class="keyword">...</span>
0051                 <span class="string">'approxgradFD requires the cost to be computable.'</span>);
0052     <span class="keyword">end</span>
0053 
0054     <span class="comment">% Set local defaults here, and merge with user options, if any.</span>
0055     localdefaults.stepsize = 2^-23;
0056     localdefaults.subspacedim = [];
0057     <span class="keyword">if</span> ~exist(<span class="string">'options'</span>, <span class="string">'var'</span>) || isempty(options)
0058         options = struct();
0059     <span class="keyword">end</span>
0060     options = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts1, opts2)">mergeOptions</a>(localdefaults, options);
0061     
0062     <span class="comment">% % Finite-difference parameters</span>
0063     <span class="comment">% How far do we look?</span>
0064     stepsize = options.stepsize;
0065     <span class="comment">% Approximate the projection of the gradient on a random subspace of</span>
0066     <span class="comment">% what dimension? If [], uses full tangent space.</span>
0067     subspacedim = options.subspacedim;
0068                    
0069     <span class="comment">% Build and return the function handle here. This extra construct via</span>
0070     <span class="comment">% funhandle makes it possible to make storedb and key optional.</span>
0071     gradfun = @<a href="#_sub1" class="code" title="subfunction gradfd = funhandle(x, storedb, key)">funhandle</a>;
0072     <a name="_sub1" href="#_subfunctions" class="code">function gradfd = funhandle(x, storedb, key)</a>
0073         <span class="comment">% Allow omission of the key, and even of storedb.</span>
0074         <span class="keyword">if</span> ~exist(<span class="string">'key'</span>, <span class="string">'var'</span>)
0075             <span class="keyword">if</span> ~exist(<span class="string">'storedb'</span>, <span class="string">'var'</span>)
0076                 storedb = <a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>();
0077             <span class="keyword">end</span>
0078             key = storedb.getNewKey();
0079         <span class="keyword">end</span>
0080         gradfd = <a href="#_sub2" class="code" title="subfunction gradfd = gradientFD(stepsize, subspacedim, problem, x, storedb, key)">gradientFD</a>(stepsize, subspacedim, problem, x, storedb, key);
0081     <span class="keyword">end</span>
0082     
0083 <span class="keyword">end</span>
0084 
0085 
0086 <a name="_sub2" href="#_subfunctions" class="code">function gradfd = gradientFD(stepsize, subspacedim, problem, x, storedb, key)</a>
0087 <span class="comment">% This function does the actual work.</span>
0088 <span class="comment">%</span>
0089 <span class="comment">% Original code: Nov. 1, 2016 (NB).</span>
0090     
0091     <span class="comment">% Evaluate the cost at the root point</span>
0092     fx = <a href="../../../manopt/core/getCost.html" class="code" title="function cost = getCost(problem, x, storedb, key)">getCost</a>(problem, x, storedb, key);
0093 
0094     <span class="comment">% Pick an orthonormal basis for the tangent space at x, or a subspace</span>
0095     <span class="comment">% thereof. The default is a full subspace. If a strict subspace is</span>
0096     <span class="comment">% picked, the returned vector approximates the orthogonal projection of</span>
0097     <span class="comment">% the gradient to that subspace.</span>
0098     B = <a href="../../../manopt/tools/tangentorthobasis.html" class="code" title="function orthobasis = tangentorthobasis(M, x, n)">tangentorthobasis</a>(problem.M, x, subspacedim);
0099     
0100     <span class="comment">% Use finite differences to approximate the directional derivative</span>
0101     <span class="comment">% along each direction in the basis B.</span>
0102     df = zeros(size(B));
0103     <span class="keyword">for</span> k = 1 : numel(B)
0104         <span class="comment">% Move in the B{k} direction</span>
0105         xk = problem.M.retr(x, B{k}, stepsize);
0106         <span class="comment">% Evaluate the cost there</span>
0107         fxk = <a href="../../../manopt/core/getCost.html" class="code" title="function cost = getCost(problem, x, storedb, key)">getCost</a>(problem, xk, storedb);
0108         <span class="comment">% Finite difference</span>
0109         df(k) = (fxk - fx)/stepsize;
0110     <span class="keyword">end</span>
0111     
0112     <span class="comment">% Build the gradient approximation.</span>
0113     gradfd = <a href="../../../manopt/tools/lincomb.html" class="code" title="function vec = lincomb(M, x, vecs, coeffs)">lincomb</a>(problem.M, x, B, df);
0114     
0115 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Sat 12-Nov-2016 14:11:22 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>