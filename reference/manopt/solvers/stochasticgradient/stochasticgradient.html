<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of stochasticgradient</title>
  <meta name="keywords" content="stochasticgradient">
  <meta name="description" content="Stochastic gradient (SG) minimization algorithm for Manopt.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="#">solvers</a> &gt; <a href="index.html">stochasticgradient</a> &gt; stochasticgradient.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../index.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\solvers\stochasticgradient&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>stochasticgradient
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>Stochastic gradient (SG) minimization algorithm for Manopt.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function [x, info, options] = stochasticgradient(problem, x, options) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Stochastic gradient (SG) minimization algorithm for Manopt.

 function [x, info, options] = stochasticgradient(problem)
 function [x, info, options] = stochasticgradient(problem, x0)
 function [x, info, options] = stochasticgradient(problem, x0, options)
 function [x, info, options] = stochasticgradient(problem, [], options)

 Apply the Riemannian stochastic gradient algorithm to the problem defined
 in the problem structure, starting at x0 if it is provided (otherwise, at
 a random point on the manifold). To specify options whilst not specifying
 an initial guess, give x0 as [] (the empty matrix).

 The problem structure must contain the following fields:

  problem.M:
       Defines the manifold to optimize over, given by a factory.

  problem.partialgrad or problem.partialegrad (or equivalent)
       Describes the partial gradients of the cost function. If the cost
       function is of the form f(x) = sum_{k=1}^N f_k(x),
       then partialegrad(x, K) = sum_{k \in K} grad f_k(x).
       As usual, partialgrad must define the Riemannian gradient, whereas
       partialegrad defines a Euclidean (classical) gradient which will be
       converted automatically to a Riemannian gradient. Use the tool
       checkgradient(problem) to check it.

  problem.ncostterms
       An integer specifying how many terms are in the cost function (in
       the example above, that would be N.)

 Importantly, the cost function itself needs not be specified.

 Some of the options of the solver are specific to this file. Please have
 a look inside the code.

 To record the value of the cost function or the norm of the gradient for
 example (which are statistics the algorithm does not require and hence
 does not compute by default), one can set the following options:

   metrics.cost = @(problem, x) getCost(problem, x);
   metrics.gradnorm = @(problem, x) problem.M.norm(x, getGradient(problem, x));
   options.statsfun = statsfunhelper(metrics);

 Important caveat: stochastic algorithms usually return an average of the
 last few iterates. Computing averages on manifolds can be expensive.
 Currently, this solver does not compute averages and simply returns the
 last iterate. Using options.statsfun, it is possible for the user to
 compute averages manually. If you have ideas on how to do this
 generically, we welcome feedback. In particular, approximate means could
 be computed with M.pairmean which is available in many geometries.

 See also: steepestdescent</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../../manopt/core/applyStatsfun.html" class="code" title="function stats = applyStatsfun(problem, x, storedb, key, options, stats)">applyStatsfun</a>	Apply the statsfun function to a stats structure (for solvers).</li><li><a href="../../../manopt/core/canGetPartialGradient.html" class="code" title="function candoit = canGetPartialGradient(problem)">canGetPartialGradient</a>	Checks whether the partial gradient can be computed for a given problem.</li><li><a href="../../../manopt/core/getGlobalDefaults.html" class="code" title="function opts = getGlobalDefaults()">getGlobalDefaults</a>	Returns a structure with default option values for Manopt.</li><li><a href="../../../manopt/core/getPartialGradient.html" class="code" title="function grad = getPartialGradient(problem, x, I, storedb, key)">getPartialGradient</a>	Computes the gradient of a subset of terms in the cost function at x.</li><li><a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts1, opts2)">mergeOptions</a>	Merges two options structures with one having precedence over the other.</li><li><a href="../../../manopt/core/stoppingcriterion.html" class="code" title="function [stop, reason] = stoppingcriterion(problem, x, options, info, last)">stoppingcriterion</a>	Checks for standard stopping criteria, as a helper to solvers.</li><li><a href="stepsize_sg.html" class="code" title="function [stepsize, newx, newkey, ssstats] =stepsize_sg(problem, x, d, iter, options, storedb, key) %#ok<INUSD>">stepsize_sg</a>	Standard step size selection algorithm for the stochastic gradient method</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../examples/PCA_stochastic.html" class="code" title="function [X, A] = PCA_stochastic(A, k)">PCA_stochastic</a>	Example of stochastic gradient algorithm in Manopt on a PCA problem.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function stats = savestats()</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [x, info, options] = stochasticgradient(problem, x, options)</a>
0002 <span class="comment">% Stochastic gradient (SG) minimization algorithm for Manopt.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function [x, info, options] = stochasticgradient(problem)</span>
0005 <span class="comment">% function [x, info, options] = stochasticgradient(problem, x0)</span>
0006 <span class="comment">% function [x, info, options] = stochasticgradient(problem, x0, options)</span>
0007 <span class="comment">% function [x, info, options] = stochasticgradient(problem, [], options)</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% Apply the Riemannian stochastic gradient algorithm to the problem defined</span>
0010 <span class="comment">% in the problem structure, starting at x0 if it is provided (otherwise, at</span>
0011 <span class="comment">% a random point on the manifold). To specify options whilst not specifying</span>
0012 <span class="comment">% an initial guess, give x0 as [] (the empty matrix).</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% The problem structure must contain the following fields:</span>
0015 <span class="comment">%</span>
0016 <span class="comment">%  problem.M:</span>
0017 <span class="comment">%       Defines the manifold to optimize over, given by a factory.</span>
0018 <span class="comment">%</span>
0019 <span class="comment">%  problem.partialgrad or problem.partialegrad (or equivalent)</span>
0020 <span class="comment">%       Describes the partial gradients of the cost function. If the cost</span>
0021 <span class="comment">%       function is of the form f(x) = sum_{k=1}^N f_k(x),</span>
0022 <span class="comment">%       then partialegrad(x, K) = sum_{k \in K} grad f_k(x).</span>
0023 <span class="comment">%       As usual, partialgrad must define the Riemannian gradient, whereas</span>
0024 <span class="comment">%       partialegrad defines a Euclidean (classical) gradient which will be</span>
0025 <span class="comment">%       converted automatically to a Riemannian gradient. Use the tool</span>
0026 <span class="comment">%       checkgradient(problem) to check it.</span>
0027 <span class="comment">%</span>
0028 <span class="comment">%  problem.ncostterms</span>
0029 <span class="comment">%       An integer specifying how many terms are in the cost function (in</span>
0030 <span class="comment">%       the example above, that would be N.)</span>
0031 <span class="comment">%</span>
0032 <span class="comment">% Importantly, the cost function itself needs not be specified.</span>
0033 <span class="comment">%</span>
0034 <span class="comment">% Some of the options of the solver are specific to this file. Please have</span>
0035 <span class="comment">% a look inside the code.</span>
0036 <span class="comment">%</span>
0037 <span class="comment">% To record the value of the cost function or the norm of the gradient for</span>
0038 <span class="comment">% example (which are statistics the algorithm does not require and hence</span>
0039 <span class="comment">% does not compute by default), one can set the following options:</span>
0040 <span class="comment">%</span>
0041 <span class="comment">%   metrics.cost = @(problem, x) getCost(problem, x);</span>
0042 <span class="comment">%   metrics.gradnorm = @(problem, x) problem.M.norm(x, getGradient(problem, x));</span>
0043 <span class="comment">%   options.statsfun = statsfunhelper(metrics);</span>
0044 <span class="comment">%</span>
0045 <span class="comment">% Important caveat: stochastic algorithms usually return an average of the</span>
0046 <span class="comment">% last few iterates. Computing averages on manifolds can be expensive.</span>
0047 <span class="comment">% Currently, this solver does not compute averages and simply returns the</span>
0048 <span class="comment">% last iterate. Using options.statsfun, it is possible for the user to</span>
0049 <span class="comment">% compute averages manually. If you have ideas on how to do this</span>
0050 <span class="comment">% generically, we welcome feedback. In particular, approximate means could</span>
0051 <span class="comment">% be computed with M.pairmean which is available in many geometries.</span>
0052 <span class="comment">%</span>
0053 <span class="comment">% See also: steepestdescent</span>
0054 
0055 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0056 <span class="comment">% Original authors: Bamdev Mishra &lt;bamdevm@gmail.com&gt;,</span>
0057 <span class="comment">%                   Hiroyuki Kasai &lt;kasai@is.uec.ac.jp&gt;, and</span>
0058 <span class="comment">%                   Hiroyuki Sato &lt;hsato@ms.kagu.tus.ac.jp&gt;, 22 April 2016.</span>
0059 <span class="comment">% Contributors: Nicolas Boumal</span>
0060 <span class="comment">% Change log:</span>
0061     
0062 
0063     <span class="comment">% Verify that the problem description is sufficient for the solver.</span>
0064     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetPartialGradient.html" class="code" title="function candoit = canGetPartialGradient(problem)">canGetPartialGradient</a>(problem)
0065         warning(<span class="string">'manopt:getPartialGradient'</span>, <span class="keyword">...</span>
0066          <span class="string">'No partial gradient provided. The algorithm will likely abort.'</span>);
0067     <span class="keyword">end</span>
0068     
0069    
0070     <span class="comment">% Set local default</span>
0071     localdefaults.maxiter = 1000;       <span class="comment">% Maximum number of iterations</span>
0072     localdefaults.batchsize = 1;        <span class="comment">% Batchsize (# cost terms per iter)</span>
0073     localdefaults.verbosity = 2;        <span class="comment">% Output verbosity (0, 1 or 2)</span>
0074     localdefaults.storedepth = 20;      <span class="comment">% Limit amount of caching</span>
0075     
0076     <span class="comment">% Check stopping criteria and save stats every checkperiod iterations.</span>
0077     localdefaults.checkperiod = 100;
0078     
0079     <span class="comment">% stepsizefun is a function implementing a step size selection</span>
0080     <span class="comment">% algorithm. See that function for help with options, which can be</span>
0081     <span class="comment">% specified in the options structure passed to the solver directly.</span>
0082     localdefaults.stepsizefun = @<a href="stepsize_sg.html" class="code" title="function [stepsize, newx, newkey, ssstats] =stepsize_sg(problem, x, d, iter, options, storedb, key) %#ok<INUSD>">stepsize_sg</a>;
0083     
0084     <span class="comment">% Merge global and local defaults, then merge w/ user options, if any.</span>
0085     localdefaults = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts1, opts2)">mergeOptions</a>(<a href="../../../manopt/core/getGlobalDefaults.html" class="code" title="function opts = getGlobalDefaults()">getGlobalDefaults</a>(), localdefaults);
0086     <span class="keyword">if</span> ~exist(<span class="string">'options'</span>, <span class="string">'var'</span>) || isempty(options)
0087         options = struct();
0088     <span class="keyword">end</span>
0089     options = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts1, opts2)">mergeOptions</a>(localdefaults, options);
0090     
0091     
0092     assert(options.checkperiod &gt;= 1, <span class="keyword">...</span>
0093                  <span class="string">'options.checkperiod must be a positive integer (&gt;= 1).'</span>);
0094     
0095     
0096     <span class="comment">% If no initial point x is given by the user, generate one at random.</span>
0097     <span class="keyword">if</span> ~exist(<span class="string">'x'</span>, <span class="string">'var'</span>) || isempty(x)
0098         x = problem.M.rand();
0099     <span class="keyword">end</span>
0100     
0101     <span class="comment">% Create a store database and get a key for the current x</span>
0102     storedb = <a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>(options.storedepth);
0103     key = storedb.getNewKey();
0104     
0105     
0106     <span class="comment">% Elapsed time for the current set of iterations, where a set of</span>
0107     <span class="comment">% iterations comprises options.checkperiod iterations. We do not</span>
0108     <span class="comment">% count time spent for such things as logging statistics, as these are</span>
0109     <span class="comment">% not relevant to the actual optimization process.</span>
0110     elapsed_time = 0;
0111     
0112     <span class="comment">% Total number of completed steps</span>
0113     iter = 0;
0114     
0115     
0116     <span class="comment">% Total number of saved stats at this point.</span>
0117     savedstats = 0;
0118     
0119     <span class="comment">% Collect and save stats in a struct array info, and preallocate.</span>
0120     stats = <a href="#_sub1" class="code" title="subfunction stats = savestats()">savestats</a>();
0121     info(1) = stats;
0122     savedstats = savedstats + 1;
0123     <span class="keyword">if</span> isinf(options.maxiter)
0124         <span class="comment">% We trust that if the user set maxiter = inf, then they defined</span>
0125         <span class="comment">% another stopping criterion.</span>
0126         preallocate = 1e5;
0127     <span class="keyword">else</span>
0128         preallocate = ceil(options.maxiter / options.checkperiod) + 1;
0129     <span class="keyword">end</span>
0130     info(preallocate).iter = [];
0131     
0132     
0133     <span class="comment">% Display information header for the user.</span>
0134     <span class="keyword">if</span> options.verbosity &gt;= 2
0135         fprintf(<span class="string">'    iter       time [s]       step size\n'</span>);
0136     <span class="keyword">end</span>
0137     
0138     
0139     <span class="comment">% Main loop.</span>
0140     stop = false;
0141     <span class="keyword">while</span> iter &lt; options.maxiter
0142         
0143         <span class="comment">% Record start time.</span>
0144         start_time = tic();
0145         
0146         <span class="comment">% Draw the samples with replacement.</span>
0147         idx_batch = randi(problem.ncostterms, options.batchsize, 1);
0148         
0149         <span class="comment">% Compute partial gradient on this batch.</span>
0150         pgrad = <a href="../../../manopt/core/getPartialGradient.html" class="code" title="function grad = getPartialGradient(problem, x, I, storedb, key)">getPartialGradient</a>(problem, x, idx_batch, storedb, key);
0151         
0152         <span class="comment">% Compute a step size and the corresponding new point x.</span>
0153         [stepsize, newx, newkey, ssstats] = <span class="keyword">...</span>
0154                            options.stepsizefun(problem, x, pgrad, iter, <span class="keyword">...</span>
0155                                                options, storedb, key);
0156         
0157         <span class="comment">% Make the step.</span>
0158         x = newx;
0159         key = newkey;
0160         
0161         <span class="comment">% Total number of completed steps.</span>
0162         iter = iter + 1;
0163         
0164         <span class="comment">% Make sure we do not use too much memory for the store database.</span>
0165         storedb.purge();
0166         
0167         <span class="comment">% Elapsed time doing actual optimization work so far in this</span>
0168         <span class="comment">% set of options.checkperiod iterations.</span>
0169         elapsed_time = elapsed_time + toc(start_time);
0170         
0171         
0172         <span class="comment">% Check stopping criteria and save stats every checkperiod iters.</span>
0173         <span class="keyword">if</span> mod(iter, options.checkperiod) == 0
0174             
0175             <span class="comment">% Log statistics for freshly executed iteration.</span>
0176             stats = <a href="#_sub1" class="code" title="subfunction stats = savestats()">savestats</a>();
0177             info(savedstats+1) = stats;
0178             savedstats = savedstats + 1;
0179             
0180             <span class="comment">% Reset timer.</span>
0181             elapsed_time = 0;
0182             
0183             <span class="comment">% Print output.</span>
0184             <span class="keyword">if</span> options.verbosity &gt;= 2
0185                 fprintf(<span class="string">'%8d     %10.2f       %.3e\n'</span>, <span class="keyword">...</span>
0186                                                iter, stats.time, stepsize);
0187             <span class="keyword">end</span>
0188             
0189             <span class="comment">% Run standard stopping criterion checks.</span>
0190             [stop, reason] = <a href="../../../manopt/core/stoppingcriterion.html" class="code" title="function [stop, reason] = stoppingcriterion(problem, x, options, info, last)">stoppingcriterion</a>(problem, x, <span class="keyword">...</span>
0191                                                options, info, savedstats);
0192             <span class="keyword">if</span> stop
0193                 <span class="keyword">if</span> options.verbosity &gt;= 1
0194                     fprintf([reason <span class="string">'\n'</span>]);
0195                 <span class="keyword">end</span>
0196                 <span class="keyword">break</span>;
0197             <span class="keyword">end</span>
0198         
0199         <span class="keyword">end</span>
0200 
0201     <span class="keyword">end</span>
0202     
0203     
0204     <span class="comment">% Keep only the relevant portion of the info struct-array.</span>
0205     info = info(1:savedstats);
0206     
0207     
0208     <span class="comment">% Display a final information message.</span>
0209     <span class="keyword">if</span> options.verbosity &gt;= 1
0210         <span class="keyword">if</span> ~stop
0211             <span class="comment">% We stopped not because of stoppingcriterion but because the</span>
0212             <span class="comment">% loop came to an end, which means maxiter triggered.</span>
0213             msg = <span class="string">'Max iteration count reached; options.maxiter = %g.\n'</span>;
0214             fprintf(msg, options.maxiter);
0215         <span class="keyword">end</span>
0216         fprintf(<span class="string">'Total time is %f [s] (excludes statsfun)\n'</span>, <span class="keyword">...</span>
0217                 info(end).time + elapsed_time);
0218     <span class="keyword">end</span>
0219     
0220     
0221     <span class="comment">% Helper function to collect statistics to be saved at</span>
0222     <span class="comment">% index checkperiodcount+1 in info.</span>
0223     <a name="_sub1" href="#_subfunctions" class="code">function stats = savestats()</a>
0224         stats.iter = iter;
0225         <span class="keyword">if</span> savedstats == 0
0226             stats.time = 0;
0227             stats.stepsize = NaN;
0228             stats.stepsize_stats = [];
0229         <span class="keyword">else</span>
0230             stats.time = info(savedstats).time + elapsed_time;
0231             stats.stepsize = stepsize;
0232             stats.stepsize_stats = ssstats;
0233         <span class="keyword">end</span>
0234         stats = <a href="../../../manopt/core/applyStatsfun.html" class="code" title="function stats = applyStatsfun(problem, x, storedb, key, options, stats)">applyStatsfun</a>(problem, x, storedb, key, options, stats);
0235     <span class="keyword">end</span>
0236     
0237 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Fri 08-Sep-2017 12:43:19 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>