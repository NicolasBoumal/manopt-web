<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of stochasticgradient</title>
  <meta name="keywords" content="stochasticgradient">
  <meta name="description" content="Stochastic gradient (SG) minimization algorithm for Manopt.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="#">solvers</a> &gt; <a href="index.html">stochasticgradient</a> &gt; stochasticgradient.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../index.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\solvers\stochasticgradient&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>stochasticgradient
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>Stochastic gradient (SG) minimization algorithm for Manopt.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function [x, info, options] = stochasticgradient(problem, x, options) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Stochastic gradient (SG) minimization algorithm for Manopt.

 function [x, info, options] = stochasticgradient(problem)
 function [x, info, options] = stochasticgradient(problem, x0)
 function [x, info, options] = stochasticgradient(problem, x0, options)
 function [x, info, options] = stochasticgradient(problem, [], options)

 Apply the Riemannian stochastic gradient algorithm to the problem defined
 in the problem structure, starting at x0 if it is provided (otherwise, at
 a random point on the manifold). To specify options whilst not specifying
 an initial guess, give x0 as [] (the empty matrix).

 The problem structure must contain the following fields:

  problem.M:
       Defines the manifold to optimize over, given by a factory.

  problem.partialgrad or problem.partialegrad (or equivalent)
       Describes the partial gradients of the cost function. If the cost
       function is of the form f(x) = sum_{k=1}^N f_k(x),
       then partialegrad(x, K) = sum_{k \in K} grad f_k(x).
       As usual, partialgrad must define the Riemannian gradient, whereas
       partialegrad defines a Euclidean (classical) gradient which will be
       converted automatically to a Riemannian gradient. Use the tool
       checkgradient(problem) to check it. K is a /row/ vector, which
       makes it natural to write for k = K, ..., end.

  problem.ncostterms
       An integer specifying how many terms are in the cost function (in
       the example above, that would be N.)

 Importantly, the cost function itself needs not be specified.

 Some of the options of the solver are specific to this file. Please have
 a look inside the code.

 To record the value of the cost function or the norm of the gradient for
 example (which are statistics the algorithm does not require and hence
 does not compute by default), one can set the following options:

   metrics.cost = @(problem, x) getCost(problem, x);
   metrics.gradnorm = @(problem, x) problem.M.norm(x, getGradient(problem, x));
   options.statsfun = statsfunhelper(metrics);

 Important caveat: stochastic algorithms usually return an average of the
 last few iterates. Computing averages on manifolds can be expensive.
 Currently, this solver does not compute averages and simply returns the
 last iterate. Using options.statsfun, it is possible for the user to
 compute averages manually. If you have ideas on how to do this
 generically, we welcome feedback. In particular, approximate means could
 be computed with M.pairmean which is available in many geometries.

 See also: steepestdescent</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../../manopt/core/applyStatsfun.html" class="code" title="function stats = applyStatsfun(problem, x, storedb, key, options, stats)">applyStatsfun</a>	Apply the statsfun function to a stats structure (for solvers).</li><li><a href="../../../manopt/core/canGetPartialGradient.html" class="code" title="function candoit = canGetPartialGradient(problem)">canGetPartialGradient</a>	Checks whether the partial gradient can be computed for a given problem.</li><li><a href="../../../manopt/core/getGlobalDefaults.html" class="code" title="function opts = getGlobalDefaults()">getGlobalDefaults</a>	Returns a structure with default option values for Manopt.</li><li><a href="../../../manopt/core/getPartialGradient.html" class="code" title="function grad = getPartialGradient(problem, x, I, storedb, key)">getPartialGradient</a>	Computes the gradient of a subset of terms in the cost function at x.</li><li><a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>	Merges two options structures with one having precedence over the other.</li><li><a href="../../../manopt/core/stoppingcriterion.html" class="code" title="function [stop, reason] = stoppingcriterion(problem, x, options, info, last)">stoppingcriterion</a>	Checks for standard stopping criteria, as a helper to solvers.</li><li><a href="stepsize_sg.html" class="code" title="function [stepsize, newx, newkey, ssstats] =stepsize_sg(problem, x, d, iter, options, storedb, key) %#ok<INUSD>">stepsize_sg</a>	Standard step size selection algorithm for the stochastic gradient method</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../examples/PCA_stochastic.html" class="code" title="function [X, A] = PCA_stochastic(A, k)">PCA_stochastic</a>	Example of stochastic gradient algorithm in Manopt on a PCA problem.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function stats = savestats()</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [x, info, options] = stochasticgradient(problem, x, options)</a>
0002 <span class="comment">% Stochastic gradient (SG) minimization algorithm for Manopt.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function [x, info, options] = stochasticgradient(problem)</span>
0005 <span class="comment">% function [x, info, options] = stochasticgradient(problem, x0)</span>
0006 <span class="comment">% function [x, info, options] = stochasticgradient(problem, x0, options)</span>
0007 <span class="comment">% function [x, info, options] = stochasticgradient(problem, [], options)</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% Apply the Riemannian stochastic gradient algorithm to the problem defined</span>
0010 <span class="comment">% in the problem structure, starting at x0 if it is provided (otherwise, at</span>
0011 <span class="comment">% a random point on the manifold). To specify options whilst not specifying</span>
0012 <span class="comment">% an initial guess, give x0 as [] (the empty matrix).</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% The problem structure must contain the following fields:</span>
0015 <span class="comment">%</span>
0016 <span class="comment">%  problem.M:</span>
0017 <span class="comment">%       Defines the manifold to optimize over, given by a factory.</span>
0018 <span class="comment">%</span>
0019 <span class="comment">%  problem.partialgrad or problem.partialegrad (or equivalent)</span>
0020 <span class="comment">%       Describes the partial gradients of the cost function. If the cost</span>
0021 <span class="comment">%       function is of the form f(x) = sum_{k=1}^N f_k(x),</span>
0022 <span class="comment">%       then partialegrad(x, K) = sum_{k \in K} grad f_k(x).</span>
0023 <span class="comment">%       As usual, partialgrad must define the Riemannian gradient, whereas</span>
0024 <span class="comment">%       partialegrad defines a Euclidean (classical) gradient which will be</span>
0025 <span class="comment">%       converted automatically to a Riemannian gradient. Use the tool</span>
0026 <span class="comment">%       checkgradient(problem) to check it. K is a /row/ vector, which</span>
0027 <span class="comment">%       makes it natural to write for k = K, ..., end.</span>
0028 <span class="comment">%</span>
0029 <span class="comment">%  problem.ncostterms</span>
0030 <span class="comment">%       An integer specifying how many terms are in the cost function (in</span>
0031 <span class="comment">%       the example above, that would be N.)</span>
0032 <span class="comment">%</span>
0033 <span class="comment">% Importantly, the cost function itself needs not be specified.</span>
0034 <span class="comment">%</span>
0035 <span class="comment">% Some of the options of the solver are specific to this file. Please have</span>
0036 <span class="comment">% a look inside the code.</span>
0037 <span class="comment">%</span>
0038 <span class="comment">% To record the value of the cost function or the norm of the gradient for</span>
0039 <span class="comment">% example (which are statistics the algorithm does not require and hence</span>
0040 <span class="comment">% does not compute by default), one can set the following options:</span>
0041 <span class="comment">%</span>
0042 <span class="comment">%   metrics.cost = @(problem, x) getCost(problem, x);</span>
0043 <span class="comment">%   metrics.gradnorm = @(problem, x) problem.M.norm(x, getGradient(problem, x));</span>
0044 <span class="comment">%   options.statsfun = statsfunhelper(metrics);</span>
0045 <span class="comment">%</span>
0046 <span class="comment">% Important caveat: stochastic algorithms usually return an average of the</span>
0047 <span class="comment">% last few iterates. Computing averages on manifolds can be expensive.</span>
0048 <span class="comment">% Currently, this solver does not compute averages and simply returns the</span>
0049 <span class="comment">% last iterate. Using options.statsfun, it is possible for the user to</span>
0050 <span class="comment">% compute averages manually. If you have ideas on how to do this</span>
0051 <span class="comment">% generically, we welcome feedback. In particular, approximate means could</span>
0052 <span class="comment">% be computed with M.pairmean which is available in many geometries.</span>
0053 <span class="comment">%</span>
0054 <span class="comment">% See also: steepestdescent</span>
0055 
0056 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0057 <span class="comment">% Original authors: Bamdev Mishra &lt;bamdevm@gmail.com&gt;,</span>
0058 <span class="comment">%                   Hiroyuki Kasai &lt;kasai@is.uec.ac.jp&gt;, and</span>
0059 <span class="comment">%                   Hiroyuki Sato &lt;hsato@ms.kagu.tus.ac.jp&gt;, 22 April 2016.</span>
0060 <span class="comment">% Contributors: Nicolas Boumal</span>
0061 <span class="comment">% Change log:</span>
0062     
0063 
0064     <span class="comment">% Verify that the problem description is sufficient for the solver.</span>
0065     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetPartialGradient.html" class="code" title="function candoit = canGetPartialGradient(problem)">canGetPartialGradient</a>(problem)
0066         warning(<span class="string">'manopt:getPartialGradient'</span>, <span class="keyword">...</span>
0067          <span class="string">'No partial gradient provided. The algorithm will likely abort.'</span>);
0068     <span class="keyword">end</span>
0069     
0070    
0071     <span class="comment">% Set local default</span>
0072     localdefaults.maxiter = 1000;       <span class="comment">% Maximum number of iterations</span>
0073     localdefaults.batchsize = 1;        <span class="comment">% Batchsize (# cost terms per iter)</span>
0074     localdefaults.verbosity = 2;        <span class="comment">% Output verbosity (0, 1 or 2)</span>
0075     localdefaults.storedepth = 20;      <span class="comment">% Limit amount of caching</span>
0076     
0077     <span class="comment">% Check stopping criteria and save stats every checkperiod iterations.</span>
0078     localdefaults.checkperiod = 100;
0079     
0080     <span class="comment">% stepsizefun is a function implementing a step size selection</span>
0081     <span class="comment">% algorithm. See that function for help with options, which can be</span>
0082     <span class="comment">% specified in the options structure passed to the solver directly.</span>
0083     localdefaults.stepsizefun = @<a href="stepsize_sg.html" class="code" title="function [stepsize, newx, newkey, ssstats] =stepsize_sg(problem, x, d, iter, options, storedb, key) %#ok<INUSD>">stepsize_sg</a>;
0084     
0085     <span class="comment">% Merge global and local defaults, then merge w/ user options, if any.</span>
0086     localdefaults = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>(<a href="../../../manopt/core/getGlobalDefaults.html" class="code" title="function opts = getGlobalDefaults()">getGlobalDefaults</a>(), localdefaults);
0087     <span class="keyword">if</span> ~exist(<span class="string">'options'</span>, <span class="string">'var'</span>) || isempty(options)
0088         options = struct();
0089     <span class="keyword">end</span>
0090     options = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>(localdefaults, options);
0091     
0092     
0093     assert(options.checkperiod &gt;= 1, <span class="keyword">...</span>
0094                  <span class="string">'options.checkperiod must be a positive integer (&gt;= 1).'</span>);
0095     
0096     
0097     <span class="comment">% If no initial point x is given by the user, generate one at random.</span>
0098     <span class="keyword">if</span> ~exist(<span class="string">'x'</span>, <span class="string">'var'</span>) || isempty(x)
0099         x = problem.M.rand();
0100     <span class="keyword">end</span>
0101     
0102     <span class="comment">% Create a store database and get a key for the current x</span>
0103     storedb = <a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>(options.storedepth);
0104     key = storedb.getNewKey();
0105     
0106     
0107     <span class="comment">% Elapsed time for the current set of iterations, where a set of</span>
0108     <span class="comment">% iterations comprises options.checkperiod iterations. We do not</span>
0109     <span class="comment">% count time spent for such things as logging statistics, as these are</span>
0110     <span class="comment">% not relevant to the actual optimization process.</span>
0111     elapsed_time = 0;
0112     
0113     <span class="comment">% Total number of completed steps</span>
0114     iter = 0;
0115     
0116     
0117     <span class="comment">% Total number of saved stats at this point.</span>
0118     savedstats = 0;
0119     
0120     <span class="comment">% Collect and save stats in a struct array info, and preallocate.</span>
0121     stats = <a href="#_sub1" class="code" title="subfunction stats = savestats()">savestats</a>();
0122     info(1) = stats;
0123     savedstats = savedstats + 1;
0124     <span class="keyword">if</span> isinf(options.maxiter)
0125         <span class="comment">% We trust that if the user set maxiter = inf, then they defined</span>
0126         <span class="comment">% another stopping criterion.</span>
0127         preallocate = 1e5;
0128     <span class="keyword">else</span>
0129         preallocate = ceil(options.maxiter / options.checkperiod) + 1;
0130     <span class="keyword">end</span>
0131     info(preallocate).iter = [];
0132     
0133     
0134     <span class="comment">% Display information header for the user.</span>
0135     <span class="keyword">if</span> options.verbosity &gt;= 2
0136         fprintf(<span class="string">'    iter       time [s]       step size\n'</span>);
0137     <span class="keyword">end</span>
0138     
0139     
0140     <span class="comment">% Main loop.</span>
0141     stop = false;
0142     <span class="keyword">while</span> iter &lt; options.maxiter
0143         
0144         <span class="comment">% Record start time.</span>
0145         start_time = tic();
0146         
0147         <span class="comment">% Draw the samples with replacement.</span>
0148         idx_batch = randi(problem.ncostterms, options.batchsize, 1);
0149         
0150         <span class="comment">% Compute partial gradient on this batch.</span>
0151         pgrad = <a href="../../../manopt/core/getPartialGradient.html" class="code" title="function grad = getPartialGradient(problem, x, I, storedb, key)">getPartialGradient</a>(problem, x, idx_batch, storedb, key);
0152         
0153         <span class="comment">% Compute a step size and the corresponding new point x.</span>
0154         [stepsize, newx, newkey, ssstats] = <span class="keyword">...</span>
0155                            options.stepsizefun(problem, x, pgrad, iter, <span class="keyword">...</span>
0156                                                options, storedb, key);
0157         
0158         <span class="comment">% Make the step: transfer iterate, remove cache from previous x.</span>
0159         storedb.removefirstifdifferent(key, newkey);
0160         x = newx;
0161         key = newkey;
0162         
0163         <span class="comment">% Make sure we do not use too much memory for the store database.</span>
0164         storedb.purge();
0165         
0166         <span class="comment">% Total number of completed steps.</span>
0167         iter = iter + 1;
0168         
0169         <span class="comment">% Elapsed time doing actual optimization work so far in this</span>
0170         <span class="comment">% set of options.checkperiod iterations.</span>
0171         elapsed_time = elapsed_time + toc(start_time);
0172         
0173         
0174         <span class="comment">% Check stopping criteria and save stats every checkperiod iters.</span>
0175         <span class="keyword">if</span> mod(iter, options.checkperiod) == 0
0176             
0177             <span class="comment">% Log statistics for freshly executed iteration.</span>
0178             stats = <a href="#_sub1" class="code" title="subfunction stats = savestats()">savestats</a>();
0179             info(savedstats+1) = stats;
0180             savedstats = savedstats + 1;
0181             
0182             <span class="comment">% Reset timer.</span>
0183             elapsed_time = 0;
0184             
0185             <span class="comment">% Print output.</span>
0186             <span class="keyword">if</span> options.verbosity &gt;= 2
0187                 fprintf(<span class="string">'%8d     %10.2f       %.3e\n'</span>, <span class="keyword">...</span>
0188                                                iter, stats.time, stepsize);
0189             <span class="keyword">end</span>
0190             
0191             <span class="comment">% Run standard stopping criterion checks.</span>
0192             [stop, reason] = <a href="../../../manopt/core/stoppingcriterion.html" class="code" title="function [stop, reason] = stoppingcriterion(problem, x, options, info, last)">stoppingcriterion</a>(problem, x, <span class="keyword">...</span>
0193                                                options, info, savedstats);
0194             <span class="keyword">if</span> stop
0195                 <span class="keyword">if</span> options.verbosity &gt;= 1
0196                     fprintf([reason <span class="string">'\n'</span>]);
0197                 <span class="keyword">end</span>
0198                 <span class="keyword">break</span>;
0199             <span class="keyword">end</span>
0200         
0201         <span class="keyword">end</span>
0202 
0203     <span class="keyword">end</span>
0204     
0205     
0206     <span class="comment">% Keep only the relevant portion of the info struct-array.</span>
0207     info = info(1:savedstats);
0208     
0209     
0210     <span class="comment">% Display a final information message.</span>
0211     <span class="keyword">if</span> options.verbosity &gt;= 1
0212         <span class="keyword">if</span> ~stop
0213             <span class="comment">% We stopped not because of stoppingcriterion but because the</span>
0214             <span class="comment">% loop came to an end, which means maxiter triggered.</span>
0215             msg = <span class="string">'Max iteration count reached; options.maxiter = %g.\n'</span>;
0216             fprintf(msg, options.maxiter);
0217         <span class="keyword">end</span>
0218         fprintf(<span class="string">'Total time is %f [s] (excludes statsfun)\n'</span>, <span class="keyword">...</span>
0219                 info(end).time + elapsed_time);
0220     <span class="keyword">end</span>
0221     
0222     
0223     <span class="comment">% Helper function to collect statistics to be saved at</span>
0224     <span class="comment">% index checkperiodcount+1 in info.</span>
0225     <a name="_sub1" href="#_subfunctions" class="code">function stats = savestats()</a>
0226         stats.iter = iter;
0227         <span class="keyword">if</span> savedstats == 0
0228             stats.time = 0;
0229             stats.stepsize = NaN;
0230             stats.stepsize_stats = [];
0231         <span class="keyword">else</span>
0232             stats.time = info(savedstats).time + elapsed_time;
0233             stats.stepsize = stepsize;
0234             stats.stepsize_stats = ssstats;
0235         <span class="keyword">end</span>
0236         stats = <a href="../../../manopt/core/applyStatsfun.html" class="code" title="function stats = applyStatsfun(problem, x, storedb, key, options, stats)">applyStatsfun</a>(problem, x, storedb, key, options, stats);
0237     <span class="keyword">end</span>
0238     
0239 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Mon 10-Sep-2018 11:48:06 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>