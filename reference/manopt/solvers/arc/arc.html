<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of arc</title>
  <meta name="keywords" content="arc">
  <meta name="description" content="Adaptive regularization by cubics (ARC) minimization algorithm for Manopt">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="#">solvers</a> &gt; <a href="index.html">arc</a> &gt; arc.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../index.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\solvers\arc&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>arc
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>Adaptive regularization by cubics (ARC) minimization algorithm for Manopt</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function [x, cost, info, options] = arc(problem, x, options) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Adaptive regularization by cubics (ARC) minimization algorithm for Manopt

 function [x, cost, info, options] = arc(problem)
 function [x, cost, info, options] = arc(problem, x0)
 function [x, cost, info, options] = arc(problem, x0, options)
 function [x, cost, info, options] = arc(problem, [], options)

 Apply the ARC minimization algorithm to the problem defined in the
 problem structure, starting at x0 if it is provided (otherwise, at a
 random point on the manifold). To specify options whilst not specifying
 an initial guess, give x0 as [] (the empty matrix).

 In most of the examples bundled with the toolbox (see link below), the
 solver can be replaced by the present one as is.

 With the default subproblem solver (@arc_conjugate_gradient), tuning
 parameter options.theta properly appears important for performance.
 Users may want to try different values in the range 1e-3 to 1e3 for a
 particular application.

 The outputs x and cost are the last reached point on the manifold and its
 cost. The struct-array info contains information about the iterations:
   iter (integer)
       The (outer) iteration number, i.e., number of steps considered
       so far (whether accepted or rejected). The initial guess is 0.
   cost (double)
       The corresponding cost value.
   gradnorm (double)
       The (Riemannian) norm of the gradient.
   hessiancalls (integer)
       The number of Hessian calls issued by the subproblem solver to
       compute this iterate.
   time (double)
       The total elapsed time in seconds to reach the corresponding cost.
   rho (double)
       The regularized performance ratio for the iterate.
       See options.rho_regularization.
   rhonum, rhoden (double)
       Numerator and denominator of the performance ratio, before
       regularization.
   accepted (boolean)
       Whether the proposed iterate was accepted or not.
   stepsize (double)
       The (Riemannian) norm of the vector returned by the subproblem
       solver and which is retracted to obtain the proposed next iterate.
       If accepted = true for the corresponding iterate, this is the size
       of the step from the previous to the new iterate. If accepted is
       false, the step was not executed and this is the size of the
       rejected step.
   sigma (double)
       The cubic regularization parameter at the outer iteration.
   And possibly additional information logged by options.statsfun or by
   the subproblem solver.
 For example, type [info.gradnorm] to obtain a vector of the successive
 gradient norms reached and [info.time] to obtain a vector with the
 corresponding computation times to reach that point.

 The options structure is used to overwrite the default values. All
 options have a default value and are hence optional. To force an option
 value, pass an options structure with a field options.optionname, where
 optionname is one of the following. The default value is indicated
 between parentheses. The subproblem solver may also accept options.

   tolgradnorm (1e-6)
       The algorithm terminates if the norm of the gradient drops below this.
   maxiter (1000)
       The algorithm terminates if maxiter (outer) iterations have been executed.
   maxtime (Inf)
       The algorithm terminates if maxtime seconds elapsed.
   sigma_0 (100 / trust-regions default maximum radius)
       Initial regularization parameter.
   sigma_min (1e-7)
       Minimum regularization parameter.
   eta_1 (0.1)
       If rho is below this, the step is unsuccessful (rejected).
   eta_2 (0.9)
       If rho exceeds this, the step is very successful.
   gamma_1 (0.1)
       Shrinking factor for regularization parameter if very successful.
   gamma_2 (2)
       Expansion factor for regularization parameter if unsuccessful.
   subproblemsolver (@arc_conjugate_gradient)
       Function handle to a subproblem solver. The subproblem solver will
       also see this options structure, so that parameters can be passed
       to it through here as well. Built-in solvers included:
           arc_lanczos
           arc_conjugate_gradient
           arc_gradient_descent
   rho_regularization (1e3)
       See help for the same parameter in the trustregions solver.
   statsfun (none)
       Function handle to a function that will be called after each
       iteration to provide the opportunity to log additional statistics.
       They will be returned in the info struct. See the generic Manopt
       documentation about solvers for further information.
   stopfun (none)
       Function handle to a function that will be called at each iteration
       to provide the opportunity to specify additional stopping criteria.
       See the generic Manopt documentation about solvers for further
       information.
   verbosity (3)
       Integer number used to tune the amount of output the algorithm
       generates during execution (mostly as text in the command window).
       The higher, the more output. 0 means silent.
   storedepth (2)
       Maximum number of different points x of the manifold for which a
       store structure will be kept in memory in the storedb. If the
       caching features of Manopt are not used, this is irrelevant. As of
       version 5.0, this is not particularly important.


 Please cite the Manopt paper as well as the research paper:
 @article{agarwal2018arcfirst,
   author  = {Agarwal, N. and Boumal, N. and Bullins, B. and Cartis, C.},
   title   = {Adaptive regularization with cubics on manifolds},
   journal = {arXiv preprint arXiv:1806.00065},
   year    = {2018}
 }
 

 See also: trustregions conjugategradient manopt/examples <a href="arc_lanczos.html" class="code" title="function [eta, Heta, hesscalls, stop_str, stats] = arc_lanczos(problem, x, grad, gradnorm, sigma, options, storedb, key)">arc_lanczos</a> <a href="arc_conjugate_gradient.html" class="code" title="function [eta, Heta, hesscalls, stop_str, stats] = arc_conjugate_gradient(problem, x, grad, gradnorm, sigma, options, storedb, key)">arc_conjugate_gradient</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../../manopt/core/applyStatsfun.html" class="code" title="function stats = applyStatsfun(problem, x, storedb, key, options, stats)">applyStatsfun</a>	Apply the statsfun function to a stats structure (for solvers).</li><li><a href="../../../manopt/core/canGetApproxGradient.html" class="code" title="function candoit = canGetApproxGradient(problem)">canGetApproxGradient</a>	Checks whether an approximate gradient can be computed for this problem.</li><li><a href="../../../manopt/core/canGetApproxHessian.html" class="code" title="function candoit = canGetApproxHessian(problem)">canGetApproxHessian</a>	Checks whether an approximate Hessian can be computed for this problem.</li><li><a href="../../../manopt/core/canGetCost.html" class="code" title="function candoit = canGetCost(problem)">canGetCost</a>	Checks whether the cost function can be computed for a problem structure.</li><li><a href="../../../manopt/core/canGetGradient.html" class="code" title="function candoit = canGetGradient(problem)">canGetGradient</a>	Checks whether the gradient can be computed for a problem structure.</li><li><a href="../../../manopt/core/canGetHessian.html" class="code" title="function candoit = canGetHessian(problem)">canGetHessian</a>	Checks whether the Hessian can be computed for a problem structure.</li><li><a href="../../../manopt/core/getCostGrad.html" class="code" title="function [cost, grad] = getCostGrad(problem, x, storedb, key)">getCostGrad</a>	Computes the cost function and the gradient at x in one call if possible.</li><li><a href="../../../manopt/core/getGlobalDefaults.html" class="code" title="function opts = getGlobalDefaults()">getGlobalDefaults</a>	Returns a structure with default option values for Manopt.</li><li><a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>	Merges two options structures with one having precedence over the other.</li><li><a href="../../../manopt/core/stoppingcriterion.html" class="code" title="function [stop, reason] = stoppingcriterion(problem, x, options, info, last)">stoppingcriterion</a>	Checks for standard stopping criteria, as a helper to solvers.</li><li><a href="arc_conjugate_gradient.html" class="code" title="function [eta, Heta, hesscalls, stop_str, stats] = arc_conjugate_gradient(problem, x, grad, gradnorm, sigma, options, storedb, key)">arc_conjugate_gradient</a>	Subproblem solver for ARC based on a nonlinear conjugate gradient method.</li><li><a href="../../../manopt/solvers/gradientapproximations/approxgradientFD.html" class="code" title="function gradfun = approxgradientFD(problem, options)">approxgradientFD</a>	Gradient approx. fnctn handle based on finite differences of the cost.</li><li><a href="../../../manopt/solvers/hessianapproximations/approxhessianFD.html" class="code" title="function hessfun = approxhessianFD(problem, options)">approxhessianFD</a>	Hessian approx. fnctn handle based on finite differences of the gradient.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
</ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function stats = savestats(problem, x, storedb, key, options)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [x, cost, info, options] = arc(problem, x, options)</a>
0002 <span class="comment">% Adaptive regularization by cubics (ARC) minimization algorithm for Manopt</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function [x, cost, info, options] = arc(problem)</span>
0005 <span class="comment">% function [x, cost, info, options] = arc(problem, x0)</span>
0006 <span class="comment">% function [x, cost, info, options] = arc(problem, x0, options)</span>
0007 <span class="comment">% function [x, cost, info, options] = arc(problem, [], options)</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% Apply the ARC minimization algorithm to the problem defined in the</span>
0010 <span class="comment">% problem structure, starting at x0 if it is provided (otherwise, at a</span>
0011 <span class="comment">% random point on the manifold). To specify options whilst not specifying</span>
0012 <span class="comment">% an initial guess, give x0 as [] (the empty matrix).</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% In most of the examples bundled with the toolbox (see link below), the</span>
0015 <span class="comment">% solver can be replaced by the present one as is.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">% With the default subproblem solver (@arc_conjugate_gradient), tuning</span>
0018 <span class="comment">% parameter options.theta properly appears important for performance.</span>
0019 <span class="comment">% Users may want to try different values in the range 1e-3 to 1e3 for a</span>
0020 <span class="comment">% particular application.</span>
0021 <span class="comment">%</span>
0022 <span class="comment">% The outputs x and cost are the last reached point on the manifold and its</span>
0023 <span class="comment">% cost. The struct-array info contains information about the iterations:</span>
0024 <span class="comment">%   iter (integer)</span>
0025 <span class="comment">%       The (outer) iteration number, i.e., number of steps considered</span>
0026 <span class="comment">%       so far (whether accepted or rejected). The initial guess is 0.</span>
0027 <span class="comment">%   cost (double)</span>
0028 <span class="comment">%       The corresponding cost value.</span>
0029 <span class="comment">%   gradnorm (double)</span>
0030 <span class="comment">%       The (Riemannian) norm of the gradient.</span>
0031 <span class="comment">%   hessiancalls (integer)</span>
0032 <span class="comment">%       The number of Hessian calls issued by the subproblem solver to</span>
0033 <span class="comment">%       compute this iterate.</span>
0034 <span class="comment">%   time (double)</span>
0035 <span class="comment">%       The total elapsed time in seconds to reach the corresponding cost.</span>
0036 <span class="comment">%   rho (double)</span>
0037 <span class="comment">%       The regularized performance ratio for the iterate.</span>
0038 <span class="comment">%       See options.rho_regularization.</span>
0039 <span class="comment">%   rhonum, rhoden (double)</span>
0040 <span class="comment">%       Numerator and denominator of the performance ratio, before</span>
0041 <span class="comment">%       regularization.</span>
0042 <span class="comment">%   accepted (boolean)</span>
0043 <span class="comment">%       Whether the proposed iterate was accepted or not.</span>
0044 <span class="comment">%   stepsize (double)</span>
0045 <span class="comment">%       The (Riemannian) norm of the vector returned by the subproblem</span>
0046 <span class="comment">%       solver and which is retracted to obtain the proposed next iterate.</span>
0047 <span class="comment">%       If accepted = true for the corresponding iterate, this is the size</span>
0048 <span class="comment">%       of the step from the previous to the new iterate. If accepted is</span>
0049 <span class="comment">%       false, the step was not executed and this is the size of the</span>
0050 <span class="comment">%       rejected step.</span>
0051 <span class="comment">%   sigma (double)</span>
0052 <span class="comment">%       The cubic regularization parameter at the outer iteration.</span>
0053 <span class="comment">%   And possibly additional information logged by options.statsfun or by</span>
0054 <span class="comment">%   the subproblem solver.</span>
0055 <span class="comment">% For example, type [info.gradnorm] to obtain a vector of the successive</span>
0056 <span class="comment">% gradient norms reached and [info.time] to obtain a vector with the</span>
0057 <span class="comment">% corresponding computation times to reach that point.</span>
0058 <span class="comment">%</span>
0059 <span class="comment">% The options structure is used to overwrite the default values. All</span>
0060 <span class="comment">% options have a default value and are hence optional. To force an option</span>
0061 <span class="comment">% value, pass an options structure with a field options.optionname, where</span>
0062 <span class="comment">% optionname is one of the following. The default value is indicated</span>
0063 <span class="comment">% between parentheses. The subproblem solver may also accept options.</span>
0064 <span class="comment">%</span>
0065 <span class="comment">%   tolgradnorm (1e-6)</span>
0066 <span class="comment">%       The algorithm terminates if the norm of the gradient drops below this.</span>
0067 <span class="comment">%   maxiter (1000)</span>
0068 <span class="comment">%       The algorithm terminates if maxiter (outer) iterations have been executed.</span>
0069 <span class="comment">%   maxtime (Inf)</span>
0070 <span class="comment">%       The algorithm terminates if maxtime seconds elapsed.</span>
0071 <span class="comment">%   sigma_0 (100 / trust-regions default maximum radius)</span>
0072 <span class="comment">%       Initial regularization parameter.</span>
0073 <span class="comment">%   sigma_min (1e-7)</span>
0074 <span class="comment">%       Minimum regularization parameter.</span>
0075 <span class="comment">%   eta_1 (0.1)</span>
0076 <span class="comment">%       If rho is below this, the step is unsuccessful (rejected).</span>
0077 <span class="comment">%   eta_2 (0.9)</span>
0078 <span class="comment">%       If rho exceeds this, the step is very successful.</span>
0079 <span class="comment">%   gamma_1 (0.1)</span>
0080 <span class="comment">%       Shrinking factor for regularization parameter if very successful.</span>
0081 <span class="comment">%   gamma_2 (2)</span>
0082 <span class="comment">%       Expansion factor for regularization parameter if unsuccessful.</span>
0083 <span class="comment">%   subproblemsolver (@arc_conjugate_gradient)</span>
0084 <span class="comment">%       Function handle to a subproblem solver. The subproblem solver will</span>
0085 <span class="comment">%       also see this options structure, so that parameters can be passed</span>
0086 <span class="comment">%       to it through here as well. Built-in solvers included:</span>
0087 <span class="comment">%           arc_lanczos</span>
0088 <span class="comment">%           arc_conjugate_gradient</span>
0089 <span class="comment">%           arc_gradient_descent</span>
0090 <span class="comment">%   rho_regularization (1e3)</span>
0091 <span class="comment">%       See help for the same parameter in the trustregions solver.</span>
0092 <span class="comment">%   statsfun (none)</span>
0093 <span class="comment">%       Function handle to a function that will be called after each</span>
0094 <span class="comment">%       iteration to provide the opportunity to log additional statistics.</span>
0095 <span class="comment">%       They will be returned in the info struct. See the generic Manopt</span>
0096 <span class="comment">%       documentation about solvers for further information.</span>
0097 <span class="comment">%   stopfun (none)</span>
0098 <span class="comment">%       Function handle to a function that will be called at each iteration</span>
0099 <span class="comment">%       to provide the opportunity to specify additional stopping criteria.</span>
0100 <span class="comment">%       See the generic Manopt documentation about solvers for further</span>
0101 <span class="comment">%       information.</span>
0102 <span class="comment">%   verbosity (3)</span>
0103 <span class="comment">%       Integer number used to tune the amount of output the algorithm</span>
0104 <span class="comment">%       generates during execution (mostly as text in the command window).</span>
0105 <span class="comment">%       The higher, the more output. 0 means silent.</span>
0106 <span class="comment">%   storedepth (2)</span>
0107 <span class="comment">%       Maximum number of different points x of the manifold for which a</span>
0108 <span class="comment">%       store structure will be kept in memory in the storedb. If the</span>
0109 <span class="comment">%       caching features of Manopt are not used, this is irrelevant. As of</span>
0110 <span class="comment">%       version 5.0, this is not particularly important.</span>
0111 <span class="comment">%</span>
0112 <span class="comment">%</span>
0113 <span class="comment">% Please cite the Manopt paper as well as the research paper:</span>
0114 <span class="comment">% @article{agarwal2018arcfirst,</span>
0115 <span class="comment">%   author  = {Agarwal, N. and Boumal, N. and Bullins, B. and Cartis, C.},</span>
0116 <span class="comment">%   title   = {Adaptive regularization with cubics on manifolds},</span>
0117 <span class="comment">%   journal = {arXiv preprint arXiv:1806.00065},</span>
0118 <span class="comment">%   year    = {2018}</span>
0119 <span class="comment">% }</span>
0120 <span class="comment">%</span>
0121 <span class="comment">%</span>
0122 <span class="comment">% See also: trustregions conjugategradient manopt/examples arc_lanczos arc_conjugate_gradient</span>
0123 
0124 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0125 <span class="comment">% Original authors: May 1, 2018,</span>
0126 <span class="comment">%    Naman Agarwal, Brian Bullins, Nicolas Boumal and Coralia Cartis.</span>
0127 <span class="comment">% Contributors:</span>
0128 <span class="comment">% Change log:</span>
0129 <span class="comment">%</span>
0130 <span class="comment">%   Aug 14, 2019 (NB):</span>
0131 <span class="comment">%       Default subproblem solver for ARC is now arc_conjugate_gradient</span>
0132 <span class="comment">%       instead of arc_lanczos. Default gamma_2 changed to 2 from 5.</span>
0133 
0134     M = problem.M;
0135     
0136     <span class="comment">% Verify that the problem description is sufficient for the solver.</span>
0137     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetCost.html" class="code" title="function candoit = canGetCost(problem)">canGetCost</a>(problem)
0138         warning(<span class="string">'manopt:getCost'</span>, <span class="keyword">...</span>
0139                 <span class="string">'No cost provided. The algorithm will likely abort.'</span>);
0140     <span class="keyword">end</span>
0141     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetGradient.html" class="code" title="function candoit = canGetGradient(problem)">canGetGradient</a>(problem) &amp;&amp; ~<a href="../../../manopt/core/canGetApproxGradient.html" class="code" title="function candoit = canGetApproxGradient(problem)">canGetApproxGradient</a>(problem)
0142         <span class="comment">% Note: we do not give a warning if an approximate gradient is</span>
0143         <span class="comment">% explicitly given in the problem description, as in that case the</span>
0144         <span class="comment">% user seems to be aware of the issue.</span>
0145         warning(<span class="string">'manopt:getGradient:approx'</span>, [<span class="string">'No gradient provided. '</span> <span class="keyword">...</span>
0146                 <span class="string">'Using an FD approximation instead (slow).\n'</span> <span class="keyword">...</span>
0147                 <span class="string">'It may be necessary to increase options.tolgradnorm.\n'</span><span class="keyword">...</span>
0148                 <span class="string">'To disable this warning: '</span> <span class="keyword">...</span>
0149                 <span class="string">'warning(''off'', ''manopt:getGradient:approx'')'</span>]);
0150         problem.approxgrad = <a href="../../../manopt/solvers/gradientapproximations/approxgradientFD.html" class="code" title="function gradfun = approxgradientFD(problem, options)">approxgradientFD</a>(problem);
0151     <span class="keyword">end</span>
0152     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetHessian.html" class="code" title="function candoit = canGetHessian(problem)">canGetHessian</a>(problem) &amp;&amp; ~<a href="../../../manopt/core/canGetApproxHessian.html" class="code" title="function candoit = canGetApproxHessian(problem)">canGetApproxHessian</a>(problem)
0153         <span class="comment">% Note: we do not give a warning if an approximate Hessian is</span>
0154         <span class="comment">% explicitly given in the problem description, as in that case the</span>
0155         <span class="comment">% user seems to be aware of the issue.</span>
0156         warning(<span class="string">'manopt:getHessian:approx'</span>, [<span class="string">'No Hessian provided. '</span> <span class="keyword">...</span>
0157                 <span class="string">'Using an FD approximation instead.\n'</span> <span class="keyword">...</span>
0158                 <span class="string">'To disable this warning: '</span> <span class="keyword">...</span>
0159                 <span class="string">'warning(''off'', ''manopt:getHessian:approx'')'</span>]);
0160         problem.approxhess = <a href="../../../manopt/solvers/hessianapproximations/approxhessianFD.html" class="code" title="function hessfun = approxhessianFD(problem, options)">approxhessianFD</a>(problem);
0161     <span class="keyword">end</span>
0162 
0163     <span class="comment">% Set local defaults here</span>
0164     localdefaults.tolgradnorm = 1e-6;
0165     localdefaults.maxiter = 1000;
0166     localdefaults.maxtime = inf;
0167     localdefaults.sigma_min = 1e-7;
0168     localdefaults.eta_1 = 0.1;
0169     localdefaults.eta_2 = 0.9;
0170     localdefaults.gamma_1 = 0.1;
0171     localdefaults.gamma_2 = 2;
0172     localdefaults.storedepth = 2;
0173     localdefaults.subproblemsolver = @<a href="arc_conjugate_gradient.html" class="code" title="function [eta, Heta, hesscalls, stop_str, stats] = arc_conjugate_gradient(problem, x, grad, gradnorm, sigma, options, storedb, key)">arc_conjugate_gradient</a>;
0174     localdefaults.rho_regularization = 1e3;
0175     
0176     <span class="comment">% Merge global and local defaults, then merge w/ user options, if any.</span>
0177     localdefaults = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>(<a href="../../../manopt/core/getGlobalDefaults.html" class="code" title="function opts = getGlobalDefaults()">getGlobalDefaults</a>(), localdefaults);
0178     <span class="keyword">if</span> ~exist(<span class="string">'options'</span>, <span class="string">'var'</span>) || isempty(options)
0179         options = struct();
0180     <span class="keyword">end</span>
0181     options = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>(localdefaults, options);
0182     
0183     <span class="comment">% Default initial sigma_0 is based on the initial Delta_bar of the</span>
0184     <span class="comment">% trustregions solver.</span>
0185     <span class="keyword">if</span> ~isfield(options, <span class="string">'sigma_0'</span>)
0186         <span class="keyword">if</span> isfield(M, <span class="string">'typicaldist'</span>)
0187             options.sigma_0 = 100/M.typicaldist();
0188         <span class="keyword">else</span>
0189             options.sigma_0 = 100/sqrt(M.dim());
0190         <span class="keyword">end</span> 
0191     <span class="keyword">end</span>
0192     
0193     
0194     timetic = tic();
0195     
0196     <span class="comment">% If no initial point x is given by the user, generate one at random.</span>
0197     <span class="keyword">if</span> ~exist(<span class="string">'x'</span>, <span class="string">'var'</span>) || isempty(x)
0198         x = M.rand();
0199     <span class="keyword">end</span>
0200 
0201     <span class="comment">% Create a store database and get a key for the current x.</span>
0202     storedb = <a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>(options.storedepth);
0203     key = storedb.getNewKey();
0204 
0205     <span class="comment">% Compute objective-related quantities for x.</span>
0206     [cost, grad] = <a href="../../../manopt/core/getCostGrad.html" class="code" title="function [cost, grad] = getCostGrad(problem, x, storedb, key)">getCostGrad</a>(problem, x, storedb, key);
0207     gradnorm = M.norm(x, grad);
0208     
0209     <span class="comment">% Initialize regularization parameter.</span>
0210     sigma = options.sigma_0;
0211 
0212     <span class="comment">% Iteration counter.</span>
0213     <span class="comment">% At any point, iter is the number of fully executed iterations so far.</span>
0214     iter = 0;
0215     
0216     <span class="comment">% Save stats in a struct array info, and preallocate.</span>
0217     stats = <a href="#_sub1" class="code" title="subfunction stats = savestats(problem, x, storedb, key, options)">savestats</a>(problem, x, storedb, key, options);
0218     info(1) = stats;
0219     info(min(10000, options.maxiter+1)).iter = [];
0220     
0221     <span class="keyword">if</span> options.verbosity &gt;= 2
0222         fprintf(<span class="string">' iter\t\t\t\t\tcost val\t\t grad norm       sigma   #Hess\n'</span>);
0223     <span class="keyword">end</span>
0224     
0225     <span class="comment">% Iterate until stopping criterion triggers.</span>
0226     <span class="keyword">while</span> true
0227 
0228         <span class="comment">% Display iteration information.</span>
0229         <span class="keyword">if</span> options.verbosity &gt;= 2
0230             fprintf(<span class="string">'%5d\t %+.16e\t %.8e   %.2e'</span>, <span class="keyword">...</span>
0231                     iter, cost, gradnorm, sigma);
0232         <span class="keyword">end</span>
0233         
0234         <span class="comment">% Start timing this iteration.</span>
0235         timetic = tic();
0236         
0237         <span class="comment">% Run standard stopping criterion checks.</span>
0238         [stop, reason] = <a href="../../../manopt/core/stoppingcriterion.html" class="code" title="function [stop, reason] = stoppingcriterion(problem, x, options, info, last)">stoppingcriterion</a>(problem, x, options, <span class="keyword">...</span>
0239                                                              info, iter+1);
0240         
0241         <span class="keyword">if</span> stop
0242             <span class="keyword">if</span> options.verbosity &gt;= 1
0243                 fprintf([<span class="string">'\n'</span> reason <span class="string">'\n'</span>]);
0244             <span class="keyword">end</span>
0245             <span class="keyword">break</span>;
0246         <span class="keyword">end</span>
0247 
0248         <span class="comment">% Solve the ARC subproblem.</span>
0249         <span class="comment">% Outputs: eta is the tentative step (it is a tangent vector at x);</span>
0250         <span class="comment">% Heta is the result of applying the Hessian at x along eta (this</span>
0251         <span class="comment">% is often a natural by-product of the subproblem solver);</span>
0252         <span class="comment">% hesscalls is the number of Hessian calls issued in the solver;</span>
0253         <span class="comment">% stop_str is a string describing why the solver terminated; and</span>
0254         <span class="comment">% substats is some statistics about the solver's work to be logged.</span>
0255         [eta, Heta, hesscalls, stop_str, substats] = <span class="keyword">...</span>
0256              options.subproblemsolver(problem, x, grad, gradnorm, <span class="keyword">...</span>
0257                                              sigma, options, storedb, key);
0258         
0259         etanorm = M.norm(x, eta);
0260 
0261         <span class="comment">% Get a tentative next x by retracting the proposed step.</span>
0262         newx = M.retr(x, eta);
0263         newkey = storedb.getNewKey();
0264 
0265         <span class="comment">% Compute the new cost-related quantities for proposal x.</span>
0266         <span class="comment">% We could just compute the cost here, as the gradient is only</span>
0267         <span class="comment">% necessary if the step is accepted; but we expect most steps are</span>
0268         <span class="comment">% accepted, and sometimes the gradient can be computed faster if it</span>
0269         <span class="comment">% is computed in conjunction with the cost.</span>
0270         [newcost, newgrad] = <a href="../../../manopt/core/getCostGrad.html" class="code" title="function [cost, grad] = getCostGrad(problem, x, storedb, key)">getCostGrad</a>(problem, newx, storedb, newkey);
0271 
0272         <span class="comment">% Compute a regularized ratio between actual and model improvement.</span>
0273         rho_num = cost - newcost;
0274         vec_rho = M.lincomb(x, 1, grad, .5, Heta);
0275         rho_den = -M.inner(x, eta, vec_rho);
0276         rho_reg = options.rho_regularization*eps*max(1, abs(cost));
0277         rho = (rho_num+rho_reg) / (rho_den+rho_reg);
0278         
0279         <span class="comment">% In principle, the subproblem solver should guarantee rho_den &gt; 0.</span>
0280         <span class="comment">% In practice, it may fail, in which case we reject the step.</span>
0281         subproblem_failure = (rho_den+rho_reg &lt;= 0);
0282         <span class="keyword">if</span> subproblem_failure
0283             stop_str = sprintf( <span class="keyword">...</span>
0284                  <span class="string">'SUBPROBLEM FAILURE! (Though it returned: %s)'</span>, stop_str);
0285         <span class="keyword">end</span>
0286         
0287         <span class="comment">% Determine if the tentative step should be accepted or not.</span>
0288         <span class="keyword">if</span> rho &gt;= options.eta_1 &amp;&amp; ~subproblem_failure
0289             accept = true;
0290             arc_str = <span class="string">'acc '</span>;
0291             <span class="comment">% We accepted this step: erase cache of the previous point.</span>
0292             storedb.removefirstifdifferent(key, newkey);
0293             x = newx;
0294             key = newkey;
0295             cost = newcost;
0296             grad = newgrad;
0297             gradnorm = M.norm(x, grad);
0298         <span class="keyword">else</span>
0299             accept = false;
0300             arc_str = <span class="string">'REJ '</span>;
0301             <span class="comment">% We rejected this step: erase cache of the tentative point.</span>
0302             storedb.removefirstifdifferent(newkey, key);
0303         <span class="keyword">end</span>
0304         
0305         <span class="comment">% Update the regularization parameter.</span>
0306         <span class="keyword">if</span> rho &gt;= options.eta_2 &amp;&amp; ~subproblem_failure
0307             <span class="comment">% Very successful step</span>
0308             arc_str(4) = <span class="string">'-'</span>;
0309             <span class="keyword">if</span> options.gamma_1 &gt; 0
0310                 sigma = max(options.sigma_min, options.gamma_1 * sigma);
0311             <span class="keyword">else</span>
0312                 sigma = max(options.sigma_min, min(sigma, gradnorm)); <span class="comment">% TODO document this</span>
0313             <span class="keyword">end</span>
0314         <span class="keyword">elseif</span> rho &gt;= options.eta_1 &amp;&amp; ~subproblem_failure
0315             <span class="comment">% Successful step</span>
0316             arc_str(4) = <span class="string">' '</span>;
0317         <span class="keyword">else</span>
0318             <span class="comment">% Unsuccessful step</span>
0319             arc_str(4) = <span class="string">'+'</span>;
0320             sigma = options.gamma_2 * sigma;
0321         <span class="keyword">end</span>
0322 
0323         <span class="comment">% iter is the number of iterations we have completed.</span>
0324         iter = iter + 1;
0325 
0326         <span class="comment">% Make sure we don't use too much memory for the store database.</span>
0327         storedb.purge();
0328         
0329         <span class="comment">% Log statistics for freshly executed iteration.</span>
0330         stats = <a href="#_sub1" class="code" title="subfunction stats = savestats(problem, x, storedb, key, options)">savestats</a>(problem, x, storedb, key, options);
0331         info(iter+1) = stats;
0332 
0333         <span class="keyword">if</span> options.verbosity &gt;= 2
0334             fprintf(<span class="string">'   %5d  %s\n'</span>, hesscalls, [arc_str <span class="string">' '</span> stop_str]);
0335         <span class="keyword">end</span>
0336         
0337         <span class="comment">% When the subproblem solver fails, it would be nice to have an</span>
0338         <span class="comment">% alternative, such as a slower but more robust solver. For now, we</span>
0339         <span class="comment">% force the solver to terminate when that happens.</span>
0340         <span class="keyword">if</span> subproblem_failure
0341             <span class="keyword">if</span> options.verbosity &gt;= 1
0342                 fprintf([<span class="string">'\nThe subproblem solver failed to make '</span> <span class="keyword">...</span>
0343                          <span class="string">'progress even on the model; this is '</span> <span class="keyword">...</span>
0344                          <span class="string">'likely due to numerical errors.\n'</span>]);
0345             <span class="keyword">end</span>
0346             <span class="keyword">break</span>;
0347         <span class="keyword">end</span>
0348         
0349     <span class="keyword">end</span>
0350     
0351     <span class="comment">% Truncate the struct-array to the part we populated</span>
0352     info = info(1:iter+1);
0353 
0354     <span class="keyword">if</span> options.verbosity &gt;= 1
0355         fprintf(<span class="string">'Total time is %f [s] (excludes statsfun)\n'</span>, info(end).time);
0356     <span class="keyword">end</span>
0357     
0358     
0359     <span class="comment">% Routine in charge of collecting the current iteration statistics</span>
0360     <a name="_sub1" href="#_subfunctions" class="code">function stats = savestats(problem, x, storedb, key, options)</a>
0361         
0362         stats.iter = iter;
0363         stats.cost = cost;
0364         stats.gradnorm = gradnorm;
0365         stats.sigma = sigma;
0366         
0367         <span class="keyword">if</span> iter == 0
0368             stats.hessiancalls = 0;
0369             stats.stepsize = NaN;
0370             stats.time = toc(timetic);
0371             stats.rho = inf;
0372             stats.rhonum = NaN;
0373             stats.rhoden = NaN;
0374             stats.accepted = true;
0375             stats.subproblem = struct();
0376         <span class="keyword">else</span>
0377             stats.hessiancalls = hesscalls;
0378             stats.stepsize = etanorm;
0379             stats.time = info(iter).time + toc(timetic);
0380             stats.rho = rho;
0381             stats.rhonum = rho_num;
0382             stats.rhoden = rho_den;
0383             stats.accepted = accept;
0384             stats.subproblem = substats;
0385         <span class="keyword">end</span>
0386         
0387         <span class="comment">% Similar to statsfun with trustregions: the x and store passed to</span>
0388         <span class="comment">% statsfun are that of the most recently accepted point after the</span>
0389         <span class="comment">% iteration fully executed.</span>
0390         stats = <a href="../../../manopt/core/applyStatsfun.html" class="code" title="function stats = applyStatsfun(problem, x, storedb, key, options, stats)">applyStatsfun</a>(problem, x, storedb, key, options, stats);
0391         
0392     <span class="keyword">end</span>
0393     
0394 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Fri 30-Sep-2022 13:18:25 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>