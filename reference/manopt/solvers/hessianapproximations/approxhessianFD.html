<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of approxhessianFD</title>
  <meta name="keywords" content="approxhessianFD">
  <meta name="description" content="Hessian approx. fnctn handle based on finite differences of the gradient.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="#">solvers</a> &gt; <a href="index.html">hessianapproximations</a> &gt; approxhessianFD.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../index.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\solvers\hessianapproximations&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>approxhessianFD
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>Hessian approx. fnctn handle based on finite differences of the gradient.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function hessfun = approxhessianFD(problem, options) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Hessian approx. fnctn handle based on finite differences of the gradient.

 function hessfun = approxhessianFD(problem)
 function hessfun = approxhessianFD(problem, options)

 Input:

 A Manopt problem structure (already containing the manifold and enough
 information to compute the cost gradient) and an options structure
 (optional), containing one option:
    options.stepsize (positive double; default: 2^-14).

 If the gradient cannot be computed or approximated on 'problem',
 a warning is issued.

 Output:
 
 Returns a function handle, encapsulating a generic finite difference
 approximation of the Hessian of the problem cost. The finite difference
 is based on computations of the gradient.
 
 The returned hessfun has this calling pattern:
 
   function hessfd = hessfun(x, xdot)
   function hessfd = hessfun(x, xdot, storedb)
   function hessfd = hessfun(x, xdot, storedb, key)
 
 x is a point on the manifold problem.M, xdot is a tangent vector to that
 manifold at x, storedb is a StoreDB object, and key is the StoreDB key to
 point x.

 Usage:

 Typically, the user will set problem.M and other fields to define the
 cost and the gradient (typically, problem.cost and problem.grad or
 problem.egrad). Then, to use this generic purpose Hessian approximation:

   problem.approxhess = approxhessianFD(problem, options);

 See also: trustregions</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../../manopt/core/canGetApproxGradient.html" class="code" title="function candoit = canGetApproxGradient(problem)">canGetApproxGradient</a>	Checks whether an approximate gradient can be computed for this problem.</li><li><a href="../../../manopt/core/canGetGradient.html" class="code" title="function candoit = canGetGradient(problem)">canGetGradient</a>	Checks whether the gradient can be computed for a problem structure.</li><li><a href="../../../manopt/core/getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>	Computes the gradient of the cost function at x.</li><li><a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>	Merges two options structures with one having precedence over the other.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../examples/positive_definite_karcher_mean.html" class="code" title="function X = positive_definite_karcher_mean(A)">positive_definite_karcher_mean</a>	Computes a Karcher mean of a collection of positive definite matrices.</li><li><a href="../../../manopt/solvers/arc/arc.html" class="code" title="function [x, cost, info, options] = arc(problem, x, options)">arc</a>	Adaptive regularization by cubics (ARC) minimization algorithm for Manopt</li><li><a href="../../../manopt/solvers/preconditioners/preconhessiansolve.html" class="code" title="function preconfun = preconhessiansolve(problem, options)">preconhessiansolve</a>	Preconditioner based on the inverse Hessian, by solving linear systems.</li><li><a href="../../../manopt/solvers/trustregions/trustregions.html" class="code" title="function [x, cost, info, options] = trustregions(problem, x, options)">trustregions</a>	Riemannian trust-regions solver for optimization on manifolds.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function hessfd = funhandle(x, xdot, storedb, key)</a></li><li><a href="#_sub2" class="code">function hessfd = hessianFD(stepsize, problem, x, xdot, storedb, key)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function hessfun = approxhessianFD(problem, options)</a>
0002 <span class="comment">% Hessian approx. fnctn handle based on finite differences of the gradient.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function hessfun = approxhessianFD(problem)</span>
0005 <span class="comment">% function hessfun = approxhessianFD(problem, options)</span>
0006 <span class="comment">%</span>
0007 <span class="comment">% Input:</span>
0008 <span class="comment">%</span>
0009 <span class="comment">% A Manopt problem structure (already containing the manifold and enough</span>
0010 <span class="comment">% information to compute the cost gradient) and an options structure</span>
0011 <span class="comment">% (optional), containing one option:</span>
0012 <span class="comment">%    options.stepsize (positive double; default: 2^-14).</span>
0013 <span class="comment">%</span>
0014 <span class="comment">% If the gradient cannot be computed or approximated on 'problem',</span>
0015 <span class="comment">% a warning is issued.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">% Output:</span>
0018 <span class="comment">%</span>
0019 <span class="comment">% Returns a function handle, encapsulating a generic finite difference</span>
0020 <span class="comment">% approximation of the Hessian of the problem cost. The finite difference</span>
0021 <span class="comment">% is based on computations of the gradient.</span>
0022 <span class="comment">%</span>
0023 <span class="comment">% The returned hessfun has this calling pattern:</span>
0024 <span class="comment">%</span>
0025 <span class="comment">%   function hessfd = hessfun(x, xdot)</span>
0026 <span class="comment">%   function hessfd = hessfun(x, xdot, storedb)</span>
0027 <span class="comment">%   function hessfd = hessfun(x, xdot, storedb, key)</span>
0028 <span class="comment">%</span>
0029 <span class="comment">% x is a point on the manifold problem.M, xdot is a tangent vector to that</span>
0030 <span class="comment">% manifold at x, storedb is a StoreDB object, and key is the StoreDB key to</span>
0031 <span class="comment">% point x.</span>
0032 <span class="comment">%</span>
0033 <span class="comment">% Usage:</span>
0034 <span class="comment">%</span>
0035 <span class="comment">% Typically, the user will set problem.M and other fields to define the</span>
0036 <span class="comment">% cost and the gradient (typically, problem.cost and problem.grad or</span>
0037 <span class="comment">% problem.egrad). Then, to use this generic purpose Hessian approximation:</span>
0038 <span class="comment">%</span>
0039 <span class="comment">%   problem.approxhess = approxhessianFD(problem, options);</span>
0040 <span class="comment">%</span>
0041 <span class="comment">% See also: trustregions</span>
0042 
0043 <span class="comment">% The Riemannian Trust-Region method, used in combination with the present</span>
0044 <span class="comment">% Hessian approximation, is called RTR-FD. Some convergence theory for it</span>
0045 <span class="comment">% is available in this paper:</span>
0046 <span class="comment">%</span>
0047 <span class="comment">% @incollection{boumal2015rtrfd</span>
0048 <span class="comment">%   author={Boumal, N.},</span>
0049 <span class="comment">%   title={Riemannian trust regions with finite-difference Hessian approximations are globally convergent},</span>
0050 <span class="comment">%   year={2015},</span>
0051 <span class="comment">%   booktitle={Geometric Science of Information}</span>
0052 <span class="comment">% }</span>
0053 
0054 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0055 <span class="comment">% Original author: Nicolas Boumal, April 8, 2015.</span>
0056 <span class="comment">% Contributors:</span>
0057 <span class="comment">% Change log:</span>
0058 <span class="comment">%</span>
0059 <span class="comment">%   Feb. 19, 2015 (NB):</span>
0060 <span class="comment">%       It is sufficient to ensure positive radial linearity to guarantee</span>
0061 <span class="comment">%       (together with other assumptions) that this approximation of the</span>
0062 <span class="comment">%       Hessian will confer global convergence to the trust-regions method.</span>
0063 <span class="comment">%       Formerly, in-code comments referred to the necessity of having</span>
0064 <span class="comment">%       complete radial linearity, and that this was harder to achieve.</span>
0065 <span class="comment">%       This appears not to be necessary after all, which simplifies the</span>
0066 <span class="comment">%       code.</span>
0067 <span class="comment">%</span>
0068 <span class="comment">%   April 3, 2015 (NB):</span>
0069 <span class="comment">%       Works with the new StoreDB class system.</span>
0070 <span class="comment">%</span>
0071 <span class="comment">%   April 8, 2015 (NB):</span>
0072 <span class="comment">%       Changed to approxhessianFD, which now returns a function handle</span>
0073 <span class="comment">%       that encapsulates the getHessianFD functionality. Will be better</span>
0074 <span class="comment">%       aligned with the other Hessian approximations to come (which may</span>
0075 <span class="comment">%       want to use storedb.internal), and now allows specifying the step</span>
0076 <span class="comment">%       size.</span>
0077 <span class="comment">%</span>
0078 <span class="comment">%   March 17, 2020 (NB):</span>
0079 <span class="comment">%       Following a bug report by Marco Sutti, added the instruction</span>
0080 <span class="comment">%           storedb.remove(key1);</span>
0081 <span class="comment">%       to avoid memory usage ramping up when many inner iterations are</span>
0082 <span class="comment">%       needed inside of tCG for trustregions. The deciding factor is that</span>
0083 <span class="comment">%       there is no need to cache the gradient at the artificially produced</span>
0084 <span class="comment">%       point used here for finite differencing, as this point is not</span>
0085 <span class="comment">%       visible outside of this function: there is no reason we would visit</span>
0086 <span class="comment">%       it again.</span>
0087 
0088     <span class="comment">% This Hessian approximation is based on the gradient:</span>
0089     <span class="comment">% check availability.</span>
0090     <span class="keyword">if</span> ~<a href="../../../manopt/core/canGetGradient.html" class="code" title="function candoit = canGetGradient(problem)">canGetGradient</a>(problem) &amp;&amp; ~<a href="../../../manopt/core/canGetApproxGradient.html" class="code" title="function candoit = canGetApproxGradient(problem)">canGetApproxGradient</a>(problem)
0091         warning(<span class="string">'manopt:approxhessianFD:nogradient'</span>, <span class="keyword">...</span>
0092                 <span class="string">'approxhessianFD requires the gradient to be computable.'</span>);
0093     <span class="keyword">end</span>
0094 
0095     <span class="comment">% Set local defaults here, and merge with user options, if any.</span>
0096     localdefaults.stepsize = 2^-14;
0097     <span class="keyword">if</span> ~exist(<span class="string">'options'</span>, <span class="string">'var'</span>) || isempty(options)
0098         options = struct();
0099     <span class="keyword">end</span>
0100     options = <a href="../../../manopt/core/mergeOptions.html" class="code" title="function opts = mergeOptions(opts_sub, opts_master)">mergeOptions</a>(localdefaults, options);
0101     
0102     <span class="comment">% Finite-difference parameter: how far do we look?</span>
0103     stepsize = options.stepsize;
0104                    
0105     <span class="comment">% Build and return the function handle here. This extra construct via</span>
0106     <span class="comment">% funhandle makes it possible to make storedb and key optional.</span>
0107     hessfun = @<a href="#_sub1" class="code" title="subfunction hessfd = funhandle(x, xdot, storedb, key)">funhandle</a>;
0108     <a name="_sub1" href="#_subfunctions" class="code">function hessfd = funhandle(x, xdot, storedb, key)</a>
0109         <span class="comment">% Allow omission of the key, and even of storedb.</span>
0110         <span class="keyword">if</span> ~exist(<span class="string">'key'</span>, <span class="string">'var'</span>)
0111             <span class="keyword">if</span> ~exist(<span class="string">'storedb'</span>, <span class="string">'var'</span>)
0112                 storedb = <a href="../../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>();
0113             <span class="keyword">end</span>
0114             key = storedb.getNewKey();
0115         <span class="keyword">end</span> 
0116         hessfd = <a href="#_sub2" class="code" title="subfunction hessfd = hessianFD(stepsize, problem, x, xdot, storedb, key)">hessianFD</a>(stepsize, problem, x, xdot, storedb, key);
0117     <span class="keyword">end</span>
0118     
0119 <span class="keyword">end</span>
0120 
0121 
0122 <a name="_sub2" href="#_subfunctions" class="code">function hessfd = hessianFD(stepsize, problem, x, xdot, storedb, key)</a>
0123 <span class="comment">% This function does the actual work.</span>
0124 <span class="comment">%</span>
0125 <span class="comment">% Original code: Dec. 30, 2012 (NB).</span>
0126     
0127     <span class="comment">% Extract the input vector norm.</span>
0128     norm_xdot = problem.M.norm(x, xdot);
0129     
0130     <span class="comment">% First, check whether the step xdot is not too small.</span>
0131     <span class="keyword">if</span> norm_xdot &lt; eps
0132         hessfd = problem.M.zerovec(x);
0133         <span class="keyword">return</span>;
0134     <span class="keyword">end</span>
0135     
0136     <span class="comment">% Determine how far to retract xdot, so that the point reached does not</span>
0137     <span class="comment">% depend on the norm of xdot. This is what ensures radial linearity of</span>
0138     <span class="comment">% this present Hessian approximation.</span>
0139     c = stepsize / norm_xdot;
0140     
0141     <span class="comment">% Compute the gradient at the current point.</span>
0142     grad = <a href="../../../manopt/core/getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>(problem, x, storedb, key);
0143     
0144     <span class="comment">% Compute a point a little further along xdot, and the gradient there.</span>
0145     <span class="comment">% Since this is a new point, we need a new key for it, for storedb.</span>
0146     x1 = problem.M.retr(x, xdot, c);
0147     key1 = storedb.getNewKey();
0148     grad1 = <a href="../../../manopt/core/getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>(problem, x1, storedb, key1);
0149     
0150     <span class="comment">% Remove any caching associated to that new point, since there is no</span>
0151     <span class="comment">% reason we would be visiting it again.</span>
0152     storedb.remove(key1);
0153     
0154     <span class="comment">% Transport grad1 back from x1 to x.</span>
0155     grad1 = problem.M.transp(x1, x, grad1);
0156     
0157     <span class="comment">% Return the finite difference of them: (grad1 - grad)/c.</span>
0158     hessfd = problem.M.lincomb(x, 1/c, grad1, -1/c, grad);
0159     
0160 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Tue 19-May-2020 18:46:12 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>