[
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "Helpful tools",
    "section": "",
    "text": "Manopt offers a suite of tools to help with studying a problem’s landscape, detecting bugs, speeding up computations, handling geometric objects, keeping track of computational efforts, etc. These are located in the folder /manopt/tools, and documented below.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#checks-for-the-cost-function",
    "href": "tools.html#checks-for-the-cost-function",
    "title": "Helpful tools",
    "section": "Checks for the cost function",
    "text": "Checks for the cost function\nThe cost function \\(f\\) and its derivatives satisfy certain relationships. By checking these numerically, we can detect possible coding errors. Manopt provides tools to this effect:\n\ncheckdiff(problem) checks directional derivatives (problem.diff etc.)\ncheckgradient(problem) checks the Riemannian gradient (problem.egrad, problem.grad, problem.costgrad etc.)\ncheckhessian(problem) checks the Riemannian Hessian (problem.ehess, problem.hess etc.)\n\nThe theory underlying these checks is explained in Sections 4.8 and 6.8 of this book.\n\nGradient check\nPick a point \\(x\\) on the manifold and a tangent vector \\(u\\) at \\(x\\). From a truncated Taylor expansion, we know that the following holds with any retraction \\(\\Retr\\): \\[\n  E(t) = \\Big| f(\\Retr_x(tu)) - \\big[ f(x) + t\\cdot\\D f(x)[u] \\big] \\Big| = \\mathcal{O}(t^2).\n\\] Hence, in a log-log plot with \\(\\log(t)\\) on the abscissa, the error should behave as \\(\\log(t^2) = 2\\log(t)\\). That is, we should observe a slope of 2. Calling checkdiff(problem, x, u) produces such a plot and reports the slope of it in a text output. Numerical errors prevent the curve to have a slope of 2 everywhere even if directional derivatives are correct, so you should really inspect the plot visually. If x and u are omitted, they are picked at random.\nThe Riemannian gradient is the (only) tangent vector field that satisfies \\[\n  \\inner{\\grad f(x)}{u}_x = \\D f(x)[u]\n\\] for all \\(x, u\\). Calling checkgradient(problem, x, u) computes \\(\\grad f(x)\\) then does two things:\n\nIt runs checkdiff(problem, x, u) with \\(\\D f(x)[u]\\) replaced by \\(\\inner{\\grad f(x)}{u}_x\\) in the expression for \\(E(t)\\): this outputs the slope plot and text.\nIt checks that the gradient is indeed a tangent vector, by reporting (as text) the norm of the difference between the gradient gradfx and the output of problem.M.tangent(x, gradfx). This should be zero.\n\nIf x and u are omitted, they are picked at random.\n\n\nHessian check\nGoing back to \\(E(t)\\) and including the next term in the Taylor expansion, we know that \\[\n  E(t) = \\left| f(\\Retr_x(tu)) - \\left[ f(x) + t\\cdot\\D f(x)[u] + \\frac{t^2}{2} \\cdot \\inner{u}{\\Hess f(x)[u]}_x \\right] \\right| = \\mathcal{O}(t^3)\n\\] as long as one (or both) of the two conditions holds:\n\nThe retraction \\(\\Retr\\) is second order (see remarks below), or\nThe point \\(x\\) is a critical point: \\(\\grad f(x) = 0\\).\n\nHence, in a log-log plot with \\(\\log(t)\\) on the abscissa, the error should behave as \\(\\log(t^3) = 3\\log(t)\\), i.e., we should observe a slope of 3. This tool produces such a plot and tries to compute the slope of it. Again, numerical errors prevent the curve to have a slope of 3 everywhere even if the derivatives are correct, so you should inspect the plot visually.\nThe tool also verifies that the Hessian indeed returns a tangent vector, in the same way that we checked above that the gradient is a tangent vector. This produces a text output.\nThe Hessian is a linear, symmetric operator from the tangent space at \\(x\\) to itself. The tool generates two random scalars \\(a_1, a_2\\) and two random tangent vectors \\(u_1\\) and \\(u_2\\) at \\(x\\) to test linearity: \\[\n  \\Big\\| a_1 \\cdot \\Hess f(x)[u_1] + a_2 \\cdot \\Hess f(x)[u_2] - \\Hess f(x)[a_1 u_1 + a_2 u_2] \\Big\\|_x = 0.\n\\] The quantity on the left-hand side is reported in text output, and should be zero up to machine precision.\nTo verify symmetry, the tool further computes the difference \\[\n  \\inner{\\Hess f(x)[u_1]}{u_2}_x - \\inner{u_1}{\\Hess f(x)[u_2]}_x,\n\\] which should also be zero.\nIf x and u are omitted, they are picked at random.\nA couple of remarks:\n\nIt is important to check both the slope test and the symmetry test. That is because \\(\\inner{u}{\\Hess f(x)[u]}_x\\) only “sees” the symmetric part of \\(\\Hess f(x)\\). If the code for the Hessian has a skew-symmetric part, then the Hessian is wrong, yet the slope test could succeed.\nThe tool checkhessian tries to use the exponential map M.exp by default (since this is a second-order retraction). If that is not available, the default retraction is used. It may be second order: read the help section of your manifold factory to confirm this. If it is not, then the slope test is inconclusive.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#checks-for-manifolds",
    "href": "tools.html#checks-for-manifolds",
    "title": "Helpful tools",
    "section": "Checks for manifolds",
    "text": "Checks for manifolds\n\ncheckretraction(M, x, v)  For manifolds M which have a correct exponential map M.exp implemented, this tool produces a slopt-test plot to check the order of agreement of the retraction M.retr with the exponential. A slope of 2 indicates the retraction is a first-order approximation of the exponential (which is necessary for most (all?) convergence theorems to hold.) A slope of 3 indicates the retraction is second-order, which is convenient in some cases. The check is conducted at point x along direction v; they are generated at random if omitted.\ncheckmanifold(M)  Runs a collection of tests on a manifold structure produced by a factory. The purpose of this tool is ease the process of creating factories for new manifolds. Contributions are welcome to extend it.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#hessian-eigenvalues-and-eigenvectors",
    "href": "tools.html#hessian-eigenvalues-and-eigenvectors",
    "title": "Helpful tools",
    "section": "Hessian eigenvalues and eigenvectors",
    "text": "Hessian eigenvalues and eigenvectors\nGiven a function \\(f \\colon \\calM \\to \\reals\\) and a point \\(x \\in \\calM\\), we may want to investigate the spectrum of \\(\\Hess f(x)\\), that is, the Riemannian Hessian at \\(x\\). With a problem structure to describe \\(f\\), and x to identify the point \\(x\\), we can do so in several ways using the tools\n\nhessianmatrix (then eig)\nhessianspectrum (internally via eigs)\nhessianextreme (via optimization)\n\n\nVia matrix representation\nThe first way is to obtain a representation of the Hessian as a matrix, then to compute the eigenvalues of that matrix. The one-line vesion goes as follows:\neig(hessianmatrix(problem, x)) % eigenvalues of Hess f(x)\nMore explicitly: \\(\\Hess f(x)\\) is a symmetric linear map on the tangent space \\(\\T_x\\calM\\). If \\(b_1, \\ldots, b_k \\in \\T_x\\calM\\) form an orthonormal basis for the tangent space, then the symmetric matrix \\(H \\in \\reals^{k \\times k}\\) with \\[H_{ij} = \\inner{b_i}{\\Hess f(x)[b_j]}_x\\] represents the Hessian in those coordinates, in the sense that if \\(v = a_1 b_1 + \\cdots + a_k b_k\\), then \\(\\Hess f(x)[v] = c_1 b_1 + \\cdots + c_k b_k\\) where \\(c = Ha\\). In particular, the eigenvalues of \\(H\\) are the same as the eigenvalues of \\(\\Hess f(x)\\) because \\(b_1, \\ldots, b_k\\) are orthonormal.\nIf hessianmatrix is called without providing an orthonormal basis, then a basis is generated at random via tangentorthobasis. You can recover that basis too, as follows:\n[H, basis] = hessianmatrix(problem, x);\nThen, basis is a cell such that basis{1}, basis{2}, ... form an orthonormal basis \\(b_1, b_2, \\ldots\\) for \\(\\T_x\\calM\\). This makes it possible to access the eigenvectors of \\(\\Hess f(x)\\) too, like so:\n[H, basis] = hessianmatrix(problem, x);\n[V, D] = eig(H);\nv = lincomb(problem.M, x, basis, V(:, 1)); % eigenvector for eigenvalue D(1, 1)\nThat code:\n\ngenerates an orthonormal basis for \\(\\T_x\\calM\\) and computes the matrix \\(H\\) which represents \\(\\Hess f(x)\\) in that basis with hessianmatrix,\ndetermines the eigenvalues and eigenvectors of \\(H\\) with eig, then\nexpands the first such eigenvector as a linear combination of the basis vectors with lincomb.\n\nThe result is a tangent vector \\(v\\) at \\(x\\) which is an eigenvector of \\(\\Hess f(x)\\). You can check this by comparing v with getHessian(problem, x, v).\nIf you already have an orthonormal basis, you can use that one by calling\nH = hessianmatrix(problem, x, basis);\nIf basis is an orthonormal basis for a subspace of the tangent space, then H is a matrix that represents the restriction of the Hessian to that subspace.\n\n\n\n\n\n\nThe matrix-way does not scale well\n\n\n\nGenerating the orthonormal basis takes time. So does applying the Hessian to each basis vector. This is a convenient tool for prototyping and exploration, but expect performance to degrade as dimension increases.\n\n\n\n\nIn a matrix-free way\nIn contrast to the hessianmatrix tool, the hessianspectrum tool provides access to the eigenvalues of the Hessian without building a basis for the tangent vector (and therefore also without constructing a matrix representation of the Hessian). It relies on Matlab’s eigs. An additional advantage is that it also provides access to the spectrum of the preconditioned Hessian (if a preconditioner is included in the problem structure).\nTo compute the eigenvalues of the Hessian \\(\\Hess f(x)\\) at \\(x\\) with this tool, call\nhessianspectrum(problem, x) % eigenvalues of Hess f(x)\nIf a preconditioner \\(\\mathrm{Prec}\\) is specified in the problem structure and you call\nhessianspectrum(problem, x, 'precon') % eigenvalues of preconditioned Hess f(x)\nthen the eigenvalues of the preconditioned Hessian \\(\\Hess f(x) \\circ \\mathrm{Prec}(x)\\) are computed.\nThis function relies on problem.M.vec and problem.M.mat to pass the computations down to Matlab’s built-in eigs function. For the eigenvalue problem to remain symmetric in the column-vector representation domain, we need M.vec and M.mat to be orthonormal, i.e., isometries (see matvecareisometries in the manifold section). If they are not isometries, computations may take longer.\nIndeed, let \\(G\\) denote the M.vec operator and let \\(G^{-1}\\) represent the M.mat operator (on the appropriate domains). Let \\(H\\) and \\(P\\) denotes the Hessian and preconditioner at \\(x\\) (with \\(P\\) being identity if there is none). Then, eigs computes the spectrum of \\(GHG^{-1}\\) or \\(GHPG^{-1}\\), which are identical to, respectively, the spectra of \\(H\\) and \\(HP\\). This is only symmetric if there is no preconditioner and \\(G^\\top = G^{-1}\\).\nIf a preconditioner is used, the symmetry of the eigenvalue problem is lost: \\(H\\) and \\(P\\) are symmetric, but \\(HP\\) is not. If M.vec and M.mat are isometries and the dimension of the manifold is large, it may be useful to restore symmetry by giving this tool a function handle for the square root of the preconditioner, \\(P^{1/2}\\) (optional). Then, eigs is given the problem of computing the spectrum of \\(GP^{1/2}HP^{1/2}G^\\top\\) (symmetric), which is equal to the spectrum of \\(HP\\). Typically, the square root of the preconditioner is given via problem.sqrtprecon (see cost description).\nThis tool can be faster than hessianmatrix, but it still aims to compute all eigenvalues. If you only need to compute an eigenvector for the largest or smallest eigenvalue, try hessianextreme as follows:\n[u_min, lambda_min] = hessianextreme(problem, x, 'min');\n[u_max, lambda_max] = hessianextreme(problem, x, 'max');\nThese run a Manopt solver on the Rayleigh quotient over the unit sphere in the tangent space \\(\\T_x\\calM\\), aiming to compute (respectively) a minimizer and a maximizer. As such, this tool is not guaranteed to succeed, but it always provides an upperbound on the smallest eigenvalue and a lowerbound on the largest eigenvalue of \\(\\Hess f(x)\\). Call help hessianextreme for more options.\nComments:\n\nAt this time, hessianspectrum outputs the eigenvalues only. It does not provide access to the eigenvectors, though it could be modified to that effect. It could also be modified to call eigs in a way that targets only extreme eigenvalues.\nBoth hessianspectrum and hessianextreme accept (storedb, key) as optional inputs, to use the caching system.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#finding-critical-points",
    "href": "tools.html#finding-critical-points",
    "title": "Helpful tools",
    "section": "Finding critical points",
    "text": "Finding critical points\nWhen studying the landscape of an optimization problem, we may want to find critical points of \\(f\\), that is, points where the Riemannian gradient is zero. If problem is the structure that describes your manifold \\(\\calM\\) and cost function \\(f\\) (with derivatives), call\ncp_problem = criticalpointfinder(problem);\nto create a new problem structure. This one is on the same manifold \\(\\calM\\), but with the cost function \\[\n  g(x) = \\frac{1}{2} \\| \\grad f(x) \\|^2_x.\n\\] The gradient of \\(g\\) is computed via \\(\\grad g(x) = \\Hess f(x)[\\grad f(x)]\\). An approximate Hessian can also be generated.\nEvidently, the minimizers of \\(g\\) are the critical points of \\(f\\). Thus, running a solver such as x = trustregions(cp_problem) could find a critical point of \\(f\\). This is not guaranteed to work because \\(g\\) may have non-global local minima. Accordingly, it is best to run the solver many times from various random initial guesses, and to check the gradient norm. For example:\n% first define the problem structure, then:\ncp_problem = criticalpointfinder(problem);\nnrepeats = 100;\npoints = cell(nrepeats, 1);\ngradfnorms = inf(nrepeats, 1);\ncp_options.tolgradnorm = 1e-10;\nfor rep = 1 : nrepeats\n    x = trustregions(cp_problem, [], cp_options); % random init\n    points{rep} = x;\n    gradfnorms(rep) = problem.M.norm(x, getGradient(problem, x));\nend\n% Now check which points have a satisfactorily small gradient norm.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#plotting-the-cost-function",
    "href": "tools.html#plotting-the-cost-function",
    "title": "Helpful tools",
    "section": "Plotting the cost function",
    "text": "Plotting the cost function\n\nplotprofile(problem, x, d, t)  Plots the cost function along a geodesic or a retraction path starting at \\(x\\), along direction \\(d\\). All inputs are optional except problem. See help plotprofile for more information.\nsurfprofile(problem, x, d1, d2, t1, t2)  Plots the cost function, lifted and restricted to a 2-dimensional subspace of the tangent space at \\(x\\). All inputs are optional except problem. See help surfprofile for more information.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#matrix-computations",
    "href": "tools.html#matrix-computations",
    "title": "Helpful tools",
    "section": "Matrix computations",
    "text": "Matrix computations\nManopt includes tools to facilitate certain matrix computations as listed in the first table below. They provide help to:\n\ndifferentiate matrix functions,\nsolve matrix equations, and\ncompute factorizations.\n\n\nTools for matrix computations that sometimes come up when using Manopt.\n\n\n\n\n\n\nCall\nDescription\n\n\n\n\ndfunm, dlogm, dexpm, dsqrtm\nFréchet derivatives of the (built-in) matrix functions, and their particularization to logm, expm and sqrtm. For example, the call [A, B] = dexpm(X, Xdot) outputs both \\(A = \\D\\mathrm{exp}(X)[\\dot X]\\) and \\(B = \\mathrm{exp}(X)\\).\n\n\nlyapunov_symmetric\nTool to solve the Lyapunov matrix equation \\(AX + XA = C\\) when \\(A = A^*\\) (real symmetric or Hermitian). Can solve for more than one right-hand side at a time.\n\n\nlyapunov_symmetric_eig\nSame as lyapunov_symmetric but the user supplies the eigenvalue decomposition of \\(A\\) instead of \\(A\\). This is more efficient if several systems with the same \\(A\\) need to be solved, but the various right-hand sides are not all known at the same time.\n\n\nsylvester_nochecks\nSolves the Sylvester equation \\(AX + XB = C\\), where \\(A\\) is an m-by-m matrix, \\(B\\) is an n-by-n matrix, and \\(X\\) and \\(C\\) are two m-by-n matrices. This is a stripped-down version of Matlab’s own sylvester function that bypasses any input checks. This is significantly faster for small m and n, which is often useful in Manopt.\n\n\nqr_unique\nGiven \\(A\\) with full columns rank, Q = qr_unique(A) computes \\(Q\\) of the same size as \\(A\\) such that \\(A = QR\\), \\(Q\\) has orthonormal columns and \\(R\\) is upper triangular with positive diagonal entries. This fully specifies \\(Q\\). (Matlab’s [Q, ~] = qr(A, 0) does not enforce positive diagonal entries of \\(R\\) by default, losing the uniqueness property). This Q-factor is exactly what one would compute through Gram–Schmidt orthonormalization of the columns of \\(A\\), but it is computed differently. Works with 3D arrays (on each slice separately) and with both real and complex matrices.\n\n\n\nMoreover, it is often useful to apply the same operations to many matrices. For best performance, it is important to vectorize such computations (in order to exploit SIMD features of processors). The table below list tools Manopt provides to do just that:\n\nTools to apply the same computations to many matrices without for-loop. This improves performance significantly.\n\n\n\n\n\n\nCall\nDescription\n\n\n\n\nB = multiscale(scale, A)\nFor a 3D matrix A of size nxmxN and a vector scale of length N, outputs B: a 3D matrix of the same size as A such that B(:, :, k) = scale(k) * A(:, :, k) for each k.\n\n\ntr = multitrace(A)\nFor a 3D matrix A of size nxnxN, outputs a column vector tr of length N such that tr(k) = trace(A(:, :, k)) for each k.\n\n\nsq = multisqnorm(A)\nFor a 3D matrix A of size nxmxN, outputs a column vector sq of length N such that sq(k) = norm(A(:, :, k), 'fro')^2 for each k.\n\n\nB = multitransp(A)\nFor a 3D matrix A of size nxmxN, outputs B, a 3D matrix of size mxnxN such that B(:, :, k) = A(:, :, k).' for each k (transpose).\n\n\nB = multihconj(A)\nFor a 3D matrix A of size nxmxN, outputs B, a 3D matrix of size mxnxN such that B(:, :, k) = A(:, :, k)' for each k (conjugate transpose).\n\n\nC = multiprod(A, B)\nFor 3D matrices A of size nxpxN and B of size pxmxN, outputs C, a 3D matrix of size nxmxN such that C(:, :, k) = A(:, :, k) * B(:, :, k) for each k.\n\n\nB = multiskew(A)\nFor a 3D matrix A of size nxnxN, outputs a 3D matrix B the same size as A such that each slice B(:, :, i) is the skew-symmetric part of the slice A(:, :, i), that is, (A(:, :, i)-A(:, :, i).')/2.\n\n\nB = multiskewh(A)\nFor a 3D matrix A of size nxnxN, outputs a 3D matrix B the same size as A such that each slice B(:, :, i) is the Hermitian skew-symmetric part of the slice A(:, :, i), that is, (A(:, :, i)-A(:, :, i)')/2.\n\n\nB = multisym(A)\nFor a 3D matrix A of size nxnxN, outputs a 3D matrix B the same size as A such that each slice B(:, :, i) is the symmetric part of the slice A(:, :, i), that is, (A(:, :, i)+A(:, :, i).')/2.\n\n\nB = multiherm(A)\nFor a 3D matrix A of size nxnxN, outputs a 3D matrix B the same size as A such that each slice B(:, :, i) is the Hermitian part of the slice A(:, :, i), that is, (A(:, :, i)+A(:, :, i)')/2.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#counters-to-track-computations",
    "href": "tools.html#counters-to-track-computations",
    "title": "Helpful tools",
    "section": "Counters (to track computations)",
    "text": "Counters (to track computations)\nManopt counters provide a way to track all sorts of metrics, including function calls, time spent in specific parts of them, particular operations, etc. They are accessed via two tools:\n\nS = statscounters(names) is used to register Manopt counters in options.statsfun via statsfunhelper.\nincrementcounter(store, countername, increment) increments a counter in a store or storedb.\n\nA basic usage would go as follows. See the cost description page, especially the section about caching, for more information about how store and prepare are used here.\nfunction foo()\n\n    n = 100;\n    A = randsym(n);\n\n    problem.M = spherefactory(size(A, 1));\n\n    problem.cost = @cost;\n    problem.egrad = @egrad;\n    problem.ehess = @ehess;\n\n    % List the names of counters we want the optimization algorithm to log.\n    % The fields in the structure stats are function handles: one for each\n    % counter. Before passing stats to statsfunhelper, we could add more\n    % fields to stats to log other things as well.\n    %\n    % Names of the counters (here, Aproducts and some_other_counter) are\n    % for us to choose: they only need to be valid structure field names.\n    % They need not have been defined in advance.\n    stats = statscounters({'Aproducts', 'some_other_counter'});\n    options.statsfun = statsfunhelper(stats);\n\n    [x, fx, info] = trustregions(problem, [], options);\n\n\n    semilogy([info.Aproducts], [info.gradnorm], '.-');\n    xlabel('Number of matrix-vector products with A');\n    ylabel('Riemannian gradient norm');\n\n    % Below, we have the code for the cost function and its derivatives.\n    % Everytime we use a matrix-vector product with A, we increment the\n    % counter.\n\n    function store = prepare(x, store)\n        if ~isfield(store, 'Ax')\n            store.Ax = A*x;\n            store = incrementcounter(store, 'Aproducts');\n        end\n    end\n    function [f, store] = cost(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        f = .5*x'*Ax;\n    end\n    function [g, store] = egrad(x, store)\n        store = prepare(x, store);\n        g = store.Ax;\n    end\n    function [h, store] = ehess(x, u, store)\n        h = A*u;\n        store = incrementcounter(store, 'Aproducts');\n    end\n\nend\nBy default, incrementcounter increments by 1. You may also specify the increment as the last input (it can be any double value, not necessarily integer or positive).\nSee the full working example in the /examples folder to see how to:\n\nregister more than one counter,\nuse counters in a stopping criterion,\nrun several solvers on the same problem and compare the metrics tracked by counters.\n\n\n\n\n\n\n\nCounter names (such as 'Aproducts' in the example) must be valid names for structure fields. Essentially, this means they should be valid variable names (no spaces, do not start with a digit, etc.)",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#working-with-tangent-vectors",
    "href": "tools.html#working-with-tangent-vectors",
    "title": "Helpful tools",
    "section": "Working with tangent vectors",
    "text": "Working with tangent vectors\nThe following tools ease certain tasks involving tangent spaces and tangent vectors.\n\nvec = lincomb(M, x, vectors, coeffs)  Given a cell vectors of \\(n\\) tangent vectors to the manifold M at x and a vector coeffs of \\(n\\) real coefficients, outputs the linear combination of the given vectors with the given coefficients. The empty linear combination is the zero vector at x.\ncoeffs = tangent2vec(M, x, basis, u)  Given a tangent vector u at x and an orthonormal basis basis for the corresponding tangent space, outputs the coordinates coeffs of u in that basis. The inverse operation is u = lincomb(M, x, basis, coeffs), see above.\nG = grammatrix(M, x, vectors)  Given \\(n\\) tangent vectors \\(v_1, \\ldots, v_n\\) to the manifold M at point x in a cell vectors, outputs a symmetric, positive semidefinite matrix G of size \\(n\\times n\\) such that \\(G_{ij} = \\inner{v_i}{v_j}_x\\).\n[orthobasis, L] = orthogonalize(M, x, basis)  Given a cell basis which contains linearly independent tangent vectors to the manifold M at x, outputs an orthonormal basis of the subspace spanned by the given basis. L is an upper triangular matrix containing the coefficients of the linear combinations needed to transform basis into orthobasis. This is essentially a QR factorization, via modified Gram–Schmidt.\n[orthobasis, L] = orthogonalizetwice(M, x, basis)  Same as orthogonalize, but calls it twice in sequence for (much) improved numerical stability (at twice the computational cost).\nobasis = tangentorthobasis(M, x, n)  Given a point x on the manifold M, generates n unit-norm, pairwise orthogonal vectors in the tangent space to M at x, in a cell. See help tangentorthobasis for more advanced call patterns.\n[u_norm, coeffs, u] = smallestinconvexhull(M, x, U)  Computes u, a tangent vector to M at x contained in the convex hull spanned by the \\(n\\) vectors in the cell U, with minimal norm (according to the Riemannian metric on M). This is obtained by solving a convex quadratic program involving the Gram matrix of the given tangent vectors. The quadratic program is solved using Matlab’s built-in quadprog, which requires the Optimization Toolbox.\n[A, B1, B2] = operator2matrix(M1, x, y, F, B1, B2, M2)  Given manifold structures M1 and M2, two points x and y on these manifolds, and a function F encoding a linear operator from the tangent space \\(\\T_x \\calM_1\\) to the tangent space \\(\\T_y \\calM_2\\), this tool uses two orthonormal bases B1 and B2 (one for \\(\\T_x \\calM_1\\), and one for \\(\\T_y \\calM_2\\); generated at random if omitted), and forms the matrix A which represents the operator F in those bases. In particular, the singular values of A are equal to the singular values of F. If M2 is omitted, then M2 = M1. See the code for more use cases.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#interactive-stopping-criteria",
    "href": "tools.html#interactive-stopping-criteria",
    "title": "Helpful tools",
    "section": "Interactive stopping criteria",
    "text": "Interactive stopping criteria\nAn interactive stopping criterion allows the user to stop the execution of a Manopt solver in real time. When it is triggered, the solver gracefully terminates and outputs the best iterate it produced so far. Matlab then proceeds to keep running the code that follows the call to the solver, so that the work done until that point is not lost.\nOne such tool open a special figure once the solver starts running. The solver terminates if the figure is closed.\noptions.stopfun = @stopifclosedfigure; % add this option\ntrustregions(problem, x0, options);    % run this or any other solver\nAnother such tool (better suited if you are running Matlab without graphical user interface, e.g., over SSH) creates a special file. The solver terminates if that file is deleted.\noptions.stopfun = stopifdeletedfile(); % add this option\ntrustregions(problem, x0, options);    % run this or any other solver\nBy default, the file is called MANOPT_DELETE_ME_TO_STOP_SOLVER. You may also specify another file name as optional input to stopifdeletedfile.\nNote that termination may not be immediate as the solver has to finish the current iteration first. In particular, certain solvers (including trustregions) check stopping criteria only at outer iterations, not during inner iterations, further increasing the delay.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#utilities-for-solvers",
    "href": "tools.html#utilities-for-solvers",
    "title": "Helpful tools",
    "section": "Utilities for solvers",
    "text": "Utilities for solvers\n\nstatsfunhelper  Helper function to place a function handle in the field options.statsfun, with the purpose of recording or displaying information about individual iterations. See this page for documentation. Also consider using statscounters and incrementcounter as documented on this page.\nmanoptsolve  This tool presents itself as a solver, with their usual calling pattern:\n[x, cost, info, options] = manoptsolve(problem, x0, options);\nIt is a gateway function to call an actual Manopt solver. You may specify which one to call by setting options.solver to a function handle corresponding to a solver. For example,\noptions.solver = @trustregions;\nIf not, a solver is picked automatically. This is mainly useful when programming meta algorithms which need to solve a Manopt problem, but one wants to leave the decision of which solver to use up to the final user (therefore making it an option).",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#creating-manifolds",
    "href": "tools.html#creating-manifolds",
    "title": "Helpful tools",
    "section": "Creating manifolds",
    "text": "Creating manifolds\n\nproductmanifold and powermanifold  These tools generate a structure that represents a product of manifolds. See this page for documentation.\nN = tangentspacefactory(M, x)  Given a manifold structure M and a point x on that manifold, outputs a manifold structure N representing the tangent space to M at x. This is used in preconhessiansolve.\nN = tangentspherefactory(M, x)  Given a manifold structure M and a point x on that manifold, outputs a manifold structure N representing the unit sphere on the tangent space to M at x. This is used by the hessianextreme tool.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "tools.html#miscellaneous",
    "href": "tools.html#miscellaneous",
    "title": "Helpful tools",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\ny = sinxoverx(x)  Computes \\(y = \\sin(x)/x\\), with the convention \\(\\sin(0)/0 = 1\\).\ns = getsize(x)  Estimates the memory usage of the input variable.",
    "crumbs": [
      "Home",
      "Helpful tools"
    ]
  },
  {
    "objectID": "manifolds.html",
    "href": "manifolds.html",
    "title": "Manifolds",
    "section": "",
    "text": "Manifolds in Manopt are represented as structures and are obtained by calling a factory. Such a structure contains a collection of functions that make it possible to interact with the manifold.",
    "crumbs": [
      "Home",
      "Manifolds"
    ]
  },
  {
    "objectID": "manifolds.html#general-description",
    "href": "manifolds.html#general-description",
    "title": "Manifolds",
    "section": "",
    "text": "Manifolds in Manopt are represented as structures and are obtained by calling a factory. Such a structure contains a collection of functions that make it possible to interact with the manifold.",
    "crumbs": [
      "Home",
      "Manifolds"
    ]
  },
  {
    "objectID": "manifolds.html#available-manifolds",
    "href": "manifolds.html#available-manifolds",
    "title": "Manifolds",
    "section": "Available manifolds",
    "text": "Available manifolds\nManopt comes with a number of implementations for generically useful manifolds. Built-in factories are located in /manopt/manifolds.\nOf course, manifolds can also be user-defined. The best way to build your own is probably to read the code of some of the standard factories and to adapt what needs to be changed. If you develop an interesting manifold factory and would like to share it, let us know.\nBear in mind that a manifold can be turned into a Riemannian manifold in many different ways, by choosing one or another metric. Which metric is best for a specific application may vary: experiments will tell.\n\nLinear and affine subspaces\n\nEuclidean space (real and complex vectors, matrices, tensors, …)\n\n\\(\\mathbb{R}^{n}\\)  euclideanfactory(n)\n\\(\\mathbb{R}^{m \\times n}\\)  euclideanfactory(m, n)\n\\(\\mathbb{C}^{n}\\)  euclideancomplexfactory(n)\n\\(\\mathbb{C}^{m \\times n}\\)  euclideancomplexfactory(m, n)\n\nSymmetric matrices\n\n\\(\\{ X \\in \\mathbb{R}^{n \\times n} : X = X^\\top\\}^k\\)  symmetricfactory(n, k)\n\nSkew-symmetric matrices\n\n\\(\\{ X \\in \\mathbb{R}^{n \\times n} : X + X^\\top = 0\\}^k\\)  skewsymmetricfactory(n, k)\n\nCentered matrices\n\n\\(\\{ X \\in \\mathbb{R}^{m \\times n} : X\\mathbf{1}_n = 0_m \\}\\)  centeredmatrixfactory(m, n)\n\nSparse matrices with fixed sparsity pattern\n\n\\(\\{ X \\in \\mathbb{R}^{m \\times n} : X_{ij} = 0 \\textrm{ if } A_{ij} = 0 \\}\\)  euclideansparsefactory(A) (inefficient implementation)\n\nLinear subspace of a linear space\n\n\\(\\{ x \\in E : x = \\mathrm{proj}(x) \\}\\) where \\(E\\) is a linear space (obtained from a factory) and \\(\\mathrm{proj}\\) is an orthogonal projector to the desired subspace.  euclideansubspacefactory(E, proj, dim)\n\n\n\n\nSpheres, unit norm and unit modulus\n\nSphere\n\n\\(\\{x\\in\\mathbb{R}^{n} : \\|x\\|_2 = 1\\}\\)  spherefactory(n) (unit 2-norm)\n\\(\\{X\\in\\mathbb{R}^{n\\times m} : \\|X\\|_\\mathrm{F} = 1\\}\\)  spherefactory(n, m) (unit Frobenius norm)\n\\(\\{x\\in\\mathbb{C}^{n} : \\|x\\|_2 = 1\\}\\)  spherecomplexfactory(n) (unit 2-norm)\n\\(\\{X\\in\\mathbb{C}^{n\\times m} : \\|X\\|_\\mathrm{F} = 1\\}\\)  spherecomplexfactory(n, m) (unit Frobenius norm)\n\nSphere of symmetric matrices\n\n\\(\\{X\\in\\mathbb{R}^{n\\times n} : \\|X\\|_\\mathrm{F} = 1 \\textrm{ and } X = X^\\top\\}\\)  spheresymmetricfactory(n)\n\nOblique manifold (product of spheres)\n\n\\(\\{X\\in\\mathbb{R}^{n\\times m} : \\|X_{:1}\\| = \\cdots = \\|X_{:m}\\| = 1\\}\\)  obliquefactory(n, m) (\\(m\\) normed columns in \\(\\mathbb{R}^n\\))\n\\(\\{X\\in\\mathbb{R}^{m\\times n} : \\|X_{1:}\\| = \\cdots = \\|X_{m:}\\| = 1\\}\\)  obliquefactory(n, m, true) (\\(m\\) normed rows in \\(\\mathbb{R}^n\\))\n\\(\\{X\\in\\mathbb{C}^{n\\times m} : \\|X_{:1}\\| = \\cdots = \\|X_{:m}\\| = 1\\}\\)  obliquecomplexfactory(n, m) (\\(m\\) normed columns in \\(\\mathbb{C}^n\\))\n\\(\\{X\\in\\mathbb{C}^{m\\times n} : \\|X_{1:}\\| = \\cdots = \\|X_{m:}\\| = 1\\}\\)  obliquecomplexfactory(n, m, true) (\\(m\\) normed rows in \\(\\mathbb{C}^n\\))\n\nComplex circle, phases\n\n\\(\\{z\\in\\mathbb{C}^n : |z_1| = \\cdots = |z_n| = 1\\}\\)  complexcirclefactory(n)\n\nPhases of discrete Fourier transform (DFT) of a real vector\n\n\\(\\{z\\in\\mathbb{C}^n : |z_k| = 1, z_{1+\\operatorname{mod}(k, n)} = \\bar{z}_{1+\\operatorname{mod}(n-k, n)} \\ \\forall k\\}\\)  realphasefactory(n)\n\n\n\n\nStiefel, Grassmann and orthonormality\n\nStiefel manifold\n\n\\(\\{X \\in \\mathbb{R}^{n \\times p} : X^\\top X = I_p\\}^k\\)  stiefelfactory(n, p, k)\n\\(\\{X \\in \\mathbb{C}^{n \\times p} : X^*X = I_p\\}^k\\)  stiefelcomplexfactory(n, p, k)\n\nGeneralized Stiefel manifold\n\n\\(\\{X \\in \\mathbb{R}^{n \\times p} : X^\\top BX = I_p\\}\\) for some \\(B \\succ 0\\)  stiefelgeneralizedfactory(n, p, B)\n\nStiefel manifold, stacked\n\n\\(\\{X \\in \\mathbb{R}^{md \\times k} : (XX^\\top)_{ii} = I_d\\}\\)  stiefelstackedfactory(m, d, k)\n\nRotation group\n\n\\(\\{R \\in \\mathbb{R}^{n \\times n} : R^\\top R = I_n, \\det(R) = 1\\}^k\\)  rotationsfactory(n, k)\n\nSpecial Euclidean group (rigid motion)\n\n\\(\\{ (R, t) \\in \\mathbb{R}^{n \\times n} \\times \\mathbb{R}^n : R^\\top R = I_n, \\det(R) = 1 \\}^k\\)  specialeuclideanfactory(n, k)\n\nUnitary matrices\n\n\\(\\{ U \\in \\mathbb{C}^{n \\times n} : U^*U = I_n \\}^k\\)  unitaryfactory(n, k)\n\nGrassmann manifold\n\n\\(\\{\\operatorname{span}(X) : X \\in \\mathbb{R}^{n \\times p}, X^\\top X = I_p\\}^k\\)  grassmannfactory(n, p, k)\n\\(\\{\\operatorname{span}(X) : X \\in \\mathbb{C}^{n \\times p}, X^*X = I_p\\}^k\\)  grassmanncomplexfactory(n, p, k)\n\nGeneralized Grassmann manifold\n\n\\(\\{\\operatorname{span}(X) : X \\in \\mathbb{R}^{n \\times p}, X^\\top BX = I_p\\}\\) for some \\(B \\succ 0\\)  grassmannfactory(n, p, B)\n\n\n\n\nRank constraints\n\nFixed-rank matrices\n\n\\(\\{X \\in \\mathbb{R}^{m \\times n} : \\operatorname{rank}(X) = k\\}\\)  fixedrankembeddedfactory(m, n, k)  fixedrankfactory_2factors(m, n, k)  fixedrankfactory_2factors_preconditioned(m, n, k)  fixedrankfactory_2factors_subspace_projection(m, n, k)  fixedrankfactory_3factors(m, n, k)  fixedrankMNquotientfactory(m, n, k)\n\nFixed-rank tensors, Tucker\n\nTensors of fixed multilinear rank in Tucker format  fixedranktensorembeddedfactory  fixedrankfactory_tucker_preconditioned\n\nFixed-rank tensors, tensor train\n\nTensors of fixed tensor train rank in TT format  fixedTTrankfactory\n\n\nSee more rank-constrained manifolds in the category Positivity constraints.\n\n\nPositivity constraints\n\nMatrices with strictly positive entries\n\n\\(\\{ X \\in \\mathbb{R}^{m\\times n} : X_{ij} &gt; 0 \\ \\forall i, j\\}\\)  positivefactory(m, n)\n\nSymmetric, positive definite matrices\n\n\\(\\{ X \\in \\mathbb{R}^{n\\times n} : X = X^\\top \\textrm{ and } X \\succ 0\\}\\)  sympositivedefinitefactory(n)\n\nSymmetric positive semidefinite, fixed-rank\n\n\\(\\{X \\in \\mathbb{R}^{n \\times n} : X = X^\\top \\succeq 0 \\textrm{ and } \\operatorname{rank}(X) = k\\}\\)  symfixedrankYYfactory(n, k)\n\\(\\{X \\in \\mathbb{C}^{n \\times n} : X = X^* \\succeq 0 \\textrm{ and } \\operatorname{rank}(X) = k\\}\\)  symfixedrankYYcomplexfactory(n, k)\n\nSymmetric positive semidefinite, fixed-rank with unit diagonal\n\n\\(\\{X \\in \\mathbb{R}^{n \\times n} : X = X^\\top \\succeq 0, \\operatorname{rank}(X) = k, \\operatorname{diag}(X) = 1\\}\\)  elliptopefactory(n, k)\n\nSymmetric positive semidefinite, fixed-rank with unit trace\n\n\\(\\{X \\in \\mathbb{R}^{n \\times n} : X = X^\\top \\succeq 0, \\operatorname{rank}(X) = k, \\operatorname{trace}(X) = 1\\}\\)  spectrahedronfactory(n, k)\n\nMultinomial manifold (strict simplex elements)\n\n\\(\\{ X \\in \\mathbb{R}^{n\\times m} : X_{ij} &gt; 0 \\ \\forall i,j \\textrm{ and } X^\\top \\mathbf{1}_m = \\mathbf{1}_n \\}\\)  multinomialfactory(n, m)\n\nMultinomial doubly stochastic manifold\n\n\\(\\{ X \\in \\mathbb{R}^{n\\times n} : X_{ij} &gt; 0 \\ \\forall i,j \\textrm{ and } X \\mathbf{1}_n = \\mathbf{1}_n, X^\\top \\mathbf{1}_n = \\mathbf{1}_n \\}\\)  multinomialdoublystochasticfactory(n)\n\nMultinomial symmetric and stochastic manifold\n\n\\(\\{ X \\in \\mathbb{R}^{n\\times n} : X_{ij} &gt; 0 \\ \\forall i,j \\textrm{ and } X \\mathbf{1}_n = \\mathbf{1}_n, X = X^\\top \\}\\)  multinomialsymmetricfactory(n)\n\nPositive definite simplex\n\n\\(\\{ (X_1, \\ldots, X_k) \\in (\\mathbb{R}^{n \\times n})^k : X_i \\succ 0 \\ \\forall i \\textrm{ and } X_1 + \\cdots + X_k = I_n \\}\\)  sympositivedefinitesimplexfactory(n, k)\n\\(\\{ (X_1, \\ldots, X_k) \\in (\\mathbb{C}^{n \\times n})^k : X_i \\succ 0 \\ \\forall i \\textrm{ and } X_1 + \\cdots + X_k = I_n \\}\\)  sympositivedefinitesimplexcomplexfactory(n, k)\n\n\n\n\nMiscellaneous\n\nConstant manifold (singleton)\n\n\\(\\{ A \\}\\)  constantfactory(A)  This is convenient with productmanifold, to fix some variables.\n\nHyperbolic manifold\n\n\\(\\{ x \\in \\mathbb{R}^{n+1} : x_0^2 = x_1^2 + \\cdots + x_n^2 + 1 \\}^m\\) with Minkowski metric  hyperbolicfactory(n, m)\n\nPoincaré ball\n\n\\(\\{ x \\in \\mathbb{R}^{k} : x^\\top x &lt; 1 \\}^n\\) with Poincaré metric  poincareballfactory(k, n)\n\nEssential manifold\n\nEpipolar constraint between projected points in two perspective views  essentialfactory(k, 'signed') (or unsigned)",
    "crumbs": [
      "Home",
      "Manifolds"
    ]
  },
  {
    "objectID": "manifolds.html#product-manifolds",
    "href": "manifolds.html#product-manifolds",
    "title": "Manifolds",
    "section": "Product manifolds",
    "text": "Product manifolds\nThe tools productmanifold and powermanifold make it easy to work on products of existing manifolds. \nFor example, if you are minimizing a function \\(f(X, Y)\\) where \\(X\\) is a \\(3 \\times 3\\) matrix with unit Frobenius norm and \\(Y\\) is \\(4 \\times 2\\) with orthonormal columns, then use productmanifold as follows:\nelements.X = spherefactory(3, 3);\nelements.Y = stiefelfactory(4, 2);\nM = productmanifold(elements);\nPoints on M are encoded as structures with fields X and Y. Likewise for tangent vectors and vectors in the embedding space.\nIf you are minimizing a function \\(f(X_1, \\ldots, X_7)\\) where each \\(X_i\\) is a \\(3 \\times 4\\) matrix of rank \\(2\\) (the same manifold for each), then use powermanifold as follows:\nN = fixedrankembeddedfactory(3, 4, 2);\nM = powermanifold(N, 7)\nPoints on M are encoded as cells with \\(7\\) entries. Likewise for tangent vectors and vectors in the embedding space.\nOf course, calls to productmanifold and powermanifold can be composed.\nHowever, bear in mind that these tools are provided mostly for convenience. They allow fast prototyping, but it may be possible to write a more efficient factory for your specific product manifold. For example, obliquefactory(n, m) encodes the same geometry as powermanifold(spherefactory(n), m), but the former is more efficient than the latter.\nIf a factory offers built-in support for products, it is highly recommend to prefer that over the tools here. For example, stiefelfactory(n, p, k) encodes the same geometry as powermanifold(stiefelfactory(n, p), k), but the former is more efficient than the latter.",
    "crumbs": [
      "Home",
      "Manifolds"
    ]
  },
  {
    "objectID": "manifolds.html#manifold-structures-whats-in-them",
    "href": "manifolds.html#manifold-structures-whats-in-them",
    "title": "Manifolds",
    "section": "Manifold structures: what’s in them?",
    "text": "Manifold structures: what’s in them?\nThe documentation for a manifold factory should specify\n\nHow points on the manifold are represented numerically,\nHow tangent vectors to the manifold are represented numerically,\nAnd likewise for the embedding space (submanifolds) or total space (quotient manifolds).\n\nTypically, points and tangent vector are represented by matrices, but they could be represented by structures, cells, etc.: there are no limitations. They can even be represented by data on a GPU.\nBased on these, the implementation of a Riemannian manifold is a collection of functions. These functions are collected into a structure: that is what a factory returns as output.\nThese functions are listed below. Not all factories populate all of these fields, and that’s okay: for many purposes, only a subset of these functions are necessary.\nNotice that it is possible to add or replace fields in a manifold structure after it was returned by a factory. Thus, one can easily experiment with various retractions, vector transports, etc. If you find ways to improve the built-in geometries, let us know.\n\nManifolds are encoded as structures which contain fields. Most of these fields are function handles which make it possible to interact with the manifold.\n\n\n\n\n\n\n\nName\nField usage\nFunctionality\n\n\n\n\nName\nM.name()\nName of the manifold as a string.\n\n\nDimension\nM.dim()\nDimension of the manifold.\n\n\nMetric\nM.inner(x, u, v)\nRiemannian metric \\(\\langle u, v \\rangle_x.\\)\n\n\nNorm\nM.norm(x, u)\nRiemannian norm \\(\\|u\\|_x = \\sqrt{\\langle u, u \\rangle_x}.\\)\n\n\nDistance\nM.dist(x, y)\nRiemannian distance \\(\\operatorname{dist}(x, y)\\).\n\n\nTypical distance\nM.typicaldist()\n“Scale” of the manifold. This is used by the trust-regions solver for example, to determine default initial and maximal trust-region radii.\n\n\nTangent space projector\nM.proj(x, u)\nFor manifolds embedded in a Euclidean space, computes the orthogonal projection \\(\\operatorname{Proj}_x u\\) of the vector \\(u\\) from the embedding space to the tangent space at \\(x\\). If M is a quotient manifold, then the projection is from the embedding space of the total space to the horizontal space at \\(x\\).\n\n\nEuclidean to Riemannian gradient\nM.egrad2rgrad(x, egrad)\nFor manifolds embedded in a Euclidean space, converts the gradient of \\(f\\) at \\(x\\) seen as a function in that Euclidean space to the Riemannian gradient of \\(f\\) on the manifold. Allowed to take (storedb, key) as input for caching, but must also allow to be called without it.\n\n\nEuclidean to Riemannian Hessian\nM.ehess2rhess(x, egrad, ehess, u)\nSimilarly to egrad2rgrad, converts the Euclidean gradient and Hessian of \\(f\\) at \\(x\\) along a tangent vector \\(u\\) to the Riemannian Hessian of \\(f\\) at \\(x\\) along \\(u\\) on the manifold. Allowed to take (storedb, key) as input for caching, but must also allow to be called without it. Mind the warning below.\n\n\nTangentialize\nM.tangent(x, u)\nRe-tangentializes a vector. The input is a vector in the tangent vector representation, which possibly (for example because of error accumulations) is no longer tangent. The output is the “closest” tangent vector to the input. If tangent vectors are represented in the ambient space, this is equivalent to proj.\n\n\nTangent to ambient representation\nM.tangent2ambient(x, u)\nTangent vectors are sometimes represented differently from their counterpart in the ambient space. This function returns the ambient space representation of a tangent vector \\(u\\). Useful when defining the Euclidean Hessian ehess for example.\n\n\nExponential map\nM.exp(x, u, t)\nComputes \\(\\operatorname{Exp}_x(tu)\\), the point you reach by following the vector \\(u\\) scaled by \\(t\\) starting at \\(x\\). As of 5.0, this field should only exist if the manifold provides a genuine exponential map. Otherwise, manually fall back to M.retr.\n\n\nRetraction\nM.retr(x, u, t)\nComputes \\(\\Retr_x(tu)\\), where \\(\\Retr\\) is a retraction: a cheaper proxy for the exponential map.\n\n\nLogarithmic map\nM.log(x, y)\nComputes \\(\\operatorname{Log}_x(y)\\), a tangent vector at \\(x\\) pointing toward \\(y\\). This is meant to be the inverse of \\(\\operatorname{Exp}\\).\n\n\nInverse retraction\nM.invretr(x, y)\nComputes the inverse of the retraction: a tangent vector at \\(x\\) pointing toward \\(y\\).\n\n\nRandom point\nM.rand()\nComputes a random point on the manifold.\n\n\nRandom vector\nM.randvec(x)\nComputes a random, unit-norm tangent vector in the tangent space at \\(x\\).\n\n\nZero vector\nM.zerovec(x)\nReturns the zero tangent vector at \\(x\\).\n\n\nLinear combination\nM.lincomb(x, a1, u1, a2, u2)\nComputes \\(v = a_1 u_1 + a_2 u_2\\), where \\(a_1, a_2\\) are scalars and \\(u_1, u_2\\) are tangent vectors at \\(x\\). The inputs \\(a_2, u_2\\) are optional.\n\n\nTransporter\nM.transp(x, y, u)\nComputes a tangent vector at \\(y\\) that “looks like” the tangent vector \\(u\\) at \\(x\\). This is not necessarily a parallel transport. Sometimes called a vector transport.\n\n\nIsometric transport\nM.isotransp(x, y, u)\nAn isometric transporter (few manifold implementations offer this, though for some M.transp is isometric: see their documentation).\n\n\nPair mean\nM.pairmean(x, y)\nComputes the intrinsic mean of \\(x\\) and \\(y\\), that is, a point that lies mid-way between \\(x\\) and \\(y\\) on the geodesic arc joining them.\n\n\nHashing function\nM.hash(x)\nComputes a string that (almost) uniquely identifies the point \\(x\\) and that can serve as a field name for a structure. (No longer used as of Manopt 2.0.)\n\n\nVector representation\nM.vec(x, u)\nReturns a real column-vector representation of the tangent vector \\(u\\). The length of the output is always the same and at least M.dim(). This function is linear and invertible in \\(u\\) on the tangent space at \\(x\\).\n\n\nNormal representation\nM.mat(x, u_vec)\nThe inverse of the vec function: returns a tangent vector representation from a column vector such that M.mat(x, M.vec(x, u)) = u.\n\n\nIsometry check for vec and mat\nM.vecmatareisometries()\nReturns true if M.vec is a linear isometry, i.e., if for all tangent vectors \\(u,v\\), M.inner(x, u, v) == M.vec(x, u).'*M.vec(x, v). Then, M.mat is both the adjoint and the inverse of M.vec (on the tangent space).\n\n\nLie group identity\nM.lie_identity()\nIf the manifold is a Lie group, this function returns the identity element (e.g., for the rotation group in \\(\\mathbb{R}^d\\), that would be the identity matrix of size \\(d\\)).\n\n\n\n\n\n\n\n\n\nMind the details for ehess2rhess\n\n\n\nConsider a Riemannian manifold M embedded in a Euclidean space E. In the call pattern\nrhess = M.ehess2rhess(x, egrad, ehess, u)\nthe vectors egrad and ehess are vectors in the embedding space E, whereas the vectors u and rhess are tangent vectors to M at x. It is important to use the corresponding numerical representations, as documented by the manifold’s factory.\nFor factories which use the same numerical representation for tangent vectors and vectors in the embedding space (e.g., spherefactory), this causes no difficulties. However, for factories such as rotationsfactory, the distinction matters. The functions M.proj (from embedding space to tangent space) and M.tangent2ambient (from tangent space to embedding space) may help.\nIf M is a quotient manifold of a manifold N (called the total space) embedded in E, then egrad and ehess are still vectors in the embedding space E but u and rhess are horizontal vectors at x. For example, grassmannfactory(n, p) is a quotient of stiefelfactory(n, p) which is embedded in \\(\\mathbb{R}^{n \\times p}\\). Since stiefelfactory(n, p) uses the same representation for tangent vectors and vectors in the embedding space, there is no friction for that one either.",
    "crumbs": [
      "Home",
      "Manifolds"
    ]
  },
  {
    "objectID": "learning.html",
    "href": "learning.html",
    "title": "Resources to learn optimization on manifolds",
    "section": "",
    "text": "The documentation on this website is meant to help users get to grips with Manopt. Underneath the software, there is a fair amount of math. This page provides some pointers to learn that theory.\n\nBooks\nThe following books (both available online for free) can be helpful to learn the relevant mathematics:\n\n\n\n\n\n\n An introduction to optimization on smooth manifolds  Nicolas Boumal, Cambridge University Press, 2023.\n\n\n Optimization algorithms on matrix manifolds  Pierre-Antoine Absil, Robert Mahony and Rodolphe Sepulchre, Princeton University Press, 2008.\n\n\n\n\n\nA full course\n\nMATH-512 at EPFL: this is a full set of video lectures, slides and exercises (with hints and solutions).\nedX course: this covers the first six weeks of MATH-512, on the edX platform.\n\n\n\nTutorial videos\n\nThis one-hour video and this two-hour video introduce the basics of differential geometry and Riemannian geometry for optimization on smooth manifolds. They cover more or less the same contents. The slides have been augmented for a longer in-person tutorial.\nWeek 5 of MATH-512 includes a lecture about Manopt: the basics and a bit more.\n\n\n\nBlogs and blog posts\n\nThe Race to the bottom blog about nonconvex optimization features some Riemannian optimization.\nThis blog post gives an informal overview of optimization on manifolds.\n\n\n\nCode examples\n\nSee the examples that ship with Manopt."
  },
  {
    "objectID": "gettingstarted.html",
    "href": "gettingstarted.html",
    "title": "Getting started",
    "section": "",
    "text": "With Manopt, you can solve optimization problems on manifolds and on linear spaces (e.g., matrix spaces) using state-of-the-art algorithms, with minimal effort. The toolbox targets great flexibility in the problem description and comes with advanced features, such as caching and automatic differentiation.\nThe toolbox architecture is based on a separation of the manifolds, the solvers and the problem descriptions. For basic use, one only needs to pick a manifold from the library, describe the cost function (and possible derivatives) and pass it on to a solver. Accompanying tools help the user in common tasks such as numerically checking the derivatives, plotting the cost function, computing eigenvalues of the Hessian etc.\nThis is a prototyping toolbox, built on the premise that the costly part of solving an optimization problem is querying the cost function, and not the inner machinery of the solver. It is also work in progress: feedback and contributions are welcome!\nMailing list Consider registering as a user to hear about updates.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#manopts-purpose-and-design",
    "href": "gettingstarted.html#manopts-purpose-and-design",
    "title": "Getting started",
    "section": "",
    "text": "With Manopt, you can solve optimization problems on manifolds and on linear spaces (e.g., matrix spaces) using state-of-the-art algorithms, with minimal effort. The toolbox targets great flexibility in the problem description and comes with advanced features, such as caching and automatic differentiation.\nThe toolbox architecture is based on a separation of the manifolds, the solvers and the problem descriptions. For basic use, one only needs to pick a manifold from the library, describe the cost function (and possible derivatives) and pass it on to a solver. Accompanying tools help the user in common tasks such as numerically checking the derivatives, plotting the cost function, computing eigenvalues of the Hessian etc.\nThis is a prototyping toolbox, built on the premise that the costly part of solving an optimization problem is querying the cost function, and not the inner machinery of the solver. It is also work in progress: feedback and contributions are welcome!\nMailing list Consider registering as a user to hear about updates.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#download",
    "href": "gettingstarted.html#download",
    "title": "Getting started",
    "section": "Download",
    "text": "Download\nThere are two ways to get Manopt:\nDownload Download the latest packaged version (v7.1, Sep. 30, 2022).\n GitHub Clone the GitHub repository to use the latest updates as they roll out.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#install",
    "href": "gettingstarted.html#install",
    "title": "Getting started",
    "section": "Install",
    "text": "Install\n\nEither clone or unzip the whole manopt directory you just downloaded in a location of your choice, say, in /my/directory/.\nGo to /my/directory/manopt/ at the Matlab prompt and execute importmanopt.\nYou will be asked whether you want to save this path for your next Matlab sessions. If you reply Y (yes) and you have the rights to run savepath, then you won’t need to go through these steps next time you open Matlab.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#check",
    "href": "gettingstarted.html#check",
    "title": "Getting started",
    "section": "Check",
    "text": "Check\nGo to /my/directory/manopt/checkinstall/ and run the script basicexample.m. If there are no errors, you are done! Otherwise, feel free to report issues on the forum.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#move-on-to-the-first-example",
    "href": "gettingstarted.html#move-on-to-the-first-example",
    "title": "Getting started",
    "section": "Move on to the first example",
    "text": "Move on to the first example\nThis tutorial provides detailed instructions from zero to the advanced features of Manopt. Check out a first example to get a feel for how things work, then continue through the detailed documentation.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#dig-into-more-advanced-examples",
    "href": "gettingstarted.html#dig-into-more-advanced-examples",
    "title": "Getting started",
    "section": "Dig into more advanced examples",
    "text": "Dig into more advanced examples\nYou may find it helpful to look through the examples that ship with Manopt.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "gettingstarted.html#learn-more-of-the-math",
    "href": "gettingstarted.html#learn-more-of-the-math",
    "title": "Getting started",
    "section": "Learn more of the math",
    "text": "Learn more of the math\nSee our pointers for helpful learning resources including video lectures and books.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "firstexample.html",
    "href": "firstexample.html",
    "title": "A first example",
    "section": "",
    "text": "Let us first illustrate the most commonly useful features of Manopt using a standard optimization problem on a sphere.",
    "crumbs": [
      "Home",
      "A first example"
    ]
  },
  {
    "objectID": "firstexample.html#the-math",
    "href": "firstexample.html#the-math",
    "title": "A first example",
    "section": "The math",
    "text": "The math\nLet \\(A \\in \\mathbb{R}^{n\\times n}\\) be a symmetric matrix. The eigenvectors of \\(A\\) associated to its largest eigenvalue are known to be the optimizers for the following optimization problem:\n\\[\\max\\limits_{x\\in\\mathbb{R}^n, x \\neq 0} \\frac{x^\\top A x}{x^\\top x}.\\]\nThe cost function is insensitive to the norm of \\(x\\), hence we might as well fix it to \\(x^\\top x = \\|x\\|^2 = 1\\). Also, we would like to have a minimization problem rather than a maximization problem (we’ll see why in a moment). Accordingly, we flip the sign of the cost function. In the end, we want to solve:\n\\[\\min\\limits_{x\\in\\mathbb{R}^n, \\|x\\| = 1} -x^\\top A x.\\]\nThe cost function and its gradient in \\(\\mathbb{R}^n\\) are:\n\\[  \n\\begin{align*}\n    f(x) = -x^\\top A x, &&\n    \\nabla f(x) = -2Ax.\n\\end{align*}\n\\]\n(See the matrix calculus website for help with figuring out gradients. You can also learn the math to do these computations in Section 4.7 of this book.)\nThe constraint on the vector \\(x\\) tells us that \\(x\\) is a point on the sphere (one of the nicest manifolds):\n\\[\\mathbb{S}^{n-1} = \\{x \\in \\mathbb{R}^n : x^\\top x = 1\\}.\\]\nThis is all the information we need to apply Manopt to our problem. For additional theory, see the cost function page and the learning page.",
    "crumbs": [
      "Home",
      "A first example"
    ]
  },
  {
    "objectID": "firstexample.html#the-code",
    "href": "firstexample.html#the-code",
    "title": "A first example",
    "section": "The code",
    "text": "The code\nSolving this optimization problem using Manopt requires a few lines of Matlab code. Here they are, and explanations follow.\n% Generate random problem data.\nn = 1000;\nA = randn(n);\nA = .5*(A+A');\n\n% Create the problem structure.\nmanifold = spherefactory(n);\nproblem.M = manifold;\n\n% Define the problem cost function and its Euclidean gradient.\nproblem.cost  = @(x) -x'*(A*x);\nproblem.egrad = @(x) -2*A*x;      % notice the 'e' in 'egrad' for Euclidean\n\n% Numerically check gradient consistency (just once, optional).\ncheckgradient(problem); pause;\n\n% Solve.\n[x, xcost, info, options] = trustregions(problem);\n\n% Display some statistics.\nfigure;\nsemilogy([info.iter], [info.gradnorm], '.-');\nxlabel('Iteration number');\nylabel('Norm of the Riemannian gradient of f');\nLet us look at the code bit by bit. First, we generate some data for our problem. Then, we execute these two lines:\nmanifold = spherefactory(n);\nproblem.M = manifold;\nThe call to spherefactory returns a structure describing the manifold \\(\\mathbb{S}^{n-1}\\), i.e., the sphere. This manifold corresponds to the constraint appearing in our optimization problem. For other constraints, take a look at the various supported manifolds.\nThe second instruction creates a structure named problem and sets the field problem.M to contain the manifold structure.\nThe problem structure is further populated with everything a solver might need to know about the problem in order to solve it, such as the cost function and its gradient:\nproblem.cost  = @(x) -x'*(A*x);\nproblem.egrad = @(x) -2*A*x;\nThe cost function and its derivatives are specified as function handles. Notice how the gradient was specified as the Euclidean gradient of \\(f\\), i.e., \\(\\nabla f(x) = -2Ax\\) in the function egrad (mind the e). The conversion to the Riemannian gradient happens automatically behind the scene. This is especially useful with more complicated manifolds.\nWe could also define the cost and its derivatives in several other ways, e.g., to avoid the redundant computation of the product A*x: see the cost description page. In particular, with Manopt 7.0 and Matlab R2021a or later, if you have the Deep Learning Toolbox, then you can also use automatic differentiation (AD) instead of defining the gradient (and even the Hessian) yourself:\n% problem.egrad = @(x) -2*A*x; -- we can replace that line with:\nproblem = manoptAD(problem); % automatic differentiation\nSee the cost description page for more information. Keep in mind that, while AD is convenient and reasonably efficient, it is usually slower than (good) hand-written code. \nThe next instruction is not needed to solve the problem but often helps at the prototyping stage:\ncheckgradient(problem);\nThe checkgradient tool verifies numerically that the cost function and its gradient agree up to the appropriate order. See the tools page for further details and more helpful tools offered by Manopt. This tool generates the following figure:\n\n\n\nThe checkgradient tool outputs a figure and text in the command line. In the figure here, we see that part of the continuous curve has a slope that matches that of the dashed line: that’s what we like to see. If not, then it is likely that the gradient is incorrectly implemented. Try it: change problem.egrad to @(x) A*x for example and see what happens.\n\n\nThe blue curve seems to have the same slope as the dashed line over a decent segment (highlighted in orange): that’s what we want to see. Also check the text output in the command prompt.\nWe now run one of the solvers on our problem:\n[x, xcost, info, options] = trustregions(problem);\nThis instruction calls trustregions, without initial guess and without options structure. As a result, the solver generates a random initial guess automatically and resorts to the default values for all options. As a general feature in Manopt, all options are, well, optional.\n\n\n\n\n\n\nManopt always minimizes\n\n\n\nAll solvers in Manopt aim to minimize the cost function in the problem structure. If you want to maximize a function, do as we did earlier on this page: flip the sign of \\(f\\) (and likewise for its derivatives).\n\n\nThe returned values are:\n\nx: usually an approximate local minimizer of the cost function,\nxcost: the value of \\(f\\) at x,\ninfo: a struct-array containing information about the successive iterations performed by the solver, and\noptions: a structure containing the options used and their values: peek inside to find out what you can parameterize.\n\nFor more details and more solvers, see the solvers page.\nThis call issues a warning:\n\nWarning: No Hessian provided. Using FD approximation.\n\nThat is because the trust-regions algorithm normally requires the Hessian of the cost function to be provided in the problem structure. When the Hessian is not provided, Manopt approximates it using finite differences on the gradient and it warns you about it. This is mostly fine. You may disable this warning by calling warning('off', 'manopt:getHessian:approx');.\nFinally, we access the contents of the struct-array info to display a convergence plot:\nsemilogy([info.iter], [info.gradnorm], '.-');  \nxlabel('Iteration number');  \nylabel('Norm of the gradient of f');\nThis generates the following figure. For more information on what data is stored in info, look inside and see the solvers page.\n\n\n\nThe Riemannian gradient norm is converging to zero fast: that’s what we like to see.\n\n\n\n\n\n\n\n\ninfo is a struct-array\n\n\n\nNotice that we write [info.xyz] with brackets, and not simply info.xyz. This is because info is a struct-array. Read this MathWorks blog post for further information.\n\n\n\n\n\n\n\n\nYou may omit the gradient, but…\n\n\n\nIn the example above, we specified the gradient but not the Hessian. As a result, Manopt automatically uses finite differences (FD) to approximate the Hessian if needed. This is fine.\nIf we also do not specify the gradient, then Manopt approximates that with FD as well. The solver will run, but this is slow. The approximation is good enough that it is convenient to have as a feature for prototyping on low-dimensional manifolds, but it should not be used for anything serious. If you do, you may want to set options.tolgradnorm to a larger value (say, 1e-4) and pass the options structure to the solver.",
    "crumbs": [
      "Home",
      "A first example"
    ]
  },
  {
    "objectID": "download.html",
    "href": "download.html",
    "title": "Downloading the latest release of Manopt",
    "section": "",
    "text": "Your download should start now. Click this link if not.\nPlease consider registering to our mailing list for updates – historically, less than one e-mail per year."
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core tools (internals)",
    "section": "",
    "text": "This page lists the core tools of Manopt. They are mostly relevant for users who develop solvers and tools (but not only).",
    "crumbs": [
      "Home",
      "Core tools"
    ]
  },
  {
    "objectID": "core.html#getxyz",
    "href": "core.html#getxyz",
    "title": "Core tools (internals)",
    "section": "getXYZ",
    "text": "getXYZ\nIn our discussion of how to implement cost functions, we already noted that it is best to use the tools getCost, getGradient and getHessian to evaluate \\(f\\) and its derivatives, as opposed to calling problem.cost or problem.grad directly. The main reason for this is that users have many choices available for how to implement these objects. For example, problem.cost may not exist if the user opted to define problem.costgrad instead.\nThe inputs storedb and key are usually optional. It is a good idea to pass them if they are available, as this allows for caching to be used.\n\ncost = getCost(problem, x, storedb, key)\n[cost, grad] = getCostGrad(problem, x, storedb, key)\ngrad = getGradient(problem, x, storedb, key)\nagrad = getApproxGradient(problem, x, storedb, key)\npgrad = getPartialGradient(problem, x, I, storedb, key)\negrad = getEuclideanGradient(problem, x, storedb, key)\npgrad = getPartialEuclideanGradient(problem, x, I, storedb, key)\nsubgrad = getSubgradient(problem, x, tol, storedb, key)\ndiff = getDirectionalDerivative(problem, x, d, storedb, key)\nhess = getHessian(problem, x, d, storedb, key)\nhessfd = getHessianFD(problem, x, d, storedb, key)\napproxhess = getApproxHessian(problem, x, d, storedb, key)\nt = getLinesearch(problem, x, d, storedb, key)\nPd = getPrecon(problem, x, d, storedb, key)\nsqrtPd = getSqrtPrecon(problem, x, d, storedb, key)",
    "crumbs": [
      "Home",
      "Core tools"
    ]
  },
  {
    "objectID": "core.html#cangetxyz",
    "href": "core.html#cangetxyz",
    "title": "Core tools (internals)",
    "section": "canGetXYZ",
    "text": "canGetXYZ\nFunctions called canGetXYZ output true if the problem structure provides sufficient information for Manopt to compute XYZ exactly. They output false otherwise.\nIf false is returned, that does not imply a call to getXYZ will fail. For example, if the problem structure specifies the gradient via problem.grad but it does not provide the Hessian, then there is not enough information to compute the exact Hessian. Accordingly, canGetHessian(problem) ouputs false. Yet, a call to getHessian(problem, x, u) does produce something; namely, a finite difference approximation of the Hessian for the provided inputs.\nTypically, solvers and tools call canGetXYZ functions to assess what can be done with the given problem structure. They issue appropriate warnings as needed, then often proceed to call the getXYZ functions anyway. The general philosophy is that Manopt tries to do its best to answer the question asked, with the caveat that it might be slow or inaccurate. If so, tools and solvers normally give a heads up to that effect.\n\ncandoit = canGetCost(problem)\ncandoit = canGetDirectionalDerivative(problem)\ncandoit = canGetGradient(problem)\ncandoit = canGetApproxGradient(problem)\ncandoit = canGetPartialGradient(problem)\ncandoit = canGetEuclideanGradient(problem)\ncandoit = canGetPartialEuclideanGradient(problem)\ncandoit = canGetSubgradient(problem)\ncandoit = canGetHessian(problem)\ncandoit = canGetApproxHessian(problem)\ncandoit = canGetPrecon(problem)\ncandoit = canGetSqrtPrecon(problem)\ncandoit = canGetLinesearch(problem)",
    "crumbs": [
      "Home",
      "Core tools"
    ]
  },
  {
    "objectID": "core.html#helpers-for-solvers",
    "href": "core.html#helpers-for-solvers",
    "title": "Core tools (internals)",
    "section": "Helpers for solvers",
    "text": "Helpers for solvers\nWhen developing solvers (optimization algorithms), it is usually necessary to call these tools:\n\nopts = getGlobalDefaults()\nopts = mergeOptions(opts1, opts2)\nstats = applyStatsfun(problem, x, storedb, key, options, stats)\n[stop, reason] = stoppingcriterion(problem, x, options, info, last)\n[newx, newkey, info, hooked] = applyHook(problem, x, storedb, key, options, info, last) (less common)\n\nFor an example, read through the code of an existing solver, e.g., steepestdescent.",
    "crumbs": [
      "Home",
      "Core tools"
    ]
  },
  {
    "objectID": "core.html#caching-system",
    "href": "core.html#caching-system",
    "title": "Core tools (internals)",
    "section": "Caching system",
    "text": "Caching system\nThe caching system is described on this page. Internally, it is handled with the StoreDB class whose code is here.\n\nstoredb = StoreDB()\n\nThe class inherits from handle_light, whose code is here. The latter comes from a StackOverflow post by user sclarke81.",
    "crumbs": [
      "Home",
      "Core tools"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of Manopt is to facilitate experimentation with optimization on manifolds, as well as sharing geometries and algorithms.\nThe Matlab version of Manopt is developed by Nicolas Boumal and Bamdev Mishra. The toolbox originated in 2012 within the RANSO group, led by Pierre-Antoine Absil, Yurii Nesterov and Rodolphe Sepulchre. See also PyManopt.org and Manoptjl.org for information about the Python and Julia versions of Manopt.\nThe toolbox is stable and can be used right away. Being research software, it is also perpetually work in progress. We welcome contributions, bug reports and feedback. Let us know what you think!\nIf you use the Matlab version of Manopt, please cite the paper. Notice the ‘o’ in Manopt is lowercase.\nResearchers develop new solvers and geometries all the time. It is important for them that their work be credited properly. Please cite the relevant papers for the solvers and geometries you are using, as they may have been contributed by different authors. See the comments at the beginning of the m-files for instructions. Likewise, please cite the PyManopt and Manopt.jl papers if you use the Python or Julia versions. Thank you.\nManopt won the ORBEL Wolsey Award 2014 for best operational research software developed as part of a PhD thesis."
  },
  {
    "objectID": "about.html#authorship-and-contributors",
    "href": "about.html#authorship-and-contributors",
    "title": "About",
    "section": "Authorship and contributors",
    "text": "Authorship and contributors\nThe original design, code and documentation of the toolbox is due to Nicolas Boumal. The design of the toolbox was imagined with Pierre Borckmans, who also contributed the PSO solver. The main developers are Nicolas and Bamdev Mishra. The RANSO group (Pierre-Antoine Absil, Yurii Nesterov and Rodolphe Sepulchre) provided helpful support and guidance at the onset.\nThe GenRTR code by Chris Baker, Pierre-Antoine Absil and Kyle Gallivan was modified to become the trustregions solver. The latter is arguably the most important solver in the toolbox so far, hence Chris and his colleagues merit special credit. We thank them for releasing their excellent software under an open source license, which allowed us to build upon it.\nBart Vandereycken helped a lot in revising the geometry file fixedrankembeddedfactory, as per his paper. Eitan Levin added some numerical tweaks to the retraction that make it more robust close to “the brink” (matrices of lower rank), though also a bit slower to compute.\nHiroyuki Sato contributed the complex version of the Stiefel manifold, stiefelcomplexfactory as well as the complex Grassmann manifold, grassmanncomplexfactory. These geometries are partly exposed in his paper.\nRoberto Tron contributed code for Riemannian geometries of the essential manifold, an important manifold in computer vision to handle relative camera information. He describes this geometry in his paper with Kostas Daniilidis.\nSarod Yatawatta contributed a factory for complex, Hermitian positive semidefinite matrices of fixed rank, symfixedrankYYcomplexfactory. This geometry appears in a paper.\nHiroyuki Kasai, together with Bamdev, contributed fixedrankfactory_tucker_preconditioned, a geometry for tensors in Tucker format with fixed multilinear rank. This and the accompanying example is based on their paper. Both, together with Hiroyuki Sato, also contributed the stochasticgradient solver.\nChangshuo Liu contributed the Riemannian limited-memory BFGS solver, rlbfgs.\nMargherita Porcelli and Bruno Iannazzo contributed the Barzilai-Borwein solver, barzilaiborwein.\nJesus Briales contributed valuable improvements to the code via pull requests on GitHub.\nAhmed Douik contributed factories for doubly stochastic matrices, symmetric (multinomialsymmetricfactory) and non-symmetric (multinomialdoublystochasticfactory), as well as an example (doubly_stochastic_denoising) and documentation for these.\nNaman Agarwal, Brian Bullins and Coralia Cartis, together with Nicolas, contributed an implementation for the new solver arc (adaptive regularization with cubics), and Bryan Zhu contributed the nonlinear CG-based subproblem solver.\nGennadij Heidel contributed a factory for tensors of fixed multilinear rank in Tucker format: fixedranktensorembeddedfactory.\nEstelle Massart contributed code to symfixedrankYYfactory.\nRonny Bergmann contributed code to multinomialfactory.\nMichael Psenka contributed the code for optimization over tensors with fixed tensor-train rank, accessible through fixedTTrankfactory, together with an example script. This geometry heavily relies on TTeMPS for all core functionalities except second-order optimization (specifically, M.ehess2rhess). TTeMPS is code distributed by Michael Steinlechner, Daniel Kressner and Bart Vandereycken. We thank them for releasing their excellent software under an open source license, which allowed us to build upon it. It is packaged in Manopt with small modifications.\nQuentin Rebjock contributed poincareballfactory and more.\nXiaowen Jiang worked in the group of Nicolas during the summer of 2021 to add support for automatic differentiation, based on Matlab’s Deep Learning Toolbox. This fantastic feature aligns well with Manopt’s overarching goal: to lower the entrance barrier for people who would like to give Riemannian optimization a try. It is available via manoptAD. Thanks a lot, Xiaowen!\nNiklas Koep (sinxoverx), Nick Vannieuwenhoven (Storey-Liu for CG), Spencer Kraisler (Rodrigues formula, Lie identity), sfrcorne (rlbfgs invariant to positive scaling) brought welcome improvements after discussions on the github repo page.\nVictor Liao worked on Manopt in the group of Nicolas during the summer of 2022 and contributed: a long-awaited refactoring of the trustregions solver to allow for various subproblem solvers, a rewrite of the truncated CG (tCG) subproblem solver to improve performance by recycling computations after a step rejection, a new global subproblem solver based on code by Yuji Nakatsukasa, a constant step-size line-search helper for gradient methods, and various improvements (e.g., to tangentorthobasis).\nBelow are some third-party open-source codes that are or were used at some point:\n\nThe multitransp / multiprod pair is code by Paolo de Leva (no longer used: multiprod now calls pagemtimes);\nmultitrace is a wrapper around diagsum, which is code by Wynton Moore ;\nThe hashmd5 tool is a stripped version of more general hashing code (no longer available) by Michael Kleder. It is no longer used."
  },
  {
    "objectID": "about.html#how-to-contribute",
    "href": "about.html#how-to-contribute",
    "title": "About",
    "section": "How to contribute",
    "text": "How to contribute\nPlease send a pull request on github for all contributions, big and small.\nManopt is meant to ease the sharing of geometries and solvers. If you developed a Riemannian geometry, a solver or some other tool for optimization on manifolds and would like it to be featured in Manopt,\nYou should include:\n\nAn implementation of your manifold / solver / tool in the Manopt format.\nAn example script to illustrate its features.\nAmple in-code documentation.\n\nWe will gladly help: discussions can take place along your PR on github or prior to that on the forum.\nThe documentation page as well as the code will, of course, visibly reflect the authors of the contribution as well as relevant publications.\nContributors agree to the terms of the Contributor License Agreement. This agreement protects you as a contributor by making it clear that you retain your right to use your own contributions for any other purpose (you retain the copyrights). This agreement protects us as maintainers by authorizing us to distribute the toolbox under a unified license."
  },
  {
    "objectID": "about.html#license",
    "href": "about.html#license",
    "title": "About",
    "section": "License",
    "text": "License\nManopt, a Matlab toolbox for optimization on manifolds, is copyright by Nicolas Boumal and is distributed under the terms of the GNU General Public License (GPL) version 3 (or later). Contributed and third-party code is copyrighted by their respective authors, but is distributed under a unified license for the whole Manopt toolbox.\nIn short, this means that everyone is free to use Manopt, to modify it and to redistribute it on a free basis. Manopt is not in the public domain; it is copyrighted and there are restrictions on its distribution (see the license and the related frequently asked questions). For example, you cannot integrate this version of Manopt (in full or in parts) in any closed-source software you plan to distribute (commercially or not). Please contact us for more information.\nThe documentation of Manopt (this website) is copyright by Nicolas Boumal, all rights reserved."
  },
  {
    "objectID": "about.html#related-software",
    "href": "about.html#related-software",
    "title": "About",
    "section": "Related software",
    "text": "Related software\nManopt exists in three versions (which differ significantly):\n\nManopt itself usually refers to the Matlab version (this website).\nPyManopt is a Python version led by Jamie Townsend, Niklas Koep and Sebastian Weichwald.\nManopt.jl is a Julia version led by Ronny Bergmann.\n\nYou may also be interested in the following:\n\nGenRTR is the Generic Riemannian Trust-Region package for Matlab (it is included in modified form in Manopt).\nROPTLIB is a Riemannian optimization package in C++ (with mex interface to Matlab), by Wen Huang and Kyle Gallivan ; Ankit Rathore started a Python version.\nManifoldOptim is an R interface to ROPTLIB.\nGeomstats is a Python toolbox with lots of differential geometric tools.\nMcTorch is a Python library for optimization on manifolds dedicated to deep learning, built on PyTorch.\nRieoptax is library for Riemannian Optimization in JAX.\nGeoopt is also a Python library bringing Riemannian optimization tools to PyTorch.\nGOPT is designed for optimization over positive definite matrices.\nCDOpt is a Python toolbox for optimization on Riemannian manifolds with supports for deep learning.\nSGMIN performs Stiefel-Grassmann optimization.\nQGOpt extends TensorFlow to Riemannian manifolds that often arise in quantum mechanics.\nGrassmannOptim is an R-package for optimization on the Grassmann manifold.\nOptman hosts a collection of algorithms for optimization with orthogonality constraints.\nTraian Abrudan has code for optimization under unitary matrix constraints.\nLORM is a C++ toolbox for global optimization of polynomials on the sphere and the special orthogonal group.\nOptim.jl in Julia now supports certain embedded manifolds, though it appears that this is not technically Riemannian optimization.\nManifolds.jl is a Julia toolbox to work with manifolds: Manopt.jl is tightly connected to that project.\n\nShould we list your code? Let us know!"
  },
  {
    "objectID": "about.html#about-the-website",
    "href": "about.html#about-the-website",
    "title": "About",
    "section": "About the website",
    "text": "About the website\nThis website is statically generated with Quarto and uses MathJax to display math."
  },
  {
    "objectID": "costdescription.html",
    "href": "costdescription.html",
    "title": "Describing the cost function",
    "section": "",
    "text": "An optimization problem in Manopt is represented as a problem structure. The latter must include a field problem.M which contains a structure describing a manifold, as obtained from a factory. On top of this, the problem structure must include some fields that describe the cost function \\(f\\) to be minimized and, possibly, its derivatives. This is done with function handles.\nThe solvers do not query these function handles directly. Instead, they call core (internal) tools such as getCost, getGradient, getHessian, etc. These tools consider the available fields in the problem structure and “do their best” to return the requested object.\nAs a result, we gain great flexibility in the cost function description. Indeed, as the needs grow during the life-cycle of the toolbox and new ways of describing the cost function become necessary, it suffices to update the core get* tools to take these new ways into account. This has made it much easier over time to incorporate (and improve) caching. Also, if a solver requests an object that is not available, then Manopt can automatically fall back to an approximation. \n\n\n\n\n\n\nTry to provide the gradient\n\n\n\nIf you do not provide the gradient and a solver queries it, then Manopt falls back to finite differences of the cost function to approximate the Riemannian gradient. This requires building an orthonormal basis for the tangent space (that’s expensive) and then querying the cost function value along each basis vector (that’s \\(\\dim \\mathcal{M}\\) calls). Solvers will still run, but this feature is included only for convenience when prototyping.\n\n\n\n\n\n\n\n\nIt’s fine to omit the Hessian\n\n\n\nIf you do not provide the Hessian and a solver queries it, then Manopt falls back to finite differences of the gradient to approximate the Hessian. This is typically good enough, and often has a computational cost similar to evaluating the true Hessian. You can control this further with approxhessianFD.\n\n\n\n\n\n\n\n\nCheck your derivatives\n\n\n\nRegardless of how you implement the gradient, make sure to check that it is correct by running checkgradient(problem) at least once. Likewise, check the Hessian with checkhessian(problem). See the tools page for more.",
    "crumbs": [
      "Home",
      "Cost functions"
    ]
  },
  {
    "objectID": "costdescription.html#general-philosophy",
    "href": "costdescription.html#general-philosophy",
    "title": "Describing the cost function",
    "section": "",
    "text": "An optimization problem in Manopt is represented as a problem structure. The latter must include a field problem.M which contains a structure describing a manifold, as obtained from a factory. On top of this, the problem structure must include some fields that describe the cost function \\(f\\) to be minimized and, possibly, its derivatives. This is done with function handles.\nThe solvers do not query these function handles directly. Instead, they call core (internal) tools such as getCost, getGradient, getHessian, etc. These tools consider the available fields in the problem structure and “do their best” to return the requested object.\nAs a result, we gain great flexibility in the cost function description. Indeed, as the needs grow during the life-cycle of the toolbox and new ways of describing the cost function become necessary, it suffices to update the core get* tools to take these new ways into account. This has made it much easier over time to incorporate (and improve) caching. Also, if a solver requests an object that is not available, then Manopt can automatically fall back to an approximation. \n\n\n\n\n\n\nTry to provide the gradient\n\n\n\nIf you do not provide the gradient and a solver queries it, then Manopt falls back to finite differences of the cost function to approximate the Riemannian gradient. This requires building an orthonormal basis for the tangent space (that’s expensive) and then querying the cost function value along each basis vector (that’s \\(\\dim \\mathcal{M}\\) calls). Solvers will still run, but this feature is included only for convenience when prototyping.\n\n\n\n\n\n\n\n\nIt’s fine to omit the Hessian\n\n\n\nIf you do not provide the Hessian and a solver queries it, then Manopt falls back to finite differences of the gradient to approximate the Hessian. This is typically good enough, and often has a computational cost similar to evaluating the true Hessian. You can control this further with approxhessianFD.\n\n\n\n\n\n\n\n\nCheck your derivatives\n\n\n\nRegardless of how you implement the gradient, make sure to check that it is correct by running checkgradient(problem) at least once. Likewise, check the Hessian with checkhessian(problem). See the tools page for more.",
    "crumbs": [
      "Home",
      "Cost functions"
    ]
  },
  {
    "objectID": "costdescription.html#one-example-five-ways",
    "href": "costdescription.html#one-example-five-ways",
    "title": "Describing the cost function",
    "section": "One example, five ways",
    "text": "One example, five ways\nSimilarly to the first example, consider minimizing \\[\n  f(x) = \\frac{1}{2} x^\\top A x\n\\] for \\(x\\) on the unit sphere in \\(\\mathbb{R}^n\\), where \\(A\\) is a symmetric matrix. The base code could look something like this:\nn = 1000;\nA = randsym(n);\nproblem.M = spherefactory(n);\n\n% ... define the cost: see below\n\nx = trustregions(problem);\nThe cost function can be specified by adding fields to the problem structure. Let us go through a few different ways to do that.\n\nThe common way: via Euclidean extension\nIf we think of \\(f\\) as a function on \\(\\mathbb{R}^n\\) (ignoring the restriction to the sphere), then the gradient and Hessian of \\(f\\) are easily derived: \\[\n\\begin{align}\n  \\nabla f(x) = Ax, && \\nabla^2 f(x)[u] = Au.\n\\end{align}\n\\] We think of this approach as “extending” the function from the sphere to the embedding space, which is the Euclidean space \\(\\mathbb{R}^n\\). You can tell Manopt what the gradient and Hessian for that Euclidean extension are using the fields egrad and ehess, as follows (mind the e for Euclidean or embedding):\nproblem.cost = @(x) .5*x'*A*x;\nproblem.egrad = @(x) A*x;\nproblem.ehess = @(x, u) A*u; % optional\nManopt takes care of converting these to the Riemannian gradient and Hessian of \\(f\\) on the sphere, using problem.M.egrad2rgrad and problem.M.ehess2rhess: this is automatic.\nA few comments:\n\nIt is fine to omit ehess, but try not to omit egrad (see earlier comments).\nThe computation A*x is redundant between cost and egrad: more on this later.\nThe input to egrad is a point \\(x\\). The output is a vector in the embedding space, corresponding to \\(\\nabla f(x)\\).\nThe inputs to ehess are a point \\(x\\) and a tangent vector \\(u\\) at \\(x\\). The output is a vector in the embedding space, corresponding to \\(\\nabla^2 f(x)[u]\\). \n\nMind the distinction between tangent vectors and vectors in the embedding space. For many manifolds, these are numerically represented in the same way, so the distinction does not matter (e.g., for spherefactory and stiefelfactory). However, some manifolds use different numerical representations (e.g., rotationsfactory). For those, you may want to call M.tangent2ambient(x, u) to obtain the embedding space equivalent of u. Read the help section of your manifold factory to make sure.\n\n\nCoding the Riemannian derivatives manually\nThere are instances where it is more natural or more efficient to describe the Riemannian derivatives directly (as opposed to the Euclidean extension approach), though this is not common.\nOne example where this is preferred is when computing an intrinsic mean. There, the cost function involves the squared Riemannian distance, whose Riemannian gradient is the logarithmic map.\nIn our running example, the sphere is a Riemannian submanifold of \\(\\mathbb{R}^n\\). Therefore,\n\nThe Riemannian gradient is the orthogonal projection of \\(\\nabla f(x)\\) to the tangent space at \\(x\\) (see Proposition 3.61 in this book). The projector is available in problem.M.proj: \\[\\grad f(x) = \\Proj_x(\\nabla f(x)).\\]\nThe Riemannian Hessian at \\(x\\) along \\(u\\) is the projection of the derivative of the Riemannian gradient at \\(x\\) along \\(u\\) (see Corollary 5.16 in the same book): \\[\\Hess f(x)[u] = \\Proj_x(\\D\\grad f(x)[u]).\\]\n\nFor the unit sphere, \\(\\Proj_x(u) = u - (x^\\top u)x\\). It is then an exercise to work out the expressions above.\nYou can specify the Riemannian gradient and Hessian using the fields grad and hess (no e), as follows:\nproblem.cost = @(x) .5*x'*A*x;\nproblem.grad = @(x) problem.M.proj(x, A*x);\nproblem.hess = @(x, u) problem.M.proj(x, A*u - (x'*A*x)*u); % optional\nSome comments:\n\nAgain, it is fine to omit hess, but try not to omit grad (see earlier comments).\nThe input to grad is a point \\(x\\). The output is a tangent vector at \\(x\\), corresponding to \\(\\grad f(x)\\).\nThe inputs to hess are a point \\(x\\) and a tangent vector \\(u\\) at \\(x\\). The output is a tangent vector at \\(x\\), corresponding to \\(\\Hess f(x)[u]\\).\n\n\n\nUsing automatic differentiation\nAutomatic differentiation (AD) is a means to obtain gradients and Hessians automatically, without the need to derive and implement formulas for them. This is usually slower than (good) hand-written code, but it can drastically reduce coding time, making it great (at least) for prototyping.\nManopt 7.0 added support for AD by building on Matlab’s Deep Learning Toolbox. To use it, simply define the cost and call manoptAD:\nproblem.cost = @(x) .5*x'*A*x;\nproblem = manoptAD(problem);\nIf it works, then the problem structure now includes access to the gradient and Hessian. If it does not work, check the following:\n\nDo you have the Deep Learning Toolbox? Type help dlarray.\nIs your Matlab version 2019 or later? Type version.\nIs your Manopt version 7.0 or later? Type manopt_version.\nWas there an error message? AD does not work for all functions. Check out:\n\nThe list of dlarray supported functions, and\nThe docs for AD in Manopt, specifically: help manoptAD and help manoptADhelp.\n\nKeep in mind that dlarray support also depends on your versions of Matlab and the DL toolbox (e.g., support for AD with complex numbers was added in Matlab R2021b).\nIf a function you need is not supported (e.g., diag), see help manoptADhelp for a possible replacement (e.g., cdiag), or try to replace it with a direct implementation (e.g., mydiag = @(A) A(1:size(A,1)+1:end);').\nAre you using the caching system (store) in the definition of the cost function? This does not pair well with AD (and AD has its own caching system), so it is better not to mix the two.\n\nXiaowen Jiang implemented manoptAD (and the system behind it) during an internship in 2021.\n\n\nFewer redundant computations with costgrad\nComputing the gradient at \\(x\\) often requires going through some of the computations that are also necessary to compute \\(f(x).\\) In our example, both \\(f(x) = \\frac{1}{2}x^\\top Ax\\) and \\(\\grad f(x) = Ax - (x^\\top Ax)x\\) require computing \\(Ax\\).\nSince solvers tend to query both \\(f\\) and its gradient at the same point \\(x\\), it is beneficial to offer solvers the option to query both at the same time. You can do so with the field costgrad, as follows:\nproblem.costgrad = @(x) mycostgrad(A, x);\nfunction [f, g] = mycostgrad(A, x)\n    Ax = A*x; % this product is computed only once\n    f = .5*x'*Ax;\n    if nargout == 2 % compute gradient only if requested\n        g = Ax - 2*f*x;\n    end\nend\nThe input of costgrad is a point \\(x\\). The outputs are the cost and (if requested) the Riemannian gradient at \\(x\\). If you prefer to define the Euclidean gradient (as we often do) but still want to avoid redundant computations, read on.\nWe might also want to provide the Riemannian Hessian with\nproblem.hess = @(x, u) problem.M.proj(x, A*u - (x'*A*x)*u); % optional\nHowever, now we see that the product A*x could also be reused there. The next section provides a more sophisticated approach which gives users full control over which computations to cache for reuse.\n\n\nUsing the store caching system\nComputing anything at a point \\(x\\) (e.g., \\(f(x)\\)) may produce intermediate results that could be reused for other computations at \\(x\\) (e.g., the gradient). It may be beneficial to cache (that is, to store) some of those intermediate calculations.\nFor that purpose, within the run of a solver, Manopt manages a database of store structures, with a class called StoreDB. For each visited point \\(x\\), a store structure is created in that database. StoreDB labels the points visited on the manifold with a key (an integer). This key uniquely identifies \\(x\\): that is how the toolbox links \\(x\\) with its associated store. Only the stores pertaining to the most recently used points are kept in memory. \nWhenever a solver calls, say, the cost function at some point \\(x\\), the toolbox searches for a store structure associated to that \\(x\\) in the database (using its key). If there is one and if problem.cost (for example) admits store as an input and as an output, the store is passed to the cost function. The cost function then performs its duty and gets to modify the store structure at will.\nThe next time a function is called at the same point \\(x\\) (say, problem.egrad), the same store structure is passed along, possibly modified, and stored again.\nAs soon as the solver goes on to explore a new point \\(x'\\), a different store structure is created and maintained in the same way. If the solver later decides to return to the previous \\(x\\), we get access to that earlier store again (unless it was purged from memory).\nFor our running example, the code below shows how we can use the caching system to implement the cost, gradient and Hessian without redundant computations. The principle is this:\n\nWrite a function prepare which computes all the things you want to cache at a given point.\nHave cost, egrad, ehess etc. call prepare before they proceed with their own computations.\n\nThe code is given in two versions (use the tabs to switch):\n\nOne version nests the functions prepare, cost, egrad and ehess within a top function (with a common scope).\nOne version allows for those functions to be defined in independent scopes.\n\nYou may prefer one or the other depending on your use case.\n\nAs a function with nested functionsAs a script with function handles\n\n\nfunction x = rayleighmin(A)\n\n    problem.M = spherefactory(size(A, 1));\n\n    problem.cost = @cost;\n    problem.egrad = @egrad;\n    problem.ehess = @ehess; % optional\n\n    x = trustregions(problem);\n\n    % The functions below are nested:\n    % they can see the matrix A from the top scope.\n\n    function store = prepare(x, store)\n        if ~isfield(store, 'Ax')\n            store.Ax = A*x;\n        end\n    end\n    function [f, store] = cost(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        f = .5*x'*Ax;\n    end\n    function [g, store] = egrad(x, store)\n        store = prepare(x, store);\n        Ax = store.Ax;\n        g = Ax;\n    end\n    function [h, store] = ehess(x, u, store)\n        % In general we would call prepare()\n        % here too, but for this example the\n        % Hessian is so simple that we don't\n        % need to.\n        % store = prepare(x, store);\n        h = A*u;\n    end\n\nend\n\n\nclear; clc; clf;\n\nn = 1000;\nA = randsym(n);\nproblem.M = spherefactory(n);\n\nproblem.cost = @(x, store) cost(A, x, store);\nproblem.egrad = @(x, store) egrad(A, x, store);\nproblem.ehess = @(x, u, store) ehess(A, x, u, store); % optional\n\nx = trustregions(problem);\n\n% The functions below appear at the end of the script\n% (they could also be defined in separate files).\n% They do not see A, so they need to receive it as an input.\n% The function handles above are created in a part of the\n% script that can see A.\n\nfunction store = prepare(A, x, store)\n    if ~isfield(store, 'Ax')\n        store.Ax = A*x;\n    end\nend\nfunction [f, store] = cost(A, x, store)\n    store = prepare(A, x, store);\n    Ax = store.Ax;\n    f = .5*x'*Ax;\nend\nfunction [g, store] = egrad(A, x, store)\n    store = prepare(A, x, store);\n    Ax = store.Ax;\n    g = Ax;\nend\nfunction [h, store] = ehess(A, x, u, store)\n    % In general we would call prepare()\n    % here too, but for this example the\n    % Hessian is so simple that we don't\n    % need to.\n    % store = prepare(A, x, store);\n    h = A*u;\nend\n\n\n\nIt is instructive to execute such code with the profiler activated and to look at how many times each line of code is executed. You should find that the matrix-vector products \\(Ax\\) (computed only in prepare) are executed exactly as often as they should be. You can use Manopt counters to track these products and more.\nThe store structure also includes a field store.shared. The contents of that field are shared among all points the solver visited so far.\n\n\n\n\n\n\nCache reusable computations, not end results\n\n\n\nManopt automatically caches the value and the gradient of \\(f\\) (both Euclidean and Riemannian) at each queried point \\(x\\). There is no need to cache those manually. Rather, use the store to cache the most expensive (and reusable) intermediate computations. \n\n\n\n\n\n\n\n\nCaching and the Hessian\n\n\n\nEach store is associated to a point \\(x\\). Thus, calls to ehess(x, u, store)and ehess(x, v, store) with the same x and two different tangent vectors u, v receive access to the same store. Therefore, only cache quantities that depend on x, not on u.\n\n\n\n\n\n\n\n\nLifespan of the cache\n\n\n\nSolvers take care of deleting older information when it is no longer relevant. This should be good enough, but you can also cap the maximum number of store structures kept in memory with options.storedepth.\n\n\n\n\n\n\n\n\nCaching and statsfun\n\n\n\nThe store structure is readable (but not writable) by options.statsfun. The store.shared mechanism was originally used together with statsfun to keep track of function calls. As of Manopt 5.0, it is much better to use Manopt counters for this purpose.\n\n\n\n\n\n\n\n\nStoreDB and key (for solver developers and advanced users; click to expand)\n\n\n\n\n\nWhen you have access to storedb and a key associated to \\(x\\) rather than to a specific store, the store of \\(x\\) can be obtained as store = storedb.getStore(key). Put the modified store back into the database with storedb.set(store, key).\nAccess the shared memory directly as storedb.shared, not via store.shared. This is important: store might have a store.shared field, but when storedb and key are explicitly used, store.shared will not be populated or read on get/set.\nIf you are developing a solver and hence are managing the StoreDB object yourself:\nEach point \\(x\\) should be associated to a key, which is obtained by calling storedb.getNewKey(). From time to time, call storedb.purge() to reduce memory usage. Even better, as soon as you know that the store associated to a certain point is no longer useful, call storedb.remove(key) or storedb.removefirstifdifferent(key1, key2).\nStoreDB is a handle class: its instances are passed by reference. This means that when a storedb object is passed as input to a function, and that function modifies the storedb object, the calling function sees the changes too (without the need to explicitly return the storedb object). Thus, each storedb object exists only once in memory. This makes for cleaner calling patterns and avoids unnecessary copies. This is not the case for the store structures though, which are passed by copy and thus must be returned if the changes are to be permanent.",
    "crumbs": [
      "Home",
      "Cost functions"
    ]
  },
  {
    "objectID": "costdescription.html#all-the-ways-to-describe-the-cost",
    "href": "costdescription.html#all-the-ways-to-describe-the-cost",
    "title": "Describing the cost function",
    "section": "All the ways to describe the cost",
    "text": "All the ways to describe the cost\nManopt offers many ways to implement \\(f\\), its gradient, its Hessian and more. This is done by adding function handles as fields in the problem structure. We list them all below.\nYou can mix and match what you include. If you provide more than one way to compute, say, the gradient, then the toolbox may use any and all of them: it makes an educated guess of which may be most efficient in context. Still, it is good practice to avoid redundancies.\nEach function can be provided with one of three different calling patterns, as indicated below. The first one is the simplest and is perfectly fine for prototyping. The other calling patterns give explicit access to Manopt’s caching system, in two flavors:\n\nThe normal way, with the store structure of the point x as an input and (possibly after modifications) as an output.\nThe advanced way, with the storedb database and the key associated to x: see the collapsible note above.\n\n\nTable of all the ways one can describe the cost function in Manopt, including its derivatives, approximations, preconditioners and a line-search hint.\n\n\nField name (problem.\"...\")\nDescription\n\n\n\n\ncost\n\\(f = f(x)\\)  f = cost(x)  [f, store] = cost(x, store)  f = cost(x, storedb, key)\n\n\ngrad\n\\(g = \\grad f(x)\\)  g = grad(x)  [g, store] = grad(x, store)  g = grad(x, storedb, key)\n\n\ncostgrad\nComputes both \\(f = f(x)\\) and \\(g = \\grad f(x)\\).  [f, g] = costgrad(x)  [f, g, store] = costgrad(x, store)  [f, g] = costgrad(x, storedb, key)\n\n\negrad\nFor submanifolds of a Euclidean space and for quotient spaces with a total space embedded in a Euclidean space, computes \\(eg = \\nabla f(x)\\): the gradient of \\(f\\) “as if” it were defined in that Euclidean space. This is passed to M.egrad2rgradand is automatically cached for use with ehess.  eg = egrad(x)  [eg, store] = egrad(x, store)  eg = egrad(x, storedb, key)\n\n\npartialgrad\nAssume the cost function problem.cost is a sum of many terms, as \\(f(x) = \\sum_{i=1}^{d} f_i(x)\\) where \\(d\\) is specified as problem.ncostterms = d. For a subset \\(I\\) of \\(1\\ldots d\\), partialgrad(x, I) computes the Riemannian gradient of the partial cost function \\(f_I(x) = \\sum_{i \\in I} f_i(x)\\).  pg = partialgrad(x, I)  [pg, store] = partialgrad(x, I, store)  pg = partialgrad(x, I, storedb, key)\n\n\npartialegrad\nSame as partialgrad but computes the Euclidean partial gradient. This is automatically transformed into a Riemannian partial gradient by Manopt.  peg = partialegrad(x, I)  [peg, store] = partialegrad(x, I, store)  peg = partialegrad(x, I, storedb, key)\n\n\napproxgrad\nApproximation for the gradient of the cost at \\(x\\). Solvers asking for the gradient when one is not provided automatically fall back to this approximation. If it is not provided either, a standard finite-difference approximation of the gradient based on the cost is built-in. This is slow because it involves generating an orthonormal basis of the tangent space at \\(x\\) and computing a finite difference of the cost along each basis vector. This is useful almost exclusively for prototyping. Because of the limited accuracy, it may be necessary to increase options.tolgradnorm when using this feature. See /solvers/gradientapproximations.  g = approxgrad(x)  [g, store] = approxgrad(x, store)  g = approxgrad(x, storedb, key)\n\n\nsubgrad\nReturns a Riemannian subgradient of the cost function at \\(x\\), with a tolerance tol which is a nonnegative real number. If you wish to return the minimal norm subgradient (which may help solvers), see smallestinconvexhull on the tools page.  g = subgrad(x, tol)  [g, store] = subgrad(x, tol, store)  g = subgrad(x, tol, storedb, key)\n\n\ndiff\n\\(d = \\D f(x)[u]\\) defines directional derivatives. If the gradient exists, it can be computed from this too (slowly.)  d = diff(x, u)  [d, store] = diff(x, u, store)  d = diff(x, u, storedb, key)\n\n\nhess\n\\(h = \\Hess f(x)[u]\\), where \\(u\\) represents a tangent vector.  h = hess(x, u)  [h, store] = hess(x, u, store)  h = hess(x, u, storedb, key)\n\n\nehess\nFor the same settings as with egrad, this computes \\(eh = \\nabla^2 f(x)[u]\\): the Hessian of \\(f\\) along \\(u\\) “as if” it were defined in the embedding Euclidean space. This is passed to M.ehess2rhess and thus requires the Euclidean gradient to be accessible too (egrad). Input \\(u\\) is a representation of the tangent vector. You may want to call M.tangent2ambient(x, u) to obtain the ambient space equivalent of \\(u\\). The output eh should be a vector in the ambient space.  eh = ehess(x, u)  [eh, store] = ehess(x, u, store)  eh = ehess(x, u, storedb, key)\n\n\napproxhess\nThis can be any mapping from the tangent space at \\(x\\) to itself. Often, one would like for it to be a linear, symmetric operator. Solvers asking for the Hessian when one is not provided automatically fall back to this approximate Hessian. If it is not provided either, a standard finite-difference approximation of the Hessian based on the gradient is built-in. See /solvers/hessianapproximations.  h = approxhess(x, u)  [h, store] = approxhess(x, u, store)  h = approxhess(x, u, storedb, key)\n\n\nprecon\n\\(v = \\operatorname{Prec}(x)[u]\\), where \\(\\operatorname{Prec}(x)\\) is a preconditioner for the Hessian \\(\\Hess f(x)\\), that is, \\(\\operatorname{Prec}(x)\\) is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at \\(x\\). Ideally, it is cheap to compute and such that solving a linear system in \\[\\operatorname{Prec}^{1/2}(x) \\circ \\Hess f(x) \\circ \\operatorname{Prec}^{1/2}(x)\\] is easier than without the preconditioner, i.e., it should approximate the inverse of the Hessian. See /solvers/preconditioners.  v = precon(x, u)  [v, store] = precon(x, u, store)  v = precon(x, u, storedb, key)\n\n\nsqrtprecon\n\\(v = \\operatorname{Prec}^{1/2}(x)[u]\\), where \\(\\operatorname{Prec}^{1/2}(x)\\) is an (operator) square root of a preconditioner for the Hessian \\(\\Hess f(x)\\), that is, \\(\\operatorname{Prec}^{1/2}(x)\\) is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at \\(x\\), and applying it twice should amount to applying \\(\\operatorname{Prec}(x)\\) once. Solvers typically use precon rather than sqrtprecon, but some tools (such as hessianspectrum) can use sqrtprecon to speed up computations.  v = sqrtprecon(x, u)  [v, store] = sqrtprecon(x, u, store)  v = sqrtprecon(x, u, storedb, key)\n\n\nlinesearch\nGiven a point \\(x\\) and a tangent vector \\(u\\) at \\(x\\), assume \\(u\\) is a descent direction. This means there exists \\(t &gt; 0\\) such that \\(\\phi(t) &lt; \\phi(0)\\) with \\[\\phi(t) = f(\\Retr_x(td)).\\] Line-search algorithms, which are used by some solvers such as steepestdescent and conjugategradient are designed to (approximately) minimize \\(\\phi\\) at each iteration. There are built-in, generic ways of doing this. If you have additional structure in your problem that enables you to take a good guess at what \\(t\\) should be, then you can specify it here, in this function handle. This (very much optional) function should return a positive \\(t &gt; 0\\) such that \\(t\\) is a good guess of where to look for a minimizer of \\(\\phi\\). The line-search algorithm (if it decides to use this information) starts by looking at the step \\(td\\), and decides to accept it or not based on its internal rules. See the linesearch option on the solvers page for details on available line-search algorithms and how to pick one. See low_rank_matrix_completion for an example from the literature.  t = linesearch(x, u)  [t, store] = linesearch(x, u, store)  t = linesearch(x, u, storedb, key)",
    "crumbs": [
      "Home",
      "Cost functions"
    ]
  },
  {
    "objectID": "costdescription.html#accessing-the-cost-gradient-and-hessian",
    "href": "costdescription.html#accessing-the-cost-gradient-and-hessian",
    "title": "Describing the cost function",
    "section": "Accessing the cost, gradient and Hessian",
    "text": "Accessing the cost, gradient and Hessian\nGiven a problem structure with a manifold problem.M and some description of the cost function \\(f\\), Manopt provides access to \\(f\\) and its derivatives with the tools getCost, getGradient and getHessian. Here is an example:\nA = randsym(10);\nproblem.M = spherefactory(10);\nproblem.cost = @(x) .5*x'*A*x;\nproblem = manoptAD(problem);\n\n% For illustration, pick a random point on M\nx = problem.M.rand();\n% Compute f(x)\nf = getCost(problem, x);\n% Compute grad f(x) (Riemannian)\ng = getGradient(problem, x);\n% The Riemannian norm of the gradient is:\nproblem.M.norm(x, g)\n\n% Pick a random tangent vector at x\nu = problem.M.randvec(x);\n% Compute Hess f(x)[u] (Riemannian)\nHu = getHessian(problem, x, u);\n% The Hessian quadratic form &lt;u, Hess f(x)[u]&gt;_x is:\nproblem.M.inner(x, u, Hu)\nThere are more functions of this type: see the core tools page.\nAll of these tools also accept calls with store and (storedb, key) (from the caching system described above). This is mostly useful inside the code for a solver.\nTo compute the eigenvalues of the Hessian, check out the tools hessianspectrum, hessianextreme and hessianmatrix on the tools page.",
    "crumbs": [
      "Home",
      "Cost functions"
    ]
  },
  {
    "objectID": "downloads.html",
    "href": "downloads.html",
    "title": "Downloads",
    "section": "",
    "text": "Download  GitHub Mailing list\nThe current version is 7.1 and was packaged on Sep. 30, 2022. The file is about 750 Kb.\nThe latest code is available on GitHub at all times, accepting pull requests.\nGo to the Getting Started page for installation instructions.\nIt helps us to know our users. Please consider registering to our mailing list to hear about updates. (Roughly one e-mail per year.) Thanks!\nDo you use Manopt for teaching? Please get in touch! We’d love to know about this and get feedback."
  },
  {
    "objectID": "downloads.html#previous-releases-and-change-logs",
    "href": "downloads.html#previous-releases-and-change-logs",
    "title": "Downloads",
    "section": "Previous releases and change logs",
    "text": "Previous releases and change logs\n\nManopt 7.1, packaged Sep. 30, 2022\n\nSolvers\n\nSizeable improvements to trustregions (the main solver):\n\nRefactored trustregions to accommodate new subproblem solvers.\nSped up trs_tCG (the main subproblem solver for trustregions) by recycling computations after a step rejection.\nAdded new subproblem solver trs_gep to find a global optimum (based on code by Yuji Nakatsukasa).\nImproved information logged and displayed.\n\nAdded Liu-Storey rule for conjugategradient solver.\nAdded constant step-size line-search helper linesearch_constant.\n\nManifolds\n\nImprovements to sympositivedefinitesimplexfactory and sympositivedefinitesimplexcomplexfactory.\nRotations factory now uses Rodrigues formulas when \\(n = 3\\) for exp/log.\nSeveral manifolds which are Lie groups now have a method M.lie_identity(): this returns the identity element of that group.\n\nTools\n\nAdded sinxoverx, which computes \\(\\sin(x)/x\\) such that \\(\\sin(0)/0 = 1\\).\nAdded getsize, which estimates the memory footprint of an input (used to monitor caching).\nTool tangentorthobasis now accepts an initial set of vectors to build on.\n\nOther changes\n\nSmall improvements (mostly numerical) for spherefactory, obliquefactory, obliquecomplexfactory, sympositivedefinitefactory.\nRenamed tensorprod to tensorprod_ttemps for better compatibility with new Matlab versions.\nUpdated and renamed example positive_definite_karcher_mean.m to positive_definite_intrinsic_mean.m.\nMade importmanopt script more robust.\n\n\n\n\nManopt 7.0, packaged Sep. 5, 2021\n\nCore functionalities\n\nAdded support for automatic differentiation through manoptAD.\n\nManifolds\n\nAdded sympositivedefiniteBWfactory.\nAdded poincareballfactory.\nAdded fixedTTrankfactory.\nAdded multinomialdoublystochasticgeneralfactory.\nAdded tangent2ambient (identity) to some important manifolds.\nAdded pairmean to hyperbolicfactory.\n\nTools\n\nAdded checks to checkmanifold.\nTools multiprod, multitransp etc. are now wrappers for the more efficient builtin functions pagemtimes and related ones. They are also compatible with GPUs and with AD.\n\nSolvers\n\nNew feature: in trustregions and steepestdescent (for now), users can now specify an options.hook function handle that allows one to change the current point x using external code, at each iteration, if desired.\n\nOther changes\n\nImproved compatibility with Octave 6.1.0.\nFixed sylvester_nochecks for recent Matlab versions.\nSeveral small bug fixes and improvements.\n\n\n\n\nManopt 6.0, packaged May 19, 2020\n\nModifications to core engine\n\nMade it possible for egrad2rgrad and ehess2rhess in a factory-produced manifold to take (storedb, key) as input. The purpose is to allow some automatic caching of redundant computations in ehess2rhess wrt egrad2rgrad. If they do, then they should accept to be called without (storedb, key), so as not to generate errors with powermanifold and productmanifold, which cannot handle this.\n\nNew geometries\n\nHyperbolic manifold in the hyperboloid model: hyperbolicfactory.\nTensors of fixed multilinear rank in Tucker format: fixedranktensorembeddedfactory.\nLinear subspaces of linear spaces: euclideansubspacefactory.\nUnitary matrices: unitaryfactory.\nSparse matrices with fixed sparsity pattern (inefficient implementation): euclideansparsefactory.\nManifold of \\(k\\) positive definite matrices whose sum is the identity matrix: sympositivedefinitesimplexfactory and sympositivedefinitesimplexcomplexfactory.\n\nNew tools\n\nAdded randsym, randherm, ranskewh and randunitary.\nTo match the existing multiherm, added multiskewh.\nNew tool qr_unique to compute the unique Q-factor of a full column rank matrix.\nAdded tool to form the matrix of a linear operator between two tangent spaces: operator2matrix. Useful for prototyping / debugging / analysis.\n\nSolvers\n\nAdded gradient descent and nonlinear conjugate gradient subproblem solvers for Riemannian ARC.\nImproved numerical stability of Lanczos subproblem solver for ARC.\nChanged default parameters of ARC and added checks to react if subproblem solver fails.\nAdded preconditioner support to stochasticgradient solver.\n\nOther changes\n\nFix to productmanifold so that it defines a method for the product only if that method is available for each element.\nAdded a new retraction to generalized Stiefel manifold, and made it the default retraction.\nMinor changes to multinomialfactory and also added exp, log and dist functions.\nFor the manifold fixedrankembeddedfactory: added tools triplet2matrix and matrix2triplet, improved numerical behavior of the retraction for ill-conditioned tangent vectors and vec/mat replaced with lower dimensional isometries, which speed up use of hessianspectrum with that factory considerably.\nChanges to grassmannfactory: tweaks to ehess2rhess for numerical accuracy and added pairmean.\nAdded exp, log and dist in the factory symfixedrankYYfactory.\nDifferentials of matrix functions (dexpm, dlogm, dsqrtm, dfunm) now also return the matrix function evaluation as a by-product.\nThe tool checkdiff (hence also checkgradient) now checks that the cost function is real.\nThe tool checkhessian now checks that the Hessian is a linear operator.\nAdded some extra checks to checkmanifold, notably to test vec/mat and dim; and improved test of exp/log/dist.\nRefactored a number of retractions to use new tool qr_unique.\nSeveral improvements to multinomialdoublystochasticfactory.\nThe tool tangentspacefactory should now work with factories involving a non-identity tangent2ambient.\nBug fix: memory usage could increase with inner iterations of tCG inside trustregions when using finite difference approximation of the Hessian. This is no longer the case.\nGenerally improved comments in several files.\n\n\n\n\nManopt 5.0, packaged September 10, 2018\n\nNew solvers\n\nARC: adaptive regularization by cubics, arc, as an alternative to trustregions.\n\nModifications to core engine\n\nNew counters system: especially useful to keep track of cost/grad/hess calls, and also of other important computations inside of (and possibly shared among) those. See incrementcounter and statscounter and the example using_counters. As also shown in that example, the problem.stopfun handle for stopping criteria can access the counters, making it possible to stop for more sophisticated reasons than before.\nThe value of the cost function is now always cached. This leads to significant speed-ups in algorithms which use a line-search that evaluates the cost function (steepestdescent, conjugategradient, barzilaiborwein, rlbfgs included.)\nThe Riemannian gradient and Euclidean gradient are now cached by default. This is made practical by the new remove() functionalities of StoreDB (see below). This should be particularly useful for algorithms which use finite difference approximations of the Hessian, and when the user supplies a Euclidean Hessian (which, to be converted to Riemannian Hessian, requires the Euclidean gradient). This caching happens regardless of the user’s own caching efforts, which should make the overall system easier to understand, as compared to previous versions of Manopt.\nCore changes to StoreDB. Essentially two changes: (1) purge() now purges based on latest access time (access = read or write) rather than latest write time. (2) Added functions remove() and removefirstifdifferent(), which makes it possible for solvers and line-search algorithms to tell the StoreDB when a certain store is no longer relevant. For solvers that use the new remove() capabilities, purge() and storedepth now have very little importance. Furthermore, access is now more protected, with warnings issued if improper keys are accessed; this should make it easier to debug new solvers, and it already makes it possible to cache far fewer points. This rationalizes the choice of caching more things for points that matter (including cost and gradient). Line-search algorithms and all important solvers now use this system.\nAdded support for GPU. The following manifolds can now manipulate points and tangent vectors directly on the GPU, sometimes leading to huge speed-ups: spherefactory, complexcirclefactory, stiefelfactory, grassmannfactory; see the new example using_gpu.\n\nNew tools\n\northogonalizetwice runs the rewritten orthogonalize tool twice for better accuracy when orthonormalizing an ill-conditioned basis of tangent vectors.\nlyapunov_symmetric and lyapunov_symmetric_eig: solvers for Lyapunov equation \\(AX + XA = C\\) with symmetric (or Hermitian) matrix \\(A\\); acts as a pseudo-inverse. sylvester_nochecks: Matlab’s sylvester solver without input checks (much faster for small matrices); These are now used everywhere in Manopt to remove dependency on lyap, which is a tool from the Control Toolbox.\nstopifdeletedfile and stopifclosedfigure: interactive stopping criteria that allow to stop a solver at any point, and let it finish gracefully and continue executing the rest of the code (also for execution on a distant server without GUI.)\ncheckmanifold: began a new tool to run a collection of tests on manifold structures returned by factories; this is an early version to collect ideas as they come.\n\nNew geometries\n\nconstantfactory, which can be used to fix certain variables in a productmanifold.\nmultinomialsymmetricfactory and multinomialdoublystochasticfactory for doubly stochastic matrices with (strictly) positive entries, symmetric or not; contributed by Ahmed Douik. Comes with a tool named doubly_stochastic which implements Sinkhorn’s algorithm to project to doubly-stochastic matrices.\n[positivefactory](https://github.com/NicolasBoumal/manopt/blob/master/manopt/manifolds/positive/positivefactory.m) deals with strictly positive numbers.\n\nBug fixes\n\nFixed M.retr2 (second-order retraction) in rotationsfactory for \\(k &gt; 1\\).\n\nOther changes\n\nInstallation instructions and importmanopt now include savepath.\northogonalize tool is now a modified Gram-Schmidt algorithm, which is more stable than the previous code.\nstrict_inc_func in rlbfgs solver changed following recommendations of Wen Huang.\nMore heads up messages regarding the use of M.tangent2ambient with some manifolds.\ntCG solver for trustregions inner problems is now more stable (numerically) for fine convergence steps.\nAdded inverse retraction for grassmannfactory, stiefelfactory (both QR and polar retractions, both of which are now available), spherefactory, obliquefactory, rotationsfactory (both QR and polar) and complexcirclefactory.\nneldermead solver now uses retraction instead of exponential.\nIf the exponential is not implemented for a manifold, M.exp is now no longer defined. It used to be that M.exp would issue a warning, then return the result of M.retr. But this causes a deluge of warnings in functions such as checkhessian. Now, instead, such tools check if M.exp is defined; if not, they use M.retr and issue a single message to inform the user of the consequences. If your personal code uses M.exp() without checking for manifolds that didn’t have a proper implementation, you may want to check if this update breaks that part. It should be an easy fix.\nMany small improvements here and there…\n\n\n\n\nManopt 4.0, packaged September 9, 2017\n\nNew solvers\n\nLimited-memory BFGS, rlbfgs: a Riemannian version of the quasi-Newton solver, implemented by Changshuo Liu based on work by Wen Huang et al.\nbarzilaiborwein: a gradient method with step-size selection based on a Barzilai-Borwein heuristic and line-search, contributed by Margherita Porcelli and Bruno Iannazzo.\nstochasticgradient: stochastic gradient algorithm on manifolds, together with its step-size selection algorithm stepsize_sg and a new example: PCA_stochastic.\n\nNew tools\n\ntangent2vec: given a tangent vector and an orthogonal basis on the corresponding tangent space, returns the coordinates of the vector in that basis.\ncriticalpointfinder: allows to find critical points of an optimization problem (useful to study saddle points of a non-convex problem for example.)\n\nNew geometries\n\nrealphasefactory: to optimize over vectors with unit-modulus complex entries (phases) satisfying symmetries such that they could be the phases of the DFT (fft) of a real vector.\n\nModifications to core engine\n\nAdded the capacity to provide a subgradient in a problem description, and to call for it in a solver. This, together with the tool smallestinconvexhull, is an important step toward integrating nonsmooth solvers in Manopt. See canGetSubgradient and getSubgradient. Define with problem.subgrad(x, tol), where x is a point on a manifold problem.M and tol (nonnegative) is a tolerance in computing the subgradient (0 by default).\n\nBug fixes\n\ntangentspacefactory now has correct tangent, egrad2rgrad and ehess2rhess tools, including projections (thanks to a comment by Jesus Briales on the forum.)\nFor Euclidean manifolds, M.tangent functions were changed from identity to M.proj.\n\nSmaller things\n\nsympositivedefinitefactory now has a cheaper yet second-order retraction, as suggested by Wen Huang.\neuclideancomplexfactory now also handles multidimensional arrays, just like its real counterpart.\nsmallestinconvexhull tool now accepts a tolerance as optional input.\nFurther improved accuracy of distance function computations in all sphere / oblique manifolds with asin function instead of acos without branching, following discussions with Bruno Iannazzo and P.-A. Absil.\nTwo new options for linesearch_hint: allows to disable backtracking and allows to disable forcing of a non-increasing cost.\nfixedrankembeddedfactory now has an orthographic retraction provided by Teng Zhang as M.retr_ortho.\nMany, many smaller improvements to code and documentation.\n\n\n\n\nManopt 3.0, packaged November 12, 2016.\n\nCode moved to GitHub! Now accepting pull requests, and accelerating distribution of patches.\nBug fixes\n\nLogic bug in linesearch: lsmem handling corrected thanks to Wen Huang. The default line-search algorithm for steepest descent should now be much faster.\nLogic bug in getGradient when using problem.grad with a different number of inputs compared to problem.cost.\nCorrected logic in plotting step of example low_rank_dist_completion.\nobliquefactory, in transposed mode, had an incorrect M.log.\n\nModifications to core engine\n\nAdded capability to obtain a partial gradient (Euclidean or Riemannian) of a cost function by specifying problem.partialgrad or problem.partialegrad coupled with problem.ncostterms. This is an important step to simplify the future addition of stochastic gradient methods. Use cases are: if problem.cost is expressed as a sum of problem.ncostterms terms, then problem.partialgrad accepts a point x and an index set sample so that only the gradient with respect to terms indexed in sample is computed and returned.\nAdded possibility to define problem.approxgrad, to provide an approximation of the gradient. This can be populated with a generic gradient approximation based on finite differences via approxgradientFD. Solvers do this by default if they need a gradient and none is given. This feature is slow, but may be useful for prototyping. It is slow because Manopt generates an orthonormal basis of the tangent space, and compute a finite difference approximation of the directional derivative along each basis vector to get an approximate gradient (see also next item and new example thomson_problem.)\ngetGradient now knows how to compute the gradient if the directional derivatives are accessible. This involves generating an orthonormal basis of the tangent space at the current point, then evaluating the directional derivative along each basis vector and taking the appropriate linear combination. This is very slow, especially for high dimensional manifolds.\n\nNew tools\n\nlincomb for a generic way of computing a long linear combination of tangent vectors.\ngrammatrix to compute the Gram matrix of a collection of tangent vectors.\northogonalize to orthogonalize a basis of tangent vectors.\ntangentorthobasis to obtain a random orthonormal basis of a tangent space, generically.\nsmallestinconvexhull to compute the smallest tangent vector in the convex hull of a given collection of tangent vectors.\nhessianmatrix to get a matrix representing the Hessian at a point in an orthonormal tangent basis.\ncheckretraction allows, for manifolds which have a correct exponential implemented, to verify the order of agreement between the retraction and the exponential, in order to determine numerically if the retraction is first- or second-order.\n\nNew examples\n\nelliptope_SDP solves SDPs over positive semidefinite matrices with diagonal of all-ones. This should run faster than the Max-Cut example for quite a few things.\nelliptope_SDP_complex, same as above for complex matrices. This solves the SDP which appears in PhaseCut and phase synchronization, for example.\nthomson_problem to illustrate the new features that allow to not specify the gradient of the cost (slow, but good for prototyping.)\n\nNew geometries\n\nskewsymmetricfactory for skew-symmetric matrices (Euclidean geometry)\nobliquecomplexfactory, to work with complex matrices whose columns (or rows) all have unit norm\n\nModifications to previous behavior\n\nsymfixedrankYYcomplexfactory now has a Riemannian metric matching that of euclideanfactory (it was scaled down by 2 as compared to previous Manopt versions.) This makes it easier to switch between those two geometries. Relevant changes propagated to radio_interferometric_calibration.\nhessianextreme now returns the info structure returned by the internal solver call. The helper tool tangentspherefactory now incorporates extra projections to ensure the vector returned by hessianextreme is indeed a tangent vector (former version could suffer from numerical drift.)\nAt the end of generalized_eigenvalue_computation, added a rotation of Xsol to match the definition of generalized eigenvectors (the eigenvalues were fine.)\n\nNumerous minor improvements; highlights:\n\nrotationsfactory now has a function M.retr2 which is a second-order retraction.\nspherefactory and related sphere geometries now have a distance function M.dist which is orders of magnitude more accurate for close-by points.\nneldermead now respects options.verbosity &lt; 2.\nplotprofile and surfprofile have now mostly optional inputs, making them easier to call for a quick glimpse at the cost function.\n\n\n\n\nManopt 2.0, packaged July 6, 2015.\n\nModifications to core engine\n\nRevamped the internal hashing system used for caching: Manopt no longer uses hashing, which leads to speed-ups and cleaner internal code. Solvers need to be adapted consequently, to use the StoreDB class.\nThe caching system now offers a shared memory, which can be accessed and modified at all points. This can notably be used to count function evaluations, or to produce Hessian approximations which require previous iterations memory (such as BFGS for example).\nBecause of the new class StoreDB, Octave compatibility is unfortunately compromised until Octave supports Matlab’s classdef object oriented programming.\nNew cost description function: sqrtprecon, for the square root of the preconditioner (used in hessianspectrum).\nThe privatetools directory is now named core, and is documented.\n\nNew geometries:\n\nspecialeuclideanfactory (for rigid body motions).\nmultinomialfactory (for probability distributions, i.e., simplex elements).\neuclideancomplexfactory (for complex matrices).\nspheresymmetricfactory (for unit norm symmetric matrices)\nstiefelcomplexfactory (for complex orthonormal matrices)\nstiefelgeneralizedfactory (for matrices which are orthonormal in another basis)\nstiefelstackedfactory (for multiple orthonormal matrices of same size, represented in stacked form)\ngrassmanncomplexfactory (complex Grassmannian, for complex subspaces of \\(\\mathbb{C}^n\\))\ngrassmanngeneralizedfactory (for optimization over subspaces, represented via orthonormal bases in a non-standard basis)\nsymfixedrankYYcomplexfactory (for complex fixed-rank positive semidefinite matrices)\nfixedrankfactory_tucker_preconditioned (for optimization over fixed-rank tensors, in Tucker format)\ncenteredmatrixfactory (matrices whose rows or columns sum to zero)\n\nOther improvements:\n\nspherecomplexfactory: added ehess2rhess.\ncomplexcirclefactory: distance function corrected.\nContributions more explicitly acknowledged in some files, notably via BibTex entries.\nhessianspectrum: output eigenvalues now sorted, and the square root of the preconditioner, if available, must now be given through problem.sqrtprecon, not as an additional input. An option now allows to ask for the Hessian spectrum or the preconditioned Hessian spectrum, explicitly.\nNew management of Hessian approximations and preconditioners. The file hessianapproxFD encapsulates Manopt’s standard approximation, with access to options. A first generic preconditioner allows solving linear systems involving the Hessian (for Newton-type methods): preconhessiansolve.\nLine-search algorithms now work with StoreDB, and as a result have a simplified calling pattern. There is also a new one: linesearch_decrease.\n\nNew tools:\n\nmanoptsolve, to automatically call an appropriate solver (or a dynamically chosen solver) on a problem structure.\nstatsfunhelper, to ease the use of options.statsfun, which allows recording custom statistics at each iteration during optimization. See the tutorial.\nhessianextreme, to compute minimal and maximal eigenvectors and eigenvalues of the Hessian of a cost function.\nsurfprofile, to complement plotprofile: used to plot a cost function restricted to a 1D or 2D subspace of a tangent space.\ntangentspherefactory and tangentspacefactory, to obtain a manifold representation of the unit sphere on the tangent space to a manifold at a given point, or a representation of the whole tangent space. Useful to solve optimization problems over those spaces.\ndfunm, dexpm, dlogm, dsqrtm : compute the Fréchet derivatives of matrix functions.\n\nTrust-region solver:\n\nAs of Manopt 1.0.6, the inner solver tCG monitors the model cost; an (innocuous) logic bug was corrected there. Theory behind this feature is now better understood (a paper reference + BibTex was added).\nWarns if many TR+ / TR- steps are detected, to suggest changing parameter values.\nUses safe version of tic/toc timers (originally because Octave now supports them).\nIn case rho evaluates to NaN (which really should not happen), the code now ensures that the step is rejected and the radius decreased, thus preventing stagnation. In an adversely crafted example, this helped the solver escape the region where NaN’s appear (again, this is not supposed to happen, but it’s good to handle it nonetheless).\nMany more comments inside the code.\n\nNew examples:\n\nrobust_pca, illustrating how to smooth a nonsmooth cost function (here, on the Grassmann manifold).\nlow_rank_dist_completion, illustrating usage of Manopt as a building block in a rank-incremental optimization algorithm for SDP.\ndominant_invariant_subspace_complex, adapting dominant_invariant_subspace to the complex case.\nradio_interferometric_calibration, illustrating the usage of the complex fixed-rank manifold.\nnonlinear_eigenspace, showing how to address certain nonlinear eigenvalue problems.\nessential_svd, demonstrating the new geometry essentialfactory.\ngeneralized_eigenvalue_computation, shows how to use grassmanngeneralizedfactory to solve generalized eigenvalue problems.\nshapefit_smoothed, does sensor network localization from pairwise direction measurements, following the ShapeFit paper.\n\n\n\n\nManopt 1.0.7, packaged August 12, 2014.\n\nAdded the ehess2rhess function to complexcirclefactory.\nMajor revision of fixedrankembeddedfactory for support of optimization over fixed-rank matrices. It is now better documented, comes with an example called low_rank_matrix_completion, and also has support for ehess2rhess and tangent2ambient, a proper vector transport, works with the hessianspectrum tool, … This revision was executed with the precious and frequent help of Bart Vandereycken, who first described this geometry in a paper.\nAll solvers now also return the options structure, to make it easier to investigate what options a solver uses and what their default values are.\nIt is now possible to specify a line-search hint function in the problem structure; the result of that function will be used as a first guess in an Armijo backtracking line-search procedure, linesearch_hint. This is very useful if, for a given problem, you are able to make a good guess at how far along the search line one should look. It is much easier this way than with the previous way, which required implementing a whole new line-search algorithm.\nGenerally improved textual outputs (warnings, iteration information, stopping reasons…).\nThe documentation (tutorial, reference) was updated to reflect all of these changes.\nThe sympositivedefinitefactory now has the correct dim() function and implements a new vector transport as explained in the example.\n\n\n\nManopt 1.0.6, packaged June 25, 2014.\n\nFor uses of the trustregions solver with a nonlinear approximation of the Hessian (such as, for example, the default one if you do not specify a Hessian at all), the truncated-CG algorithm now explicitly checks that the model cost decreases with (inner) iterations. If an increase is witnessed (which is bad), tCG now returns the best step so far, which is always at least the Cauchy step.\nThe sympositivedefinitefactory geometry for positive definite matrices was revised. It had a number of mistakes in it due to an incorrect assumption. You can access the file before 1.0.6 is released on the forum.\nSmall bug fix in packing_on_the_sphere example, along an improvement of how the smoothing term is computed numerically.\nAdded a Riemannian Hessian conversion tool for the Stiefel manifold, ehess2rhess.\nAdded a new (Euclidean) manifold, symmetricfactory, to deal with symmetric matrices.\nMultiple enhancements and bug fixes for the embedded geometry of fixed rank matrices fixedrankembeddedfactory: now works with checkgradient, changed hash and typical dist, and the vector transport is now correct (it was wrong before, leading to failure of CG and RTR-FD). Thanks to Bart Vandereycken for the correct code.\nRandom vector generation in Stiefel and Grassmann now make more sense.\nPSO (Particle Swarm Optimization) solver debugged to work with product and power manifolds too.\nBug fix in grassmannfactory retraction for \\(k &gt; 1\\), and added final re-orthonormalization at the end of exponential map following forum discussions.\nThe functions in elliptopefactory are now a tad faster, using bsxfun.\n\n\n\nManopt 1.0.5, packaged January 2nd, 2014.\n\nMany files are now better commented and documented. In particular, the solvers now have quite complete documentation in code, available using Matlab’s help command.\nThe trust region solver was modified substantially. The algorithm is now slightly different from the previous versions, but is cleaner in its handling of errors, and behaves almost the same as before for normal operations. In particular, the fine-convergence heuristic has been changed to match a standard heuristic from the literature (see in code for references and the relevant option). The online documentation (UPDATE 2024: this documentation was deprecated) was extended as well. The original trust region radius (Delta0 and Delta_bar) are now interpreted correctly. Their values are different from earlier Manopt versions as a result. if you get a lot of TR+ or TR- for the first few iterations, you may want to tweak those options.\nNew geometry: sympositivedefinitefactory, for symmetric, positive definite matrices. Related example script: positive_definite_karcher_mean.\nLine search algorithms have been heavily modified. The basic line search for example is now invariant under shifting and rescaling of the cost function, and the built-in line search algorithms now accept options too. Line searches now do not expect to be given a normalized search direction anymore, and they can decide whether to use the norm as supplemental information or to be unaffected by it. For example, the default line search for the conjugate gradient solver (the adaptive line search) is not invariant to the norm of the search direction.\nNew example for sparse PCA via optimization on the Stiefel manifold.\nPotential bug (that never triggered) with purgeStoredb corrected.\n\n\n\nManopt 1.0.4, packaged August 22nd, 2013.\n\nThis release is a first step toward compatibility with Octave. We’re not there yet, but in the examples folder, you will find maxcut_octave (UPDATE: removed in 1.0.8), which should run in Octave 3.6.4. In there, more info about compatibility issues and limitations are provided.\nManopt is not organized in a Matlab package anymore (so folders are called folder and not +folder): no import anymore. Simply call importmanopt to add all Manopt functions to the path, once.\nSign error in right-hand side of Lyapunov equation in elliptopefactory.projection corrected.\n\n\n\nManopt 1.0.3, packaged July 26, 2013.\n\nThe new examples directory now contains documented examples.\nAdded manifolds spectrahedron and elliptope, for symmetric positive semidefinite fixed-rank matrices with constraints on the diagonal or the trace. Notably useful for max-cut like SDP relaxations (see examples) and correlation matrix approximation / completion etc.\nThe Riemannian gradient and Hessian may be given via their Euclidean counterparts, using problem.egrad and problem.ehess.\nImproved checkgradient and checkhessian tools.\nAdded Riemannian log map for the Grassmann manifold.\nMade egrad2rgrad and ehess2rhess available in more geometries.\nAdded the tool hessianspectrum to compute the eigenvalues of the Hessian (with or without preconditioner).\nAdded notions of tangent and tangent2ambient to manifolds.\nAdded notions of vec and mat for manifolds, to represent tangent vectors as column vectors.\n\n\n\nManopt 1.0.2, packaged June 11, 2013.\n\nImproved trustregions solver (e.g., avoids a redundant Hessian computation).\nImproved conjugategradient solver: now admits preconditioning.\nReorganized fixedrank geometries (not backward compatible).\nMany small improvements and bug fixes.\n\n\n\nManopt 1.0.1, packaged February 7, 2013.\n\n\nManopt 1.0, packaged January 3rd, 2013."
  },
  {
    "objectID": "forum.html",
    "href": "forum.html",
    "title": "Forum",
    "section": "",
    "text": "You can access the Manopt forum on Google Groups.\nThis is the right place to discuss math and Matlab code related to the use of Manopt.\nYou can also report issues and submit pull requests directly on GitHub.\nFor questions related to Python and Julia code, please see PyManopt.org and Manoptjl.org."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manopt",
    "section": "",
    "text": "Optimization on manifolds is a versatile framework for continuous optimization.\nIt encompasses optimization over vectors and matrices,\nand adds the possibility to optimize over curved spaces to handle constraints and symmetries such as orthonormality, low rank, positivity and invariance under group actions.\nManopt makes it easy.\nDownload  GitHub Mailing list  \n\n\n\n\nMatlab \nThis website is the home of the Matlab version of Manopt. Install from downloads or from our GitHub repository, then run a first example.\n\n\nPython \nThe PyManopt website houses the Python version of Manopt and its documentation. Also check out the GitHub repository.\n\n\nJulia \nThe Manopt.jl website hosts the Julia version of Manopt and its documentation. The GitHub repository has both Manopt.jl and Manifolds.jl."
  },
  {
    "objectID": "lifts.html",
    "href": "lifts.html",
    "title": "Lifts: parameterizations made easy",
    "section": "",
    "text": "Run importmanopt\n\n\n\nLifts were added to Manopt late June 2024. To use them, you need a sufficiently recent version of the code (e.g., from github). Lifts are stored in a new folder /manopt/lifts that needs to be on Matlab’s path. To ensure this, call importmanopt.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "lifts.html#general-idea",
    "href": "lifts.html#general-idea",
    "title": "Lifts: parameterizations made easy",
    "section": "General idea ",
    "text": "General idea \nAt first sight, optimization on manifolds is restricted to optimization problems on smooth sets. Notwithstanding, we can use smooth parameterizations of (possibly) nonsmooth sets to extend the realm of applications. See built-in examples in Table 2. This eases the process of working with:\n\nconstraints,\nnonsmooth sets, or simply\na change of variables.\n\nConsider the following commutative diagram.\n\n\n\n\n\n\nFigure 1: Commutative diagram on which lifts are based.\n\n\n\nThe principal objects in this diagram are in black. They are as follows:\n\n\\(\\calM\\) is a Riemannian manifold.\n\\(\\calN\\) is a Riemannian manifold too (often, it is a Euclidean space).\n\\(f \\colon \\calN \\to \\reals\\) is the cost function we wish to minimize on some subset.\n\\(\\varphi \\colon \\calM \\to \\calN\\) is the lift or parameterization: its image \\(\\calX = \\varphi(\\calM)\\) is a subset of \\(\\calN\\).\n\\(g = f \\circ \\varphi \\colon \\calM \\to \\reals\\) is the function we will actually minimize (without restriction on \\(\\calM\\)).\n\nNotice that by minimizing \\(g\\) on \\(\\calM\\), we are effectively minimizing \\(f\\) on \\(\\calX\\), because \\(g(y) = f(\\varphi(y))\\) so that we only ever evaluate \\(f\\) at points of the form \\(x = \\varphi(y)\\) which, by definition, are in \\(\\calX\\).\nMoreover, if \\(f\\) and \\(\\varphi\\) are both smooth, then so is \\(g\\) by composition.\nThis means that even if \\(\\calX\\) is a nonsmooth set, we can still use Manopt to (try to) minimize \\(f\\) on \\(\\calX \\subseteq \\calN\\).\nWe can do this explicitly by constructing a problem structure for \\(g\\) on \\(\\calM\\). Alternatively, we can construct a problem structure for \\(f\\) on \\(\\calN\\) and compose it with \\(\\varphi\\) by using manoptlift. To do so, this tool requires some information about \\(\\varphi\\) and its derivatives: this is all stored in a lift structure. Manopt comes with some built-in lifts (see below), and users can create their own.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "lifts.html#upstairs-downstairs-and-manoptlift",
    "href": "lifts.html#upstairs-downstairs-and-manoptlift",
    "title": "Lifts: parameterizations made easy",
    "section": "Upstairs, downstairs and manoptlift",
    "text": "Upstairs, downstairs and manoptlift\nThere are now two related optimization problems to consider. The problem downstairs is \\[\n    \\min_{x \\in \\calN} f(x) \\quad \\textrm{ subject to } \\quad x \\in \\calX,\n\\] where \\(\\calX = \\varphi(\\calM) \\subseteq \\calN\\) is the image of the lift and \\(f \\colon \\calN \\to \\reals\\) is the cost function. The problem upstairs is \\[\n    \\min_{y \\in \\calM} g(y),\n\\] where \\(g = f \\circ \\varphi \\colon \\calM \\to \\reals\\). The names “upstairs” and “downstairs” are reminiscent of the diagram in Figure 1, and echo the meaning of a “lift” as a tool to go from downstairs to upstairs.\nIn order to solve the downstairs problem, we first go through the following steps:\n\nBuild a problem structure downstairs for \\(f \\colon \\calN \\to \\reals\\) (ignoring the constraint \\(x \\in \\calX\\)).\nBuild a lift structure for \\(\\varphi \\colon \\calM \\to \\calN\\), e.g., by selecting an existing one.\nCall upstairs = manoptlift(downstairs, lift).\n\nThe outcome is a problem structure upstairs which encodes \\(g \\colon \\calM \\to \\reals\\) with \\(g = f \\circ \\varphi\\). Then,\n\nCall a solver on the upstairs problem, e.g., y = trustregions(upstairs).\nMap \\(y\\) down to \\(x = \\varphi(y)\\) with x = lift.phi(y).\n\nThe resulting \\(x\\) is guaranteed to be in \\(\\calX\\) (by construction). If \\(y\\) is optimal, so is \\(x\\).\nThere are several ways to call manoptlift:\n[upstairs, downstairs] = manoptlift(downstairs, lift)\n[upstairs, downstairs] = manoptlift(downstairs, lift, 'AD')\n[upstairs, downstairs] = manoptlift(downstairs, lift, 'noAD')\n[upstairs, downstairs] = manoptlift(downstairs, lift, 'ADnohess')\n\nThe third input (optional) is a string:\n\nIf it is omitted, or '', or 'noAD', there is no effect.\nIf it is 'AD', then automatic differentiation is used on downstairs with manoptAD before upstairs is built.\nIf it is 'ADnohess', then manoptAD is called with the nohess option.\n\nThe downstairs structure is available as second output (optional) because manoptlift may modify it in the following circumstances:\n\nIf downstairs.M is omitted, then it is set to lift.N.\nIf automatic differentiation is used.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "lifts.html#landscape-relations",
    "href": "lifts.html#landscape-relations",
    "title": "Lifts: parameterizations made easy",
    "section": "Landscape relations",
    "text": "Landscape relations\nA point \\(y \\in \\calM\\) maps to a point \\(x = \\varphi(y) \\in \\calX\\). With respect to the landscapes of the cost functions \\(g = f \\circ \\varphi\\) and \\(f\\), we may be interested in the following properties:\n\nglobal \\(\\Rightarrow\\) global: if \\(y\\) is a global minimum upstairs, then \\(x\\) is a global minimum downstairs. This is always true, simply because \\(\\varphi\\) is a surjection to \\(\\calX\\).\nlocal \\(\\Rightarrow\\) local: if \\(y\\) is a local minimum upstairs, then \\(x\\) is a local minimum downstairs. This is true if and only if \\(\\varphi\\) is an open map from \\(\\calM\\) to \\(\\calX\\).\n1 \\(\\Rightarrow\\) 1: if \\(y\\) is a first-order critical point upstairs, then \\(x\\) is a first-order stationary point downstairs. This is not often the case. In particular, it requires the tangent cone to \\(\\calX\\) at \\(x\\) to be linear.\n2 \\(\\Rightarrow\\) 1: if \\(y\\) is a second-order critical point upstairs, then \\(x\\) is a first-order stationary point downstairs. This is more common.\n\nContext, proofs and general theory are developed in the following paper:\n\nEitan Levin, Joe Kileel, Nicolas Boumal The effect of smooth parametrizations on nonconvex optimization landscapes Mathematical Programming, 2024\n\nMany of the lifts included in Manopt are treated as explicit examples in that paper.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "lifts.html#lift-structures-whats-in-them",
    "href": "lifts.html#lift-structures-whats-in-them",
    "title": "Lifts: parameterizations made easy",
    "section": "Lift structures: what’s in them?",
    "text": "Lift structures: what’s in them?\nThe lift structure must provide enough information about \\(\\varphi\\) so that Manopt can deduce how to compute \\(g = f \\circ \\varphi\\), its gradient and (ideally) its Hessian, based on the corresponding information about \\(f\\). Table 1 lists the fields in lift, including manifold structures for \\(\\calM\\) and \\(\\calN\\), and function handles for \\(\\varphi\\) and more.\nLet \\(y \\in \\calM\\) and \\(x = \\varphi(y) \\in \\calN\\). By the chain rule, for all \\(v \\in \\T_y\\calM\\) we have \\[\n    \\D g(y)[v] = \\D(f \\circ \\varphi)(y)[v] = \\D f(x)[\\D\\varphi(y)[v]],\n\\] where \\(\\D\\varphi(y) \\colon \\T_y\\calM \\to \\T_x\\calN\\) is the differential of \\(\\varphi\\) at \\(y\\). By definition of the Riemannian gradient, then by definition of the adjoint of a linear map (indicated by a star \\(\\cdot^*\\)), this yields \\[\n    \\inner{\\grad g(y)}{v}_y = \\inner{\\grad f(x)}{\\D\\varphi(y)[v]}_x = \\inner{\\D\\varphi(y)^*[\\grad f(x)]}{v}_y.\n\\] This holds for all \\(v\\). Thus, \\[\n    \\grad g(y) = \\D\\varphi(y)^*[\\grad f(x)].\n\\] This illustrates how we can get the gradient of \\(g\\) from that of \\(f\\) provided the lift gives us access to \\(\\D\\varphi(y)^*\\). For the Hessian, additional computations shown later on this page tell us what else needs to be included: see Eq. 2.\n\n\n\nTable 1: Fields in a lift structure.\n\n\n\n\n\n\n\n\n\n\nName\nField usage\nFunctionality\n\n\n\n\n\\(\\calM\\)\nlift.M\nManifold structure from a factory (“upstairs”)\n\n\n\\(\\calN\\)\nlift.N\nManifold structure from a factory (“downstairs”)\n\n\n\\(\\varphi\\)\nx = lift.phi(y)\nComputes the image of \\(y \\in \\calM\\) through \\(\\varphi \\colon \\calM \\to \\calN\\)\n\n\n\\(\\D\\varphi(y)\\)\nu = lift.Dphi(y, v)\nDifferential of \\(\\varphi\\) at \\(y \\in \\calM\\) along \\(v \\in \\T_y\\calM\\). The output is \\(u = \\D\\varphi(y)[v]\\) in \\(\\T_x\\calN\\) where \\(x = \\varphi(y)\\).\n\n\n\\(\\D\\varphi(y)^*\\)\nv = lift.Dphit(y, u)\nAdjoint of \\(\\D\\varphi(y)\\) with respect ot the inner products on \\(\\T_y\\calM\\) and \\(\\T_x\\calN\\), where \\(x = \\varphi(y)\\). Thus, \\[\\inner{\\D\\varphi(y)[v]}{u}_x = \\inner{v}{\\D\\varphi(y)^*[u]}_y.\\]\n\n\n\\(\\Hess h_w(y)\\)\ns = lift.hesshw(y, v, w)\nGiven \\(y \\in \\calM\\) and \\(w \\in \\T_x\\calN\\) where \\(x = \\varphi(y)\\), choose \\(q_w \\colon \\calN \\to \\reals\\) such that \\(\\grad q_w(x) = w\\) (for the specified \\(x\\)). Let \\(h_w = q_w \\circ \\varphi \\colon \\calM \\to \\reals\\). Then \\(s = \\Hess h_w(y)[v]\\). If \\(\\calN\\) is Euclidean, a typical choice is \\(q_w = \\inner{\\cdot}{w}_\\calN\\).\n\n\n\\(\\Hess q_w(x)\\)\ns = lift.hessqw(x, u, w)\nGiven \\(x \\in \\calN\\) and \\(w \\in \\T_x\\calN\\), choose \\(q_w \\colon \\calN \\to \\reals\\) such that \\(\\grad q_w(x) = w\\) (for the specified \\(x\\)). Then \\(s = \\Hess q_w(x)[u]\\). If \\(\\calN\\) is Euclidean, a typical choice is \\(q_w = \\inner{\\cdot}{w}_\\calN\\), in which case \\(\\Hess q_w(x) = 0\\). If the field is omitted, it is assumed to be zero.\n\n\n\\(\\varphi\\) or \\(\\bar{\\varphi}\\)?\nlift.embedded\nBoolean flag set to false (by default) if all of the above indeed pertains to \\(\\varphi\\), and set to true if the above instead describes \\(\\bar{\\varphi} \\colon \\calE \\to \\calN\\), where \\(\\calE\\) is the embedding space for \\(\\calM\\) (as specified in the documentation for the corresponding factory), as a smooth extension such that \\(\\bar{\\varphi}|_\\calM = \\varphi\\). See Figure 1. In that case, the lift enables computation of \\(\\grad \\bar{g}\\) and \\(\\Hess \\bar{g}\\), which \\(\\calM\\) can then convert to \\(\\grad g\\) and \\(\\Hess g\\) using egrad2rgrad and ehess2rhess.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "lifts.html#available-lifts",
    "href": "lifts.html#available-lifts",
    "title": "Lifts: parameterizations made easy",
    "section": "Available lifts",
    "text": "Available lifts\nA number of lifts are readily available in Manopt, making it possible to optimize over various nonsmooth sets \\(\\calX = \\varphi(\\calM)\\). We list them in a table now, and detail the corresponding lifts below with some examples.\n\n\n\nTable 2: Examples of nonsmooth sets on which we can optimize with Manopt using a lift.\n\n\n\n\n\n\n\n\n\n\nName\n\\(\\calX = \\varphi(\\calM)\\)\nlift\n\n\n\n\nCube\n\\(\\{ x \\in \\Rn : -1 \\leq x_{i} \\leq 1 \\, \\forall i \\}\\)\ncubeslift(n)\n\n\nCubes\n\\(\\{ X \\in \\Rnm : -1 \\leq X_{ij} \\leq 1 \\, \\forall i,j \\}\\)\ncubeslift(n, m)\n\n\nBall\n\\(\\{ x \\in \\Rn : \\|x\\| \\leq 1 \\}\\)\nballslift(n)\n\n\nBalls\n\\(\\{ X \\in \\Rnm : \\|X_{:, i}\\| \\leq 1 \\, \\forall i \\}\\)\nballslift(n, m)\n\n\nSimplex\n\\(\\{ x \\in \\Rn : x_1 + \\cdots + x_n = 1, x_i \\geq 0 \\, \\forall i \\}\\)\nhadamardlift('simplex', n)\n\n\nColumn stochastic\n\\(\\{ X \\in \\Rnm : X^\\top\\One = \\One, X_{ij} \\geq 0 \\}\\)\nhadamardlift('colstochastic', n, m)\n\n\nRow stochastic\n\\(\\{ X \\in \\Rnm : X\\One = \\One, X_{ij} \\geq 0 \\}\\)\nhadamardlift('rowstochastic', n, m)\n\n\nNonnegative orthant\n\\(\\{ X \\in \\Rnm : X_{ij} \\geq 0 \\, \\forall i,j \\}\\)\nhadamardlift('nonnegative', n, m)\n\n\nBounded-rank\n\\(\\{ X \\in \\Rmn : \\rank(X) \\leq r \\}\\)\nburermonteiroLRlift(m, n, r)\n\n\nBounded-rank, semidefinite\n\\(S_n^p \\triangleq \\{ X \\in \\Rnn : X \\succeq 0, \\rank(X) \\leq p \\}\\)\nburermonteirolift('free', n, p)\n\n\n⤷ unit trace\n\\(\\{ X \\in S_n^p : \\trace(X) = 1 \\}\\)\nburermonteirolift('unittrace', n, p)\n\n\n⤷ unit diagonal\n\\(\\{ X \\in S_n^p : \\diag(X) = \\One \\}\\)\nburermonteirolift('unitdiag', n, p)\n\n\n\n\n\n\n\nCubes and squares\nlift = cubeslift(n);     % m = 1 by default\nlift = cubeslift(n, m);\nThe target set \\(\\calX\\) consists of vectors or matrices whose entries are in the closed interval \\([-1, 1]\\): \\[\n    \\calX = \\{ X \\in \\Rnm : -1 \\leq X_{ij} \\leq 1 \\ \\forall i, j \\}.\n\\] One way to think about it is as \\(m\\) points in the cube \\([-1, 1]^n\\) (the columns of \\(X\\)), or \\(n\\) points in the cube \\([-1, 1]^m\\) (the rows of \\(X\\)). This is a subset of \\(\\calN = \\Rnm\\), realized as the image of the lift \\(\\varphi \\colon \\calM \\to \\calN\\) with \\(\\calM = \\Rnm\\) and \\[\n    \\varphi(Y) = \\sin(Y),\n\\] where \\(\\sin\\) is applied entrywise.\nThis lift satisfies local \\(\\Rightarrow\\) local and 2 \\(\\Rightarrow\\) 1 everywhere. It also satisifies 1 \\(\\Rightarrow\\) 1 at all \\(Y \\in \\Rnm\\) such that \\(|X_{ij}| &lt; 1\\) for all \\(i,j\\) with \\(X = \\varphi(Y)\\). \nAs an example, consider \\(\\min_{x \\in \\Rn} \\frac{1}{2} x^\\top A x + b^\\top x\\) subject to \\(-1 \\leq x_i \\leq 1\\) for \\(i = 1, \\ldots, n\\):\n\nWithout automatic differentiationWith AD\n\n\nn = 5;\nA = randsym(n);\nb = randn(n, 1);\n\ndownstairs.M = euclideanfactory(n); % optional\ndownstairs.cost = @(x) .5*(x'*A*x) + b'*x;\ndownstairs.grad = @(x) A*x + b;\ndownstairs.hess = @(x, xdot) A*xdot;\n\nlift = cubeslift(n);\n\nupstairs = manoptlift(downstairs, lift);\n\ny = trustregions(upstairs);\n\nx = lift.phi(y);\n\n\nn = 5;\nA = randsym(n);\nb = randn(n, 1);\n\ndownstairs.cost = @(x) .5*(x'*A*x) + b'*x;\n\nlift = cubeslift(n);\n\n[upstairs, downstairs] = manoptlift(downstairs, lift, 'AD');\n\ny = trustregions(upstairs);\n\nx = lift.phi(y);\n\n\n\nNote that \\(\\calX\\) is convex. If \\(f\\) is convex (e.g., in the example above, if \\(A\\) is positive semidefinite), then the problem downstairs is convex. Therefore, first-order stationary points are global minima. Since the lift satisfies 2 \\(\\Rightarrow\\) 1, it follows that second-order critical points upstairs are global minima. In other words: the problem upstairs enjoys the strict saddle property (benign nonconvexity).\n\n\nBalls and disks\nlift = ballslift(n)     % m = 1 by default\nlift = ballslift(n, m)\nThe target set \\(\\calX\\) consists of matrices whose columns have norm at most one: \\[\n    \\calX = \\{ X \\in \\Rnm : X_{1i}^2 + \\cdots + X_{ni}^2 \\leq 1 \\textrm{ for } i = 1, \\ldots, m \\}.\n\\] We can think of \\(X\\) as \\(m\\) points (the columns of \\(X\\)) in the ball \\(B_n = \\{ x \\in \\Rn : \\|x\\| \\leq 1 \\}\\). This is a subset of \\(\\calN = \\Rnm\\), realized as the image of the lift \\(\\varphi \\colon \\calM \\to \\calN\\) with \\[\n\\calM = \\mathrm{Oblique}(n+1, m) = \\{ y \\in \\reals^{n+1} : \\|y\\| = 1 \\}^m \\subset \\reals^{(n+1) \\times m}\n\\] a product of \\(m\\) spheres in \\(\\reals^{n+1}\\) and \\[\n    \\varphi(Y) = Y_{1:n, 1:m}\n\\] the map which (column-wise) projects from \\(\\reals^{n+1}\\) down to \\(\\Rn\\) by removing the last coordinate.\nThis lift satisfies local \\(\\Rightarrow\\) local and 2 \\(\\Rightarrow\\) 1 everywhere. It also satisifies 1 \\(\\Rightarrow\\) 1 at all \\(Y \\in \\calM\\) such that \\(\\|X_{:i}\\| &lt; 1\\) for all \\(i\\) with \\(X = \\varphi(Y)\\): see Example 4.3 and Corollary 4.12 in the lifts paper.\nAs an example, fix \\(\\sigma &gt; 0\\) and consider \\(\\min_{x_1, \\ldots, x_m \\in \\Rn} \\log\\!\\left( \\sum_{i, j} e^{-\\frac{\\|x_i - x_j\\|^2}{2\\sigma^2}} \\right)\\) subject to \\(\\|x_i\\| \\leq 1\\) for \\(i = 1, \\ldots, m\\). The log-sum-exp is a smoothed version of the max over the numbers \\(-\\|x_i - x_j\\|^2\\). Therefore, this optimization problem (approximately) aims to pack \\(m\\) points in a ball in \\(\\Rn\\) in such a way that the minimal distance between any two points is as large as possible.\n% Try to pack m points in a ball in R^n\nn = 2;\nm = 64;\n\nlift = ballslift(n, m); % replace with cubeslift to pack in a cube\n\n% Transforms a Gram matrix G to a squared Euclidean distance matrix.\n% Uses cdiag instead of diag to be compatible with AD.\ngram2edm = @(G) cdiag(G)*ones(1, m) + ones(m, 1)*cdiag(G).' - 2*G;\n\nsigma = .05;\ndownstairs.cost = @(X) log(sum(exp(-gram2edm(X.'*X)/(2*sigma^2)), 'all'));\n\nupstairs = manoptlift(downstairs, lift, 'AD');\n\nY = trustregions(upstairs);\n\nX = lift.phi(Y);\n\n% Some code to display the results.\nif n == 2\n    plot(X(1, :), X(2, :), '.', 'MarkerSize', 20);\n    hold all;\n    t = linspace(0, 2*pi, 251);\n    plot(cos(t), sin(t), 'k-', 'LineWidth', 2);\n    plot(0, 0, 'k.', 'MarkerSize', 10);\n    axis equal off;\n    set(gcf, 'Color', 'w');\nend\n\n\nHadamard (entrywise product)\nDocumentation will be added.\n\n\nBurer-Monteiro for smooth SDP\nDocumentation will be added.\n\n\nBurer-Monteiro for general bounded-rank\nDocumentation will be added.\n\n\n\n\n\n\nDesingularization lift of bounded rank matrices.\n\n\n\nThe desingularizationfactory encodes the geometry of a Riemannian manifold, but egrad2rgrad and ehess2rhess in that factory actually correspond to a lift, as described in the documentation of the factory. Thus, it is not a lift in Manopt’s code base, but mathematically it acts as a lift of the set of bounded-rank matrices to a smooth manifold. This is a good alternative to the \\(LR^\\top\\) lift, with stronger theoretical properties as detailed in this paper.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "lifts.html#the-hessian-of-g",
    "href": "lifts.html#the-hessian-of-g",
    "title": "Lifts: parameterizations made easy",
    "section": "The Hessian of \\(g\\)",
    "text": "The Hessian of \\(g\\)\nTo obtain the Hessian of \\(g = f \\circ \\varphi\\), it is convenient to go through curves. Let \\(c \\colon \\reals \\to \\calM\\) be a smooth curve satisfying \\(c(0) = y\\), \\(c'(0) = v\\) and \\(c''(0) = 0\\) (zero initial intrinsic acceleration).\nPush it to a curve downstairs as \\(\\gamma = \\varphi \\circ c\\). It satisfies \\(\\gamma(0) = \\varphi(y) = x\\). Let \\(u = \\gamma'(0) = \\D\\varphi(c(0))[c'(0)] = \\D\\varphi(y)[v]\\).\nThe cost function along these curves satisfies \\[\n    g \\circ c = f \\circ \\varphi \\circ c = f \\circ \\gamma.\n\\] Thus, the derivatives of \\(g \\circ c\\) and \\(f \\circ \\gamma\\) (two functions from \\(\\reals\\) to \\(\\reals\\)) are identical. On the one hand, we compute \\[\n    (g \\circ c)'(t) = \\D g(c(t))[c'(t)] = \\inner{\\grad g(c(t))}{c'(t)}_{c(t)}\n\\] and \\[\n    (g \\circ c)''(t) = \\inner{\\Hess g(c(t))[c'(t)]}{c'(t)}_{c(t)} + \\inner{\\grad g(c(t))}{c''(t)}_{c(t)}.\n\\] At \\(t = 0\\), these yield \\[\n    (g \\circ c)'(0) = \\inner{\\grad g(y)}{v}_{y}\n\\] and \\[\n    (g \\circ c)''(0) = \\inner{\\Hess g(y)[v]}{v}_{y} + \\inner{\\grad g(y)}{c''(0)}_{y}.\n\\] On the other hand, applying the same computations to \\(f \\circ \\gamma\\) instead of \\(g \\circ c\\) yields \\[\n    (f \\circ \\gamma)'(0) = \\inner{\\grad f(x)}{u}_{x}\n\\] and \\[\n    (f \\circ \\gamma)''(0) = \\inner{\\Hess f(x)[u]}{u}_{x} + \\inner{\\grad f(x)}{\\gamma''(0)}_{x}.\n\\] We know that \\((g \\circ c)'(0) = (f \\circ \\gamma)'(0)\\) and also that \\((g \\circ c)''(0) = (f \\circ \\gamma)''(0)\\). We could use the first-order derivatives to recover the identity \\[\n    \\grad g(y) = \\D\\varphi(y)^*[\\grad f(x)].\n\\] Focusing on second-order derivatives, we have found that \\[\n    \\inner{\\Hess g(y)[v]}{v}_{y} = \\inner{\\Hess f(x)[u]}{u}_{x} + \\inner{\\grad f(x)}{\\gamma''(0)}_{x} - \\inner{\\grad g(y)}{c''(0)}_{y}.\n\\tag{1}\\] Recall that we assume \\(c''(0) = 0\\). To handle \\(\\gamma''(0)\\), we proceed as follows.\nFix an arbitrary \\(w \\in \\T_x\\calN\\) and let \\(q_w \\colon \\calN \\to \\reals\\) satisfy \\(\\grad q_w(x) = w\\) (that is, at the specific \\(x\\) under consideration, the gradient of \\(q_w\\) is \\(w\\)). For example, if \\(\\calN\\) is a Euclidean space, then a convenient choice is \\(q_w = \\inner{\\cdot}{w}_\\calN\\) (a linear function whose gradient at all points is \\(w\\): it’s more than we need).\nLet \\(h_w = q_w \\circ \\varphi\\). This is a real function on \\(\\calM\\). Plug \\(h_w\\) and \\(q_w\\) in place of \\(g\\) and \\(f\\) in Eq. 1. This reveals \\[\n    \\inner{\\Hess h_w(y)[v]}{v}_{y} = \\inner{\\Hess q_w(x)[u]}{u}_{x} + \\inner{\\grad q_w(x)}{\\gamma''(0)}_{x}.\n\\] Since \\(\\grad q_w(x) = w\\), we have found that \\[\n    \\inner{w}{\\gamma''(0)}_{x} = \\inner{\\Hess h_w(y)[v]}{v}_{y} - \\inner{\\Hess q_w(x)[u]}{u}_{x}.\n\\] Now let \\(w = \\grad f(x)\\) and plug this into Eq. 1 in order to get rid of \\(\\gamma''(0)\\), as follows: \\[\n    \\inner{\\Hess g(y)[v]}{v}_{y} = \\inner{\\Hess f(x)[u]}{u}_{x} + \\inner{\\Hess h_w(y)[v]}{v}_{y} - \\inner{\\Hess q_w(x)[u]}{u}_{x}.\n\\] Recall that \\(u = \\D\\varphi(y)[v]\\). Then, all in all, we have the following formula for the Riemannian Hessian of \\(g\\) at \\(y\\): \\[\n    \\Hess g(y) = \\D\\varphi(y)^* \\circ \\left( \\Hess f(x) - \\Hess q_w(x) \\right) \\circ \\D\\varphi(y) + \\Hess h_w(y),\n\\tag{2}\\] where\n\n\\(x = \\varphi(y)\\),\n\\(w = \\grad f(x)\\),\n\\(q_w \\colon \\calN \\to \\reals\\) is any smooth function which satisfies \\(\\grad q_w(x) = w\\), and\n\\(h_w = q_w \\circ \\varphi \\colon \\calM \\to \\reals\\).\n\n(The choice of curve \\(c\\) no longer plays a role.)\nThe final formula Eq. 2 tells us exactly what information we need about \\(\\varphi\\) in order to be able to compute the Hessian of \\(g\\) based on the gradient and Hessian of \\(f\\). The fields lift.Dphi and lift.Dphit encode the maps \\(\\D\\varphi(y)\\) and \\(\\D\\varphi(y)^*\\), while the field lift.hesshw encodes the map \\(\\Hess h_w(y)\\). If \\(\\calN\\) is a Euclidean space (which is typical), then we always choose \\(q_w = \\inner{\\cdot}{w}_\\calN\\) so that \\(\\Hess q_w(x) = 0\\). Otherwise, we need to provide that map too, in lift.hessqw.",
    "crumbs": [
      "Home",
      "Lifts"
    ]
  },
  {
    "objectID": "solvers.html",
    "href": "solvers.html",
    "title": "Solvers",
    "section": "",
    "text": "Solvers (that is, optimization algorithms) are functions in Manopt. Built-in solvers are located in /manopt/solvers. In principle, all solvers accept the following basic call format:\nx = mysolver(problem)\nThe returned value x is a point on the manifold problem.M. Depending on the properties of your problem and on the guarantees of the solver, x is more or less close to a good minimizer of the cost function described in the problem structure.\nBear in mind that we are dealing with usually nonconvex, and possibly nonsmooth or derivative-free optimization, so that it is in general not guaranteed that x is a global minimizer of the cost. For smooth problems with gradient information though, most decent algorithms guarantee that x is (approximately) a critical point. Typically, we even expect an approximate local minimizer, but even that is usually not guaranteed in all cases: this is a fundamental limitation of continuous optimization.\n\n\n\n\n\n\nMin or max?\n\n\n\nAll provided solvers are minimization algorithms. If you want to maximize your objective function, multiply it by -1 (and likewise for the derivatives of the objective function), as we did in the first example.\n\n\nAll solvers also admit a more complete call format:\n[x, xcost, info, options] = mysolver(problem, x0, options)\nInputs:\n\nThe problem structure specifies the manifold and describes the cost function.\nOptionally, x0 is an initial guess, or initial iterate, for the solver. It is typically a point on the manifold problem.M, but may be something else depending on the solver. It can be omitted by passing the empty matrix [] instead.\nOptionally, the options structure is used to fine tune the behavior of the optimization algorithm. On top of hosting the algorithmic parameters, it manages the stopping criteria as well as what information needs to be displayed and / or logged during execution.\n\nOutputs:\n\nx is the returned point on the manifold.\nxcost is the value of the cost function at x.\nThe info struct-array is described below, and contains information collected at each iteration of the solver’s progress.\nThe options structure is returned too, so you can see what default values the solver used on top of the options you (possibly) specified.",
    "crumbs": [
      "Home",
      "Solvers"
    ]
  },
  {
    "objectID": "solvers.html#general-description",
    "href": "solvers.html#general-description",
    "title": "Solvers",
    "section": "",
    "text": "Solvers (that is, optimization algorithms) are functions in Manopt. Built-in solvers are located in /manopt/solvers. In principle, all solvers accept the following basic call format:\nx = mysolver(problem)\nThe returned value x is a point on the manifold problem.M. Depending on the properties of your problem and on the guarantees of the solver, x is more or less close to a good minimizer of the cost function described in the problem structure.\nBear in mind that we are dealing with usually nonconvex, and possibly nonsmooth or derivative-free optimization, so that it is in general not guaranteed that x is a global minimizer of the cost. For smooth problems with gradient information though, most decent algorithms guarantee that x is (approximately) a critical point. Typically, we even expect an approximate local minimizer, but even that is usually not guaranteed in all cases: this is a fundamental limitation of continuous optimization.\n\n\n\n\n\n\nMin or max?\n\n\n\nAll provided solvers are minimization algorithms. If you want to maximize your objective function, multiply it by -1 (and likewise for the derivatives of the objective function), as we did in the first example.\n\n\nAll solvers also admit a more complete call format:\n[x, xcost, info, options] = mysolver(problem, x0, options)\nInputs:\n\nThe problem structure specifies the manifold and describes the cost function.\nOptionally, x0 is an initial guess, or initial iterate, for the solver. It is typically a point on the manifold problem.M, but may be something else depending on the solver. It can be omitted by passing the empty matrix [] instead.\nOptionally, the options structure is used to fine tune the behavior of the optimization algorithm. On top of hosting the algorithmic parameters, it manages the stopping criteria as well as what information needs to be displayed and / or logged during execution.\n\nOutputs:\n\nx is the returned point on the manifold.\nxcost is the value of the cost function at x.\nThe info struct-array is described below, and contains information collected at each iteration of the solver’s progress.\nThe options structure is returned too, so you can see what default values the solver used on top of the options you (possibly) specified.",
    "crumbs": [
      "Home",
      "Solvers"
    ]
  },
  {
    "objectID": "solvers.html#available-solvers",
    "href": "solvers.html#available-solvers",
    "title": "Solvers",
    "section": "Available solvers",
    "text": "Available solvers\nThe toolbox comes with a handful of solvers.\nThe most trust-worthy is the trust-regions algorithm. Originally, it is a modification of the code of GenRTR.\nThe toolbox was designed to accommodate many more solvers though: we have since then added BFGS-style solvers, stochastic gradient descent and more. In particular, we look forward to proposing algorithms for nonsmooth cost functions (which notably arise when L1 penalties are at play). You can also propose your own solvers.\n\nTable of minimization algorithms available in Manopt.\n\n\nName\nRequires (benefits of)\nComment\nCall\n\n\n\n\nTrust-regions (RTR)\nCost, gradient (Hessian, approximate Hessian, preconditioner)\n#1 choice for smooth optimization; uses finite differences (FD) of the gradient in the absence of Hessian.\ntrustregions\n\n\nAdaptive regularization by cubics (ARC)\nCost, gradient (Hessian, approximate Hessian)\nAlternative to RTR; uses FD of the gradient in the absence of Hessian.\narc\n\n\nSteepest descent\nCost, gradient\nGradient descent (GD) with line-search (default is backtracking-based).\nsteepestdescent\n\n\nConjugate gradient\nCost, gradient (preconditioner)\nOften performs better than steepest descent.\nconjugategradient\n\n\nBarzilai-Borwein\nCost, gradient\nGradient descent with BB step size heuristic.\nbarzilaiborwein\n\n\nBFGS\nCost, gradient\nLimited-memory version of BFGS.\nrlbfgs\n\n\nSGD\nPartial gradient (preconditioner) [Cost not needed]\nStochastic gradient algorithm for optimization of large sums.\nstochasticgradient\n\n\nParticle swarm (PSO)\nCost\nDerivative-free optimizer (DFO) based on a population of points.\npso\n\n\nNelder-Mead\nCost\nDFO based on a simplex; requires M.pairmean; limited to (very) low-dimensional problems.\nneldermead",
    "crumbs": [
      "Home",
      "Solvers"
    ]
  },
  {
    "objectID": "solvers.html#the-options-structure",
    "href": "solvers.html#the-options-structure",
    "title": "Solvers",
    "section": "The options structure",
    "text": "The options structure\nIn Manopt, all options are optional. Standard options are assigned a default value at the toolbox level in /manopt/core/getGlobalDefaults.m (it’s a core tool, best not to edit it). Solvers then overwrite and complement these options with solver-specific fields. These options are in turn overwritten by the user-specified options, if any.\nThe subsections below list commonly used options. See each solver’s documentation for specific information (e.g., type help trustregions).\n\nGeneric options\nThe following table lists options to control text output during solver execution, whether additional debugging checks are run, and a (deprecated) option to control memory usage from caching.\n\nTable of generic options used by most solvers.\n\n\nField name (options.\"...\")\nValue type\nDescription\n\n\n\n\nverbosity\ninteger\nControls how much information a solver outputs during execution; 0: no output; 1 : output at init and at exit; 2: light output at each iteration; 3+: all you can read.\n\n\ndebug\ninteger\nIf larger than 0, the solver may perform additional computations for debugging purposes.\n\n\nstoredepth\ninteger\nMaximum number of store structures that may be kept in memory (see the cost description page). As of Manopt 5.0, this is mostly irrelevant because the main solvers do a much better job of discarding stale information on the go.\n\n\n\n\n\nOptions for stopping criterion\nSolvers stop running when one of several stopping criteria triggers. The following table lists options for some standard criteria.\n\nTable of generic stopping criterion options used by most solvers.\n\n\n\n\n\n\n\nField name (options.\"...\")\nValue type\nDescription\n\n\n\n\nmaxiter\ninteger\nLimits the number of iterations of the solver.\n\n\nmaxtime\ndouble\nLimits the execution time of the solver, in seconds.\n\n\ntolcost\ndouble\nStop as soon as the cost drops below this tolerance.\n\n\ntolgradnorm\ndouble\nStop as soon as the norm of the gradient drops below this tolerance.\n\n\nstopfun\nfun. handle\nCustom stopping criterion: see below.\n\n\n\nSome solvers offer additional stopping criteria.\nUsers can also define custom stopping criteria with options.stopfun. The general usage pattern is as follows:\n% define your problem structure, then:\noptions.stopfun = @mystopfun;\nx = mysolver(problem, [], options);\n\nfunction [stopnow, reason] = mystopfun(problem, x, info, last)\n   if xyz % decide if should stop based on inputs\n    stopnow = true;\n    reason = 'This optional message explains why we stopped.';\n  else\n    stopnow = false;\n    reason = '';\n  end\nend\nThe function handle options.stopfun is called after each iteration completes. As input, it receives:\n\nthe problem structure,\nthe current point x,\nthe whole info struct-array built so far, and\nan index last such that info(last) is the structure pertaining to the current iteration (this is because info is pre-allocated, so that info(end) typically does not refer to the current iteration).\n\nThe outputs are:\n\na Boolean stopnow: the solver terminates if this is true;\noptionally, a string reason which explains why the criterion triggered. This is displayed by the solver if options.verbosity &gt; 0.\n\nConsider the following example:\noptions.stopfun = @mystopfun;\nfunction stopnow = mystopfun(problem, x, info, last)\n    stopnow = (last &gt;= 3 && info(last-2).cost - info(last).cost &lt; 1e-3);\nend\nThis tells the solver to exit as soon as two successive iterations combined have decreased the cost by less than \\(10^{-3}\\).\nSee also the tools page for a list of built-in ways to use stopfun to good effect. For example:\n\nStop a solver on demand by closing a figure or by deleting a file. These allow to gracefully interrupt a solver interactively without breaking program execution. The second one is especially useful when running code remotely without GUI.\nStop a solver using Manopt counters. This makes it easy to stop after a certain budget of function calls, matrix-vector products etc. has been exceeded.\n\n\n\nStatsfun option for recording info at each iteration\nThe function handle options.statsfun is called after each iteration completes. It provides an opportunity to process information about each iteration. The main purpose is to store information, but this option can also be used to print, save, plot, etc.\nHere is an example:\n% define your problem structure, then:\noptions.statsfun = @mystatsfun;\n[x, fx, info] = mysolver(problem, [], options);\n\nfunction stats = mystatsfun(problem, x, stats, store)\n    stats.current_point = x;\nend\nThis logs all the points visited during the optimization process in the info struct-array returned by the solver. One could also write x to disk during this call, or update a plot (if that is useful).\nAs input, statsfun receives:\n\nthe problem structure,\nthe current point x,\nthe stats structure for the current iteration as recorded in the info struct-array, and\n(optionally) the store structure with the cache for x (and the common cache in store.shared).\n\nThe output is the stats structure. This function gives you a chance to modify the stats structure, hence to add fields if you want to.\nBear in mind that structures in a struct-array must all have the same fields: if statsfun adds a certain field to a stats structure, it must do so for all iterations. (In some instances, it is even important that the fields be created in the same order.)\nTime spent in statsfun is discounted from execution time recorded in [info.time], as this is typically only used for prototyping, debugging, plotting etc.\nIf you include store as an input for the statsfun, this lets you access the data you cached, both for that particular iterate. You also get access to the cache in store.shared, common to all points x visited by the solver so far. Note that statsfuncan read but it cannot write to store (modifications are lost).\nAn alternative to creating a statsfun by hand is to use the statsfunhelper tool. This is sometimes simpler (and allows to pass inline functions). The example above simplifies to:\noptions.statsfun = statsfunhelper('current_point', @(x) x);\nThe helper can also be used to log more than one metric, by passing it a structure. In the example below, x_reference is a certain point on the manifold problem.M. The stats structures will include fields current_point and dist_to_ref. Notice how the function handles can take different inputs. See the help of that tool for more info.\nmetrics.current_point = @(x) x;\nmetrics.dist_to_ref = @(problem, x) problem.M.dist(x, x_reference);\noptions.statsfun = statsfunhelper(metrics);\nSee also how to use Manopt counters to keep track of things such as the number of calls to cost, gradient and Hessian, or other special operations such as matrix-vector products. These counters are registered at every iteration and available in the returned stats structure. They can also be used in a stopping criterion.\n\n\n\n\n\n\nstatsfun is called after each iteration completes\n\n\n\nUpon completion of an iteration, options.statsfun is called with the point x that was reached last, even if that x did not change compared to the previous iteration. For example, with trustregions, this triggers after the accept/reject decision. If the step was accepted, we get that new x, optionally with its store. If the step was rejected, we get the same x as previously, likewise with its store. The nuance is this: there is a stats structure for each iteration, but there is a store structure for each point. \n\n\n\n\nOption to specify a line-search\nSome solvers, such as steepestdescent and conjugategradient, need to solve a line-search problem at each iteration. That is, they need to (approximately) solve the one-dimensional optimization problem:\n\\[\n  \\min_{t\\geq 0} \\phi(t) = f(\\Retr_x(td)),\n\\]\nwhere \\(x\\) is the current point on the manifold, \\(d\\) is a tangent vector at \\(x\\) (the search direction), \\(\\Retr\\) is the retraction on the manifold and \\(f\\) is the cost function. Assuming \\(d\\) is a descent direction, there exists \\(t &gt; 0\\) such that \\(\\phi(t) &lt; \\phi(0) = f(x)\\). The purpose of a line-search algorithm is to find such a real number \\(t\\).\nManopt includes certain generic purpose line-search algorithms. To force the use of one of them or of your own, specify this in the options structure (not in the problem structure), for example as follows:\noptions.linesearch = @linesearch_adaptive;\nEach line-search algorithm accepts its own options which can be added in this same options structure passed to the main solver. See each line-search’s help for details.\nFor certain problems, you may want to implement your own line-search, typically in order to exploit structure specific to the problem at hand. To this end, it is best to start from an existing line-search function and to adapt it. Alternatively (and perhaps more easily), you may specify a linesearch function in the problem structure (see the cost description page) and use a line-search that uses it, to incorporate the additional information you supply there. Do not hesitate to ask for help on the forum if you have questions on this feature.",
    "crumbs": [
      "Home",
      "Solvers"
    ]
  },
  {
    "objectID": "solvers.html#the-info-struct-array",
    "href": "solvers.html#the-info-struct-array",
    "title": "Solvers",
    "section": "The info struct-array",
    "text": "The info struct-array\nThe various solvers log information at each iteration about their progress. This information is returned in the output info.\nThis is a struct-array, that is, an array of structures. Read this MathWorks blog post for more on this data container in Matlab.\nFor example, to extract a vector containing the cost value at each iteration, call [info.cost] with the brackets. To plot the cost function value against computation time, call\nplot([info.time], [info.cost]);\nThe following table lists some indicators that might be present in the info output.\n\nTable of typical information tracked at each iteration and returned in the info struct-array. Specific solvers typically include additional fields: check out their documentation.\n\n\n\n\n\n\n\nField name ([info.\"...\"])\nValue type\nDescription\n\n\n\n\niter\ninteger\nIteration number (0 corresponds to the initial guess).\n\n\ntime\ndouble\nElapsed execution time until completion of the iterate, in seconds.\n\n\ncost\ndouble\nAttained value of the cost function.\n\n\ngradnorm\ndouble\nAttained value for the norm of the Riemannian gradient.\n\n\n\nA specific solver may not populate all of these fields and may provide additional fields, which would then be described in the solver’s documentation.\n\n\n\n\n\n\nNeed to log problem-specific information at each iteration?\n\n\n\nInclude a statsfun in your options structure: read more here. Also read about Manopt counters to keep track of things such as function calls, Hessian calls, matrix products, etc.\n\n\n\n\n\n\n\n\nAbout execution time recorded in info.time\n\n\n\nThe execution time is logged without incorporating time spent in statsfun, as it usually performs computations that are not needed to solve the optimization problem. If, however, your statsfun influences the final output of the solver (e.g., because it logs information that you then use in your stopfun criterion), then you should add the relevant computation time to the stats.time field.",
    "crumbs": [
      "Home",
      "Solvers"
    ]
  }
]