<!DOCTYPE html>
<html lang="en">
  <head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <title>Manopt, tutorial</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Nicolas Boumal">
    <link href="favicon.ico" rel="icon" type="image/x-icon">
    <!-- Le styles -->
    <link href="bootstrap/css/bootstrap.css" rel="stylesheet">
    <style type="text/css">
body {
        padding-top: 80px;
        padding-bottom: 40px;
}
      thead {
        font-weight: bold;
      }
    </style>
    <link href="bootstrap/css/bootstrap-responsive.css" rel="stylesheet">
    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>    <![endif]-->
    <link href="bootstrap/css/prettify.css" type="text/css" rel="stylesheet">
    <link href="bootstrap/css/lang-matlab.css" type="text/css" rel="stylesheet">
  </head>
  <body onload="prettyPrint()" data-spy="scroll" data-target=".sidebar">
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner"> <a class="btn btn-navbar" data-toggle="collapse"
          data-target=".nav-collapse"> <span class="icon-bar"></span> <span
            class="icon-bar"></span> <span class="icon-bar"></span> </a>
        <div class="container"> <a class="brand" href="index.html">Manopt</a>
          <div class="nav-collapse collapse">
            <ul class="nav">
              <li><a href="index.html"><i class="icon-home"></i> Home</a></li>
              <li class="active"><a href="tutorial.html"><i class="icon-road"></i> Tutorial</a></li>
              <li><a href="downloads.html"><i class="icon-download-alt"></i> Downloads</a></li>
              <li><a href="forum.html"><i class="icon-edit"></i> Forum</a></li>
              <li><a href="about.html"><i class="icon-user"></i> About</a></li>
              <li><a href="#contactmodal" data-toggle="modal"><i class="icon-envelope"></i> Contact</a></li>
            </ul>
          </div>
          <!--/.nav-collapse --> </div>
      </div>
    </div>
    <!-- Contact modal Begin -->
    <div id="contactmodal" class="modal hide fade" tabindex="-1" role="dialog"
      aria-labelledby="myModalLabel" aria-hidden="true">
      <div class="modal-header"> <button type="button" class="close" data-dismiss="modal"
          aria-hidden="true">&#215;</button>
        <h3 id="myModalLabel">To contact us</h3>
      </div>
      <div class="modal-body">
        <p>To discuss code, it is best to use the <a href="forum.html">forum</a>.</p>
        <p>For things not suitable for the forum, e-mail us at <a href="mailto:manopttoolbox@gmail.com">manopttoolbox@gmail.com</a>.</p>
        <p>We are happy to receive feedback and bug reports or requests for more features, to discuss the toolbox in general as well as its documentation and to help you use it.</p>
        <p>We would also love to know how you use the toolbox, and if you built nice manifold factories, solvers or tools that could benefit others.</p>
      </div>
      <div class="modal-footer"> <button class="btn" data-dismiss="modal"
          aria-hidden="true">Close</button> </div>
    </div>
    <!-- Contact modal End -->
    <div class="container">
      <div class="row">
        <div class="span3 sidebar" style="min-height: 1px">
          <!--Sidebar content-->
          <!-- class="nav nav-tabs nav-stacked mysidebar" -->
          <ul class="nav nav-list mysidebar" data-spy="affix">
            <li class="nav-header">Tutorial</li>
            <li><a href="#gettingstarted">Getting started</a></li>
            <li><a href="#firstexample">A first example</a></li>
            <li><a href="#manifolds">Manifolds</a></li>
            <li><a href="#solvers">Solvers</a></li>
            <li><a href="#costdescription">Describing the cost</a></li>
            <li><a href="#tools">Helpful tools</a></li>
            <li><a href="#reference">Reference</a></li>
          </ul>
        </div>
        <div class="span9">
          <!--Body content-->
          <section id="gettingstarted">
            <div class="page-header">
              <h1>Getting started with Manopt </h1>
            </div>
            <h3>Foreword</h3>
            <p><strong>With Manopt, you can solve optimization problems on manifolds</strong> using state-of-the-art algorithms, with minimal effort. The toolbox targets great flexibility in the problem description and comes with advanced features, such as caching.</p>
            <p>The toolbox architecture is based on a <strong>separation of the manifolds, the solvers and the problem descriptions</strong>. For basic use, one only needs to pick a manifold from the library, describe the cost function (and possible derivatives) on this manifold and pass it on to a solver. Accompanying tools help the user in common tasks such as numerically checking whether the cost function agrees with its derivatives up to the appropriate order etc.</p>
            <p><strong>This is a </strong><strong>prototyping toolbox</strong>, designed based on the idea that the costly part of solving an optimization problem is querying the cost function, and not the inner machinery of the solver. It is also work in progress: <strong> feedback and contributions are welcome</strong>!</p>
            <p><a href="reference/examples/index.html">Examples are available in the reference</a>. </p>
            <p>It helps us to know our users: please <a target="_blank"
                href="https://docs.google.com/forms/d/1U9Ntex_rWI8NfCLPP_b8uE5xDnKXgXG-HVvpHdq1PFo/viewform?usp=send_form">follow this link to introduce yourself</a>. Thanks!</p>
            <h3>Download </h3>
            <p><a target="_blank" class="btn btn-primary" href="download.html">Download <i
                  class="icon-download-alt icon-white"></i></a>&#160;&#160; The current version is 1.0.6 and was packaged on June 25<sup></sup>, 2014. The file is less than 200 Kb.</p>
            <h3>Install</h3>
            <blockquote>
              <ol>
                <li>Unzip and copy the whole <tt>manopt</tt> directory you just downloaded in a location of your choice on disk, say, in <tt>/my/directory/</tt>.</li>
                <li>Go to <tt>/my/directory/manopt/</tt> at the command prompt and execute <code>importmanopt</code>. You may save this path for your next Matlab sessions: follow the menu <tt>File &#187; Set Path...</tt> and <span
                    style="font-family: monospace;">save</span>. </li>
              </ol>
            </blockquote>
            <h3>Check</h3>
            <p> Go to <tt>/my/directory/manopt/checkinstall/</tt> and run the script <tt>basicexample.m</tt>. If there are no errors, you are done! Otherwise, feel free to contact us. </p>
          </section>
          <section id="firstexample">
            <div class="page-header">
              <h1>A first example</h1>
            </div>
            <h3>The mathematics</h3>
            <p>In this first example, we will compute a dominant eigenvector of a symmetric matrix $A \in \mathbb{R}^{n\times n}$. Let $\lambda_1 \geq \cdots \geq \lambda_n$ be its eigenvalues. The largest eigenvalue, $\lambda_1$, <a
                href="http://en.wikipedia.org/wiki/Rayleigh_quotient" rel="tooltip"
                title="Search for 'Rayleigh quotient' if need be.">is known to be</a> the optimal value for the following optimization problem:</p>
            <p>$$\max\limits_{x\in\mathbb{R}^n, x \neq 0} \frac{x^T A x}{x^T x}.$$</p>
            <p>This can be rewritten as follows:</p>
            <p>$$\min\limits_{x\in\mathbb{R}^n, \|x\| = 1} -x^T A x.$$</p>
            <p>The cost function and its gradient in $\mathbb{R}^n$ read:</p>
            <p>$$<br>
              \begin{align}<br>
              &#160;&#160;&#160; f(x) &amp; = -x^T A x,\\<br>
              &#160;&#160;&#160; \nabla f(x) &amp; = -2Ax.<br>
              \end{align}<br>
              $$</p>
            <p>The constraint on the vector $x$ requires that $x$ be of unit 2-norm, that is, $x$ is a point on the sphere</p>
            <p>$$\mathbb{S}^{n-1} = \{x \in \mathbb{R}^n : x^Tx = 1\}.$$</p>
            <p>This is all the information we need to apply Manopt to our problem.</p>
            <p>Users interested in how optimization on manifolds works will be interested in the following too: the cost function is smooth on $\mathbb{S}^{n-1}$. Its Riemannian gradient on $\mathbb{S}^{n-1}$ at $x$ is a tangent vector to the sphere at $x$. It can be computed as the projection from the usual gradient $\nabla f(x)$ to that tangent space using the orthogonal projector $\mathrm{Proj}_x u = (I-xx^T)u$:</p>
            <p>$$\mathrm{grad}\,f(x) = \mathrm{Proj}_x \nabla f(x) = -2(I-xx^T)Ax.$$</p>
            <p>This is an example of a mathematical relationship between the Euclidean gradient $\nabla f$, which we often already know how to compute from introductory calculus courses, and the Riemannian gradient $\mathrm{grad}\,f$, which is needed for the optimization. Fortunately, for most manifolds in Manopt the conversion happens behind the scenes via a function called <code>egrad2rgrad</code> and we only need to compute $\nabla f$.</p>
            <p>We will solve this simple optimization problem using Manopt to illustrate the most basic usage of the toolbox. For additional theory, see [AMS08], section 4.6.</p>
            <p>[AMS08] P.-A. Absil, R. Mahony and R. Sepulchre, <a target="_blank"
                href="http://press.princeton.edu/chapters/absil/">Optimization Algorithms on Matrix Manifolds</a>, Princeton University Press, 2008.</p>
            <h3>The code</h3>
            <p>Solving this optimization problem using Manopt requires little code: </p>
            <!--  pre-scrollable -->
            <pre class="prettyprint lang-matlab linenums">% Generate the problem data.
n = 1000;
A = randn(n);
A = .5*(A+A');

% Create the problem structure.
manifold = spherefactory(n);
problem.M = manifold;

% Define the problem cost function and its gradient.
problem.cost = @(x) -x'*(A*x);
problem.grad = @(x) manifold.egrad2rgrad(x, -2*A*x);

% Numerically check gradient consistency.
checkgradient(problem);

% Solve.
[x, xcost, info, options] = trustregions(problem);

% Display some statistics.
figure;
semilogy([info.iter], [info.gradnorm], '.-');<br>xlabel('Iteration number');<br>ylabel('Norm of the gradient of f');</pre>
            <p>Let us look at the code bit by bit.
              <!--The first thing
              to do is to tell Matlab to import some of Manopt's tools in the              current namespace, using the <code>import</code> command:</p>            <pre class="prettyprint lang-matlab linenumsoffset linenums:1">import manopt.solvers.trustregions.*;import manopt.manifolds.sphere.*;import manopt.tools.*;</pre>            <p>Thanks to the first import for example, we can access the              function <code>trustregions(...)</code> which is defined in <tt>(manopt-directory)/+manopt/+solvers/+trustregions/trustregions.m</tt>.              Alternatively, if we do not issue the import commands, we can              access that function using <code>manopt.solvers.trustregions.trustregions(...)</code>.</p>            <div class="alert alert-info"><strong>Heads up!</strong> The import              command only works if the directory containing the directory              +manopt has been added to the path <em><emph>before</emph> </em>the              import command is issued. If the import command is issued in a              function rather than in a script, the file containing that              function needs to be reloaded by Matlab after the path is updated.              To force Matlab to reload a file <tt>myfunction.m</tt>, type the              command <code>clear myfunction</code> in the command prompt.</div>            <p>Next,-->First, we generate some data for our problem and execute these two lines:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:7">manifold = spherefactory(n);
problem.M = manifold;
</pre>
            <p>The call to <code>spherefactory(n)</code> returns a structure describing the manifold $\mathbb{S}^{n-1}$, i.e., the sphere. This manifold corresponds to the constraint appearing in our optimization problem. For other constraints, take a look at the <a
                href="#manifolds">various supported manifolds</a>. The second instruction creates a structure named <code>problem</code> and sets the field <code>problem.M</code> to contain the manifold structure. The problem structure will be populated with everything a solver could need to know about the problem in order to solve it, such as the cost function and its gradient:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:11">problem.cost = @(x) -x'*(A*x);
problem.grad = @(x) manifold.egrad2rgrad(x, -2*A*x);
</pre>
            <p>The cost function and its derivatives are specified as <a
                href="http://www.mathworks.nl/help/matlab/ref/function_handle.html">function handles</a>. Notice how the gradient was specified as the projection of the Euclidean gradient of $f$, i.e., $\nabla f(x) = -2Ax$, with a simple call of <code>manifold.egrad2rgrad(x, u)</code> which is an implementation of the orthogonal projector $\mathrm{Proj}_x u$ mentioned in the problem introduction. This is particularly useful when one is working with a more complicated manifold.</p>
            <p>An alternative to the definition of the gradient is to specify the Euclidean gradient directly, and let Manopt call <code>egrad2rgrad</code> itself:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:12">problem.egrad = @(x) -2*A*x;
</pre>
            <p>Mind the names: <code>problem.grad</code> is to specify the <em>Riemannian</em> gradient. If you want to specify the <em>Euclidean</em> gradient, the correct name is <code>problem.egrad</code>, with an "e". For day to day use, this is the often the preferred way to go.</p>
            <div class="alert alert-info"><strong>Tip!</strong> Notice that the functions <code>cost</code> <emph>and</emph> <code>grad</code> <emph>both</emph> compute the product $Ax$, which is likely to be the most expensive operation for large scale problems. This is perfectly fine for prototyping, but not for a final version of the implementation. See the many ways of <a
                href="#costdescription">describing the cost function</a> for alternatives that alleviate redundant computations.</div>
            <p>The next instruction is not needed to solve the problem but often helps at the prototyping stage:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:15">checkgradient(problem);
</pre>
            <p>The <code>checkgradient(...)</code> tool verifies numerically that the cost function and its gradient agree up to the appropriate order. See the <a
                href="#tools">tools section</a> for more details and more helpful tools offered by Manopt. This tool generates the following figure:</p>
            <p><img title="checkgradient figure" alt="checkgradient figure"
                src="tutorial-gradientcheck.png"></p>
            <p>The blue curve seems to have the same slope as the dashed line over a decent segment: that's what we want to see. We now call a solver for our problem:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:18">[x, xcost, info, options] = trustregions(problem);
</pre>
            <p>This instruction calls <code>trustregions(...)</code> on our problem, without initial guess and without options structure. As a result, the solver will generate a random initial guess automatically and resort to the default values for all options. As a general feature in Manopt, all options are, well, optional. The returned values are <code>x</code> (usually a local minimizer of the cost function), <code>xcost</code> (the cost value attained by <code>x</code>), <code>info</code> (a struct-array containing information about the successive iterations performed by the solver) and <code>options</code> (a structure containing all options used and their values: take a peek to find out what you can parameterize). For more details and more solvers, see the <a
                href="#solvers">solvers</a> section.</p>
            <div class="alert alert-info">This call will issue a warning because the trust-regions algorithm normally requires the Hessian of the cost function, or an approximation of it, to be provided in the problem structure. When the Hessian is not provided, Manopt will approximate it using a finite differencing scheme on the gradient function and warn you about it. You may disable this warning by calling <code>warning('off', 'manopt:getHessian:approx');</code>. </div>
            <p>Finally, we access the contents of the struct-array <code>info</code> to display the convergence plot of our solver: </p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:22">semilogy([info.iter], [info.gradnorm], '.-');<br>xlabel('Iteration number');<br>ylabel('Norm of the gradient of f');
</pre>
            <p>This generates the following figure:</p>
            <p><img title="Gradient norm converging to zero" alt="Gradient norm converging to zero"
                src="tutorial-gradientnorm.png"></p>
            <p>For more information on what data is stored in <code>info</code>, see the <a
                href="#solvers">solvers</a> section.</p>
            <div class="alert alert-info"><strong>Heads up!</strong> Notice that we write <code>[info.xxx]</code> and not simply <code>info.xxx</code>, because <code>info</code> is a <emph>struct-array</emph>. Read this <a
                href="http://blogs.mathworks.com/loren/2007/04/19/vectorizing-access-to-an-array-of-structures/">MathWorks blog post</a> for further information.</div>
          </section>
          <section id="manifolds">
            <div class="page-header">
              <h1>Manifolds </h1>
            </div>
            <h3>General description <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"> </h3>
            <p>Manifolds in Manopt are represented as structures and are obtained by calling a factory. Built-in factories are located in <tt>/manopt/manifolds</tt>. Picking a manifold corresponds to specifying a search space for the decision variables. For the special (but common) case of a submanifold, the manifold represents a constraint on the decision variables (such as the sphere, which constrains vectors to have unit norm). In the case of a quotient manifold, the manifold captures an invariance in the cost function (such as the Grassmann manifold). Typically, points on the manifold as well as tangent vectors are represented by matrices.</p>
            <h3 id="manifoldslibrary">Available manifolds </h3>
            <p>Manopt comes with a number of implementations for generically useful manifolds. Of course, manifolds can also be user-defined. The best way to build your own is probably to read the code of some of the standard factories and to adapt what needs to be changed. If you develop an interesting manifold factory and would like to share it, be sure to let us know: we would love to add it to Manopt if it can be of interest to other users!</p>
            <p><em>In the future, there will be a documentation page for each manifold.</em> </p>
            <!-- table-bordered table-condensed -->
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Set </td>
                  <td>Factory</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="reference/manopt/manifolds/euclidean/euclideanfactory.html">Euclidean space</a> </td>
                  <td>$\mathbb{R}^{m\times n}$ </td>
                  <td><code>euclideanfactory(m, n)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/euclidean/symmetricfactory.html">Symmetric matrices</a> </td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X = X^T\}^k$ </td>
                  <td><code>symmetricfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_sphere.html">Sphere</a> </td>
                  <td>$\{X\in\mathbb{R}^{n\times m} : \|X\|_\mathrm{F} = 1\}$ </td>
                  <td><code>spherefactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/sphere/spherecomplexfactory.html">Complex sphere</a> </td>
                  <td>$\{X\in\mathbb{C}^{n\times m} : \|X\|_\mathrm{F} = 1\}$ </td>
                  <td><code>spherecomplexfactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_oblique.html">Oblique manifold</a> </td>
                  <td>$\{X\in\mathbb{R}^{n\times m} : \|X_{:1}\| = \cdots = \|X_{:m}\| = 1\}$ </td>
                  <td><code>obliquefactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/complexcircle/complexcirclefactory.html">Complex circle</a> </td>
                  <td>$\{z\in\mathbb{C}^n : |z_1| = \cdots = |z_n| = 1\}$ </td>
                  <td><code>complexcirclefactory(n)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/stiefel/stiefelfactory.html">Stiefel manifold </a></td>
                  <td>$\{X \in \mathbb{R}^{n \times p} : X^TX = I_p\}^k$ </td>
                  <td><code>stiefelfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/grassmann/grassmannfactory.html">Grassmann manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{R}^{n \times p}, X^TX = I_p\}^k$ </td>
                  <td><code>grassmannfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_rotations.html">Rotation group</a> </td>
                  <td>$\{R \in \mathbb{R}^{n \times n} : R^TR = I_n, \det(R) = 1\}^k$ </td>
                  <td><code>rotationsfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td>Fixed-rank </td>
                  <td>$\{X \in \mathbb{R}^{m \times n} : \operatorname{rank}(X) = k\}$ </td>
                  <td> <code>fixedrankembeddedfactory(m, n, k)</code> <a
                      href="reference/manopt/manifolds/fixedrank/fixedrankembeddedfactory.html">(ref)</a><br>
                    <code>fixedrankfactory_2factors(m, n, k)</code> <a
                      href="manifold_documentation_fixedrank_2factors.html">(doc)</a><br>
                    <code>fixedrankfactory_2factors_preconditioned(m, n, k)</code> <a
                      href="reference/manopt/manifolds/fixedrank/fixedrankfactory_2factors_preconditioned.html">(ref)</a><br>
                    <code>fixedrankfactory_2factors_subspace_projection(m, n, k)</code> <a
                      href="reference/manopt/manifolds/fixedrank/fixedrankfactory_2factors_subspace_projection.html">(ref)</a><br>
                    <code>fixedrankfactory_3factors(m, n, k)</code> <a
                      href="reference/manopt/manifolds/fixedrank/fixedrankfactory_3factors.html">(ref)</a><br>
                    <code>fixedrankMNquotientfactory(m, n, k)</code> <a
                      href="reference/manopt/manifolds/fixedrank/fixedrankMNquotientfactory.html">(ref)</a></td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_symfixedrank.html">Symmetric positive semidefinite, fixed-rank</a> </td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0, \operatorname{rank}(X) = k\}$ </td>
                  <td><code>symfixedrankYYfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/symfixedrank/elliptopefactory.html">Symmetric positive semidefinite, fixed-rank with unit diagonal</a></td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0, \operatorname{rank}(X) = k, \operatorname{diag}(X) = 1\}$</td>
                  <td><code>elliptopefactory(n, k)</code></td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/symfixedrank/spectrahedronfactory.html">Symmetric positive semidefinite, fixed-rank with unit trace</a></td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0, \operatorname{rank}(X) = k, \operatorname{trace}(X) = 1\}$</td>
                  <td><code>spectrahedronfactory(n, k)</code></td>
                </tr>
              </tbody>
            </table>
            <p>Bear in mind that a set can often be turned into a Riemannian manifold in many different ways by choosing one or another metric. Which is best for you will depend on your application. This is particularly true for the geometries of the fixed-rank matrices. The latter is a hot topic of research right now and there is no better method yet than experimenting with various geometries.</p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need to work on a <emph>product</emph> of manifolds? For example, are you minimizing a function $f(X, Y)$ where $X$ has unit norm and $Y$ is orthonormal? Then make sure to check out <code>productmanifold</code> and <code>powermanifold</code> in the <a
                href="#tools">tools section</a>. </div>
            <h3>Manifold structure fields</h3>
            <p></p>
            <p>A manifold structure has a number of fields, most of which contain function handles. Here is a list of things you might find in a structure <code>M</code> returned by a manifold factory:</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Field usage </td>
                  <td>Functionality </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Name </td>
                  <td><code>M.name()</code> </td>
                  <td>Returns a name for the manifold as a string. </td>
                </tr>
                <tr>
                  <td>Dimension </td>
                  <td><code>M.dim() </code></td>
                  <td>Returns the dimension of the manifold. </td>
                </tr>
                <tr>
                  <td>Metric </td>
                  <td><code>M.inner(x, u, v) </code></td>
                  <td>Computes $\langle u, v \rangle_x$. </td>
                </tr>
                <tr>
                  <td>Norm </td>
                  <td><code>M.norm(x, u) </code></td>
                  <td>Computes $\|u\|_x = \sqrt{\langle u, u \rangle_x}$</td>
                </tr>
                <tr>
                  <td>Distance </td>
                  <td><code>M.dist(x, y) </code></td>
                  <td>Computes $\operatorname{dist}(x, y)$, the Riemannian distance. </td>
                </tr>
                <tr>
                  <td>Typical distance </td>
                  <td><code>M.typicaldist() </code></td>
                  <td>Returns the "scale" of the manifold. This is used by the trust-regions solver for example, to determine default initial and maximal trust-region radii.</td>
                </tr>
                <tr>
                  <td>Tangent space projector </td>
                  <td><code>M.proj(x, u) </code></td>
                  <td>Computes $\operatorname{Proj}_x u$, the orthogonal projection of the vector $u$ from the ambient or total space to the tangent space at $x$ or to the horizontal space at $x$. </td>
                </tr>
                <tr>
                  <td>Euclidean to Riemannian gradient</td>
                  <td><nobr><code>M.egrad2rgrad(x, egrad)</code></nobr></td>
                  <td>For manifolds embedded in a Euclidean space, converts the gradient of $f$ at $x$ seen as a function in that Euclidean space to the Riemannian gradient of $f$ on the manifold.</td>
                </tr>
                <tr>
                  <td>Euclidean to Riemannian Hessian</td>
                  <td><code>M.ehess2rhess(x, egrad, ehess, u)</code> </td>
                  <td>Similarly to <code>egrad2rgrad</code>, converts the Euclidean gradient and Hessian of $f$ at $x$ along a tangent vector $u$ to the Riemannian Hessian of $f$ at $x$ along $u$ on the manifold. </td>
                </tr>
                <tr>
                  <td>Tangentialize</td>
                  <td><code>M.tangent(x, u)</code></td>
                  <td>Re-tangentializes a vector. The input is a vector in the tangent vector representation, which possibly (for example because of error accumulations) is not tangent anymore. The output will be the "closest" tangent vector to the input. If tangent vectors are represented in the ambient space, this is equivalent to <code>proj</code>.</td>
                </tr>
                <tr>
                  <td>Tangent to ambient representation</td>
                  <td><code>M.tangent2ambient(x, u)</code></td>
                  <td>Tangent vectors are sometimes described differently from their counterpart in the ambient space. This will return the ambient space representation of a tangent vector $u$. Useful when defining the Euclidean Hessian for example. </td>
                </tr>
                <tr>
                  <td>Exponential map </td>
                  <td><code>M.exp(x, u, t) </code></td>
                  <td>Computes $\operatorname{Exp}_x(tu)$, the point you reach by following the vector $tu$ starting at $x$. </td>
                </tr>
                <tr>
                  <td>Retraction </td>
                  <td><code>M.retr(x, u, t) </code></td>
                  <td>Computes $\operatorname{Retr}_x(tu)$, where $\operatorname{Retr}$ is a retraction: a cheaper proxy for the exponential map. </td>
                </tr>
                <tr>
                  <td>Logarithmic map </td>
                  <td><code>M.log(x, y) </code></td>
                  <td>Computes $\operatorname{Log}_x(y)$, a tangent vector at $x$ pointing toward $y$. </td>
                </tr>
                <tr>
                  <td>Random point </td>
                  <td><code>M.rand() </code></td>
                  <td>Computes a random point on the manifold. </td>
                </tr>
                <tr>
                  <td>Random vector </td>
                  <td><code>M.randvec(x) </code></td>
                  <td>Computes a random, unit-norm tangent vector in the tangent space at $x$. </td>
                </tr>
                <tr>
                  <td>Zero vector </td>
                  <td><code>M.zerovec(x) </code></td>
                  <td>Returns the zero tangent vector at $x$. </td>
                </tr>
                <tr>
                  <td>Linear combination </td>
                  <td><code>M.lincomb(x, a1, u1, a2, u2) </code></td>
                  <td>Computes the tangent vector at $x$: $v = a_1 u_1 + a_2 u_2$, where $a_1, a_2$ are scalars and $u_1, u_2$ are tangent vectors at $x$. The inputs $a_2, u_2$ are optional. </td>
                </tr>
                <tr>
                  <td>Vector transport </td>
                  <td><code>M.transp(x, y, u) </code></td>
                  <td>Computes a tangent vector at $y$ that "looks like" the tangent vector $u$ at $x$. </td>
                </tr>
                <tr>
                  <td>Pair mean </td>
                  <td><code>M.pairmean(x, y) </code></td>
                  <td>Computes the intrinsic mean of $x$ and $y$, that is, a point that lies mid-way between $x$ and $y$ on the geodesic arc joining them. </td>
                </tr>
                <tr>
                  <td>Hashing function </td>
                  <td><code>M.hash(x) </code></td>
                  <td>Computes a string that (almost) uniquely identifies the point $x$ and that can serve as a field name for a structure. </td>
                </tr>
                <tr>
                  <td>Vector representation</td>
                  <td><code>M.vec(x, u)</code></td>
                  <td>Returns a <em>real </em>column-vector representation of the tangent vector $u$. The length of the output is always the same and at least <code>M.dim()</code>. This function is linear and invertible on the tangent space at $x$.</td>
                </tr>
                <tr>
                  <td>Normal representation</td>
                  <td><code>M.mat(x, u_vec)</code></td>
                  <td>The inverse of the <code>vec</code> function: will return a tangent vector representation from a column vector such that <code>M.mat(x, M.vec(x, u)) = u</code>. </td>
                </tr>
                <tr>
                  <td>vec and mat isometry check</td>
                  <td><code>M.vecmatareisometries()</code></td>
                  <td>Returns true if <code>M.vec</code> is a linear isometry, i.e., if for all tangent vectors $u,v$, <code>M.inner(x, u, v) == M.vec(x, u).'*M.vec(x, v)</code>. Then, <code>M.mat</code> is both the adjoint and the inverse of <code>M.vec</code>.</td>
                </tr>
              </tbody>
            </table>
            <p>Not all manifold factories populate all of these fields, but that's okay: for many purposes, only a subset of these functions are necessary. Notice that it is also very easy to add or replace fields in a manifold structure returned by a factory, which can be desirable to experiment with various retractions, vector transports, etc. If you find ways to improve the built-in geometries, let us know.</p>
          </section>
          <section id="solvers">
            <div class="page-header">
              <h1>Solvers </h1>
            </div>
            <h3>General description <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"> </h3>
            <p>Solvers, or optimization algorithms, are functions in Manopt. Built-in solvers are located in <span
                style="font-family: monospace;">/manopt/solvers</span>. In principle, all solvers admit the basic call format <code>x = mysolver(problem)</code>. The returned value <code>x</code> will be a point on the manifold <code>problem.M</code>. Depending on the properties of your problem and on the guarantees of the solver, <code>x</code> will be more or less close to a good minimizer of the cost function described in the <code>problem</code> structure. Bear in mind that we are dealing with usually nonconvex, and possibly nonsmooth or derivative-free optimization, so that it is in general not guaranteed that <code>x</code> will be a global minimizer of the cost. For smooth problems with gradient information though, most decent algorithms guarantee that <code>x</code> will be a critical point (typically a local minimizer). </p>
            <div class="alert alert-info"><strong>Heads up!</strong> All provided solvers are <em>minimization</em> algorithms. If you want to <em>maximize </em>your objective function, multiply it by -1 (and accordingly for the derivatives of the objective function if needed), as we did in the <a
                href="#firstexample">first example</a>. </div>
            <p>In principle, all solvers also admit a more complete call format: <code>[x, xcost, info, options] = mysolver(problem, x0, options)</code>. The output <code>xcost</code> is the value of the cost function at the returned point <code>x</code>. The <code>info</code> struct-array is described below, and contains information collected at each iteration of the solver's progress. The <code>options</code> structure is returned too, so you can see what default values the solver used on top of the options you (possibly) specified. The input <code>x0</code> is an initial guess, or initial iterate, for the solver. It is typically a point on the manifold <code>problem.M</code>, but may be something else depending on the solver. It can be omitted by passing the empty matrix <code>[]</code> instead. The <code>options</code> structure is used to fine tune the behavior of the optimization algorithm. On top of hosting the algorithmic parameters, it manages the stopping criteria as well as what information needs to be displayed and / or logged during execution. </p>
            <h3>Available solvers </h3>
            <p>The toolbox is fairly young and comes with only a handful of solvers, the most trust-worthy being the trust-regions algorithm as it is a modification of the code of <a
                title="GenRTR, by Chris Baker, P.-A. Absil and Kyle Gallivan"
                href="http://www.math.fsu.edu/%7Ecbaker/genrtr/">GenRTR</a>. The toolbox was designed to accommodate many more solvers though, and we expect to propose BFGS-style solvers, stochastic gradient descents and many more in the future. In particular, we look forward to proposing algorithms for nonsmooth cost functions (which notably but not only arise when L1 penalties are at play).</p>
            <p><em>In the future, there will be a documentation page for each solver.</em> </p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Requires (benefits of) </td>
                  <td>Comment </td>
                  <td>Call</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="solver_documentation_trustregions.html">Trust-regions</a> </td>
                  <td>Cost, gradient (Hessian, approximate Hessian, preconditioner) </td>
                  <td>#1 choice for smooth optimization; uses <abbr title="Finite differences"
                      class="initialism">FD</abbr> of the gradient in the absence of Hessian. </td>
                  <td><code>trustregions(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/steepestdescent/steepestdescent.html">Steepest-descent</a> </td>
                  <td>Cost, gradient </td>
                  <td>Simple implementation of <abbr title="Gradient descent"
                      class="initialism">GD</abbr> ; the built-in line-search is backtracking based. </td>
                  <td><code>steepestdescent(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/conjugategradient/conjugategradient.html">Conjugate-gradient </a></td>
                  <td>Cost, gradient (preconditioner) </td>
                  <td>Often performs better than steepest-descent. </td>
                  <td><code>conjugategradient(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/pso/pso.html">Particle swarm (PSO) </a></td>
                  <td>Cost </td>
                  <td><abbr title="Derivative-free optimization" class="initialism">DFO</abbr> based on a population of points. </td>
                  <td><code>pso(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/neldermead/neldermead.html">Nelder-Mead</a> </td>
                  <td>Cost </td>
                  <td><abbr title="Derivative-free optimization" class="initialism">DFO</abbr> based on a simplex; requires <code>M.pairmean</code>; usage not advised. </td>
                  <td><code>neldermead(...)</code> </td>
                </tr>
              </tbody>
            </table>
            <h3>The options structure </h3>
            <p>In Manopt, <em>all</em> options are optional. Standard options are assigned a default value at the toolbox level in <a
                href="reference/manopt/privatetools/getGlobalDefaults.html"><tt>/manopt/privatetools/getGlobalDefaults.m</tt></a> (it's a private tool, so you really shouldn't use or edit it). Solvers then override and complement these options with solver-specific fields. These options are in turn overridden by the user-specified options, if any. Here is a list of commonly used options (see each solver's documentation for specific information):</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>options."..."</code>) </td>
                  <td>Value type </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Output and information logging</strong> </td>
                </tr>
                <tr>
                  <td><code>verbosity</code></td>
                  <td>integer </td>
                  <td>Controls how much information a solver outputs during execution ; 0: no output; 1 : output at init and at exit; 2: light output at each iteration; more: all you can read. </td>
                </tr>
                <tr>
                  <td><code>debug</code></td>
                  <td>integer </td>
                  <td>If larger than 0, the solver may perform additional computations for debugging purposes. </td>
                </tr>
                <tr>
                  <td><code>statsfun</code> </td>
                  <td>fun. handle </td>
                  <td>
                    <p>If you specify a function handle with prototype <code>stats = statsfun(problem, x, stats)</code>, it will be called after each iteration completes with the <code>problem</code> structure, the current point <code>x</code> and the statistics structure <code>stats</code> that will be logged in the <code>info</code> struct-array at the corresponding iteration number. This function gives you a chance to modify the <code>stats</code> structure, hence to add fields if you want to. Bear in mind that structures in a struct-array must <em>all </em>have the same fields, so that if the <code>statsfun</code> adds a field to a <code>stats</code> structure, it must do so for <em>all </em>iterations.</p>
                    <p>Example:</p>
                    <pre class="prettyprint lang-matlab linenums">options.statsfun = @mystatsfun;
function stats = mystatsfun(problem, x, stats)
    stats.x = x;
end</pre>
                    <p> This will log all the points visited during the optimization process in the info struct-array returned by the solver.</p>
                    <p>You may also provide a function handle with this calling pattern: <code>stats = statsfun(problem, x, stats, store)</code>. This additionally lets you access the data stored for that particular iterate in the store structure. </p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Stopping criteria</strong> </td>
                </tr>
                <tr>
                  <td><code>maxiter</code></td>
                  <td>integer </td>
                  <td>Limits the number of iterations of the solver. </td>
                </tr>
                <tr>
                  <td><code>maxtime</code></td>
                  <td>double </td>
                  <td>Limits the <abbr title="Not taking into account time spent in statsfun.">execution time</abbr> of the solver, in seconds. </td>
                </tr>
                <tr>
                  <td><code>maxcostevals</code></td>
                  <td>integer </td>
                  <td>Limits the number of evaluations of the cost function. </td>
                </tr>
                <tr>
                  <td><code>tolcost</code></td>
                  <td>double </td>
                  <td>Stop as soon as the cost drops below this tolerance. </td>
                </tr>
                <tr>
                  <td><code>tolgradnorm</code></td>
                  <td>double </td>
                  <td>Stop as soon as the norm of the gradient drops below this tolerance. </td>
                </tr>
                <tr>
                  <td><code>stopfun</code> </td>
                  <td>fun. handle </td>
                  <td>
                    <p>If you specify a function handle with prototype <code>stopnow = stopfun(problem, x, info, last)</code>, it will be called after each iteration completes with the <code>problem</code> structure, the current point <code>x</code> , the whole <code>info</code> struct-array built so far and an index <code>last</code> such that <code>info(last)</code> is the structure pertaining to the current iteration (this is because <code>info</code> is pre-allocated, so that <code>info(end)</code> typically does <em>not</em> refer to the current iteration). The return value is a boolean. If <code>stopnow</code> is returned as <tt>true</tt>, the solver will terminate.</p>
                    <p>Example:</p>
                    <pre class="prettyprint lang-matlab linenums">options.stopfun = @mystopfun;
function stopnow = mystopfun(problem, x, info, last)
    stopnow = (last &gt;= 3 &amp;&amp; info(last-2).cost - info(last).cost &lt; 1e-3);
end</pre>
                    <p> This will tell the solver to exit as soon as two successive iterations combined have decreased the cost by less than 10<sup>-3</sup>.</p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Line-search<a id="linesearchoptions">&#160;</a></strong> </td>
                </tr>
                <tr>
                  <td><code>linesearch</code></td>
                  <td>fun. handle</td>
                  <td>Some solvers, such as <code>steepestdescent</code> and <code>conjugategradient</code>, need to solve a line-search problem at each iteration. That is, they need to (approximately) solve the one-dimensional optimization problem:<br>
                    $$\min_{t\geq 0} \phi(t) = f(\operatorname{Retr}_x(td)),$$<br>
                    where $x$ is the current point on the manifold, $d$ is a tangent vector at $x$ (the search direction), $\operatorname{Retr}$ is the retraction on the manifold and $f$ is the cost function. Assuming $d$ is a descent direction, there exists $t &gt; 0$ such that $\phi(t) &lt; \phi(0) = f(x)$. A line-search algorithm is conceived to find such a real number $t$.<br>
                    Manopt includes certain <a href="reference/manopt/solvers/linesearch/index.html">generic purpose line-search algorithms</a>. To force the use of one of them or of your own, specify this in the options structure (not in the problem structure) as follows: <code>options.linesearch = @linesearch_adaptive;</code> (for example). Each line-search algorithm will accept its own options which can be added in this same <code>options</code> structure. See each line-search's help for details.<br>
                    For certain problems, you may want to implement your own line-search, typically in order to exploit structure specific to your problem at hand. To this end, it is best to start from an existing line-search function and to adapt it. Alternatively (and perhaps more easily), you may specify a <code>linesearch</code> function in the <code>problem</code> structure (see the <a
                      href="#linesearchproblem">cost description section</a>) and use a line-search that will use it, to incorporate the additional information you supply there. Do not hesitate to ask for help on the forum if you run into trouble here :).</td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Miscellaneous</strong> </td>
                </tr>
                <tr>
                  <td><code>storedepth</code></td>
                  <td>integer </td>
                  <td>Maximum number of <code>store</code> structures that may be kept in memory (see the <a
                      href="#costdescription">cost description</a> section). </td>
                </tr>
              </tbody>
            </table>
            <p>Keep in mind that a specific solver may not use all of these options and may use additional options, which would then be described on the solver's documentation page. </p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need a problem-specific stopping criterion? Include a <code>stopfun</code> in your <code>options</code> structure. </div>
            <h3>The info struct-array </h3>
            <p>The various solvers will log information at each iteration about their progress. This information is returned in the output <code>info</code>, a struct-array, a.k.a., an array of structures. Read this <a
                href="http://blogs.mathworks.com/loren/2007/04/19/vectorizing-access-to-an-array-of-structures/">MathWorks blog post</a> for help on dealing with this data container in Matlab. Here are the typical indicators that might be present in the <code>info</code> output:</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>[info."..."]</code>) </td>
                  <td>Value type </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><code>iter</code></td>
                  <td>integer </td>
                  <td>Iteration number (0 corresponds to the initial guess). </td>
                </tr>
                <tr>
                  <td><code>time</code> </td>
                  <td>double </td>
                  <td>Elapsed <abbr title="Not taking into account time spent in statsfun.">execution time</abbr> until completion of the iterate, in seconds. </td>
                </tr>
                <tr>
                  <td><code>cost</code> </td>
                  <td>double </td>
                  <td>Attained value of the cost function. </td>
                </tr>
                <tr>
                  <td><code>gradnorm</code> </td>
                  <td>double </td>
                  <td>Attained value for the norm of the gradient. </td>
                </tr>
              </tbody>
            </table>
            <p>A specific solver may not populate all of these fields and may provide additional fields, which would then be described on the solver's documentation page. </p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need to log problem-specific information at each iteration? Include a <code>statsfun</code> in your <code>options</code> structure.</div>
            <div class="alert alert-info"><strong>Heads up!</strong> The execution time is logged <em>without</em> incorporating time spent in <code>statsfun</code>, as it usually performs computations that are not needed to solve the optimization problem. If, however, you use information logged by <code>statsfun</code> for your <code>stopfun</code> criterion, and if this is important for your method (i.e., it is not just for convenience during prototyping), you should time the execution time of <code>statsfun</code> and add it to the <code>stats.time</code> field. </div>
          </section>
          <section id="costdescription">
            <div class="page-header">
              <h1>Describing the cost function</h1>
            </div>
            <h3>General philosophy <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"></h3>
            <h3> </h3>
            <p>An optimization problem in Manopt is represented as a <code>problem</code> structure. The latter must include a field <code>problem.M</code> which contains a structure describing a manifold, as obtained from <a
                href="#manifolds">a factory</a>. On top of this, the problem structure must include some fields that describe the cost function $f$ and, possibly, its derivatives. </p>
            <p>The solvers will <em>not </em>query these function handles directly. Instead, they call private tools such as <code>getCost</code>, <code>getGradient</code>, <code>getHessian</code>, etc. (These are private tools, so you really shouldn't use or edit them, unless you are writing your own solver or factory.) These tools will consider the available fields in the problem structure and "do their best" to return the required object. </p>
            <p>As a result, we gain great flexibility in the cost function description. Indeed, as the needs grow during the life-cycle of the toolbox and new ways of describing the cost function become necessary, it suffices to update the private <code>get*</code> tools to take these new ways into account. We never have to modify the solvers.</p>
            <p>For now, there are only a few ways to describe the cost and its derivatives, but there will be more as the needs grow. </p>
            <h3>Cost describing fields </h3>
            <p> You may specify as many of the following fields as you wish in the <code>problem</code> structure. If you specify some function more than once (for example, if you define <code>diff</code> <em>and</em> <code>grad</code>, which both could be used to compute directional derivatives), the toolbox does not specify which will be called. In the example, it will assume that the code for <code>diff</code> is more efficient than the code for <code>grad</code> when only a directional derivative is needed, but there is no guarantee. Bottom line: they should be consistent.</p>
            <div class="alert alert-info"><strong>Good to know!</strong> All function handles admit a store structure as extra argument for caching purposes, as explained in the next section. This is an optional feature. For prototyping, it is often easier to write a first version of the code without caching. </div>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>problem."..."</code>)</td>
                  <td>Prototype </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><code>cost</code> </td>
                  <td><code>f = cost(x)</code><br>
                    <nobr><code>[f store] = cost(x, store)</code></nobr></td>
                  <td>$f = f(x)$ </td>
                </tr>
                <tr>
                  <td><code>grad</code> </td>
                  <td><code>g = grad(x)</code><br>
                    <nobr><code>[g store] = grad(x, store)</code></nobr></td>
                  <td>$g = \operatorname{grad} f(x)$ </td>
                </tr>
                <tr>
                  <td><code>costgrad</code> </td>
                  <td><code>[f g] = costgrad(x)</code><br>
                    <nobr><code>[f g store] = costgrad(x, store)</code></nobr> </td>
                  <td>Computes both $f = f(x)$ and $g = \operatorname{grad} f(x)$.</td>
                </tr>
                <tr>
                  <td><code>egrad</code> </td>
                  <td><code>eg = egrad(x)</code><br>
                    <nobr><code>[eg store] = egrad(x, store)</code></nobr> </td>
                  <td>For submanifolds of a Euclidean space or quotient spaces with a Euclidean total space, computes $eg = \nabla f(x)$, the gradient of $f$ "as if" it were defined in that Euclidean space. This will be passed to <code>M.egrad2rgrad</code>.</td>
                </tr>
                <tr>
                  <td><code>hess</code> </td>
                  <td><code>h = hess(x, u)</code><br>
                    <nobr><code>[h store] = hess(x, u, store)</code></nobr></td>
                  <td>$h = \operatorname{Hess} f(x)[u]$ </td>
                </tr>
                <tr>
                  <td><code>ehess</code> </td>
                  <td><code>eh = ehess(x, u)</code><br>
                    <nobr><code>[eh store] = ehess(x, u, store)</code></nobr></td>
                  <td>For submanifolds of a Euclidean space or quotient spaces with a Euclidean total space, computes $eh = \nabla^2 f(x)[u]$, the Hessian of $f$ along $u$ "as if" it were defined in that Euclidean space. This will be passed to <code>M.ehess2rhess</code> and thus requires the Euclidean gradient to be accessible (<code>egrad</code>).</td>
                </tr>
                <tr>
                  <td><code>diff</code> </td>
                  <td><code>d = diff(x, u)</code><br>
                    <nobr><code>[d store] = diff(x, u, store)</code></nobr></td>
                  <td>$d = \operatorname{D}\! f(x)[u]$ </td>
                </tr>
                <tr>
                  <td><code>approxhess</code> </td>
                  <td><code>h = approxhess(x, u)</code><br>
                    <nobr><code>[h store] = approxhess(x, u, store)</code></nobr> </td>
                  <td>This can be any mapping from the tangent space at $x$ to itself. Often, one would like it to be a linear, symmetric operator. Solvers asking for the Hessian when one is not provided will automatically fall back on this approximate Hessian. If it is not provided either, a standard finite-difference approximation of the Hessian based on the gradient is built-in. </td>
                </tr>
                <tr>
                  <td><code>precon</code> </td>
                  <td><code>v = precon(x, u)</code><br>
                    <nobr><code>[v store] = precon(x, u, store)</code></nobr> </td>
                  <td>$v = \operatorname{Prec}(x)[u]$, where $\operatorname{Prec}(x)$ is a preconditioner for the Hessian $\operatorname{Hess} f(x)$, that is, $\operatorname{Prec}(x)$ is a symmetric, positive-definite linear operator (w.r.t. the Riemannian metric) on the tangent space at $x$. Ideally, it is cheap to compute and such that solving a linear system in $\operatorname{Prec}^{1/2}(x) \circ \operatorname{Hess} f(x) \circ \operatorname{Prec}^{1/2}(x)$ is easier than without the preconditioner, i.e., it should approximate the inverse of the Hessian. </td>
                </tr>
                <tr>
                  <td><code>linesearch</code><a id="linesearchproblem"> </a></td>
                <td><code>t = linesearch(x, u)</code><br>
                  <code>[t, store] = linesearch(x, u, store)</code></td>
                <td>Given a point $x$ and a tangent vector $u$ at $x$, assume $u$ is a descent direction. This means that there exists $t &gt; 0$ such that $\phi(t) &lt; \phi(0)$ with<br>
                  $$\phi(t) = f(\operatorname{Retr}_x(td)).$$<br>
                  Line-search algorithms, which are used by some solvers such as <code>steepestdescent</code> and <code>conjugategradient</code>, are designed to (approximately) minimize this function at each iteration. There are built-in, generic ways of doing this. But if you have additional structure in your problem that enables you to take a good guess at what $t$ should be, than you can specify it here, in this function handle. This (very much optional) function should return a positive $t &gt; 0$ such that $t$ is a good guess of where to look for a minimizer of $\phi$. The line-search algorithm (if it decides to use this information) will start by looking at the step $td$, and decide to accept it or not based on its internal rules. See the <code>linesearch</code> <a
                    href="#linesearchoptions">option in the solver section</a> (options table) for details on available line-search algorithms and how to pick one.<br>
                  <br>
                  See <a href="reference/examples/low_rank_matrix_completion.html">low_rank_matrix_completion.m</a> for an example from the literature.</td>
              </tr>
            </tbody>
          </table>
          <p> Here is one way to address the redundant computation of $Ax$ that appeared in the <a
              href="file:///C:/Users/nicolas/manopt/web/tutorial.html#firstexample">first example</a>. Replace the cost and gradient description (code lines 11-12) with the following code (we chose to spell out the gradient projection, but that is not necessary):</p>
          <pre class="prettyprint lang-matlab linenums">problem.costgrad = @(x) mycostgrad(A, x);
function [f g] = mycostgrad(A, x)
    Ax = A*x;
    f = -x'*Ax;
    if nargout == 2
        g = -2*(Ax + f*x);
    end
end
</pre>
          <p>Solvers that call subsequently for the cost and the gradient at the same point will be able to escape most redundant computations (e.g., <code>steepestdescent</code> and <code>conjugategradient</code> are good at this). This is not perfect though: when the Hessian is requested for example, we can't access our hard work (<code>trustregions</code> would not gain much for example). In the next section, we cover a more sophisticated way of sharing data between components of the cost description. </p>
          <h3>Caching: how to use the store structure </h3>
          <p>As demonstrated in the <a href="#firstexample">first example</a>, it is often the case that computing $f(x)$ produces intermediate results (such as the product $Ax$) that can be reused in order to compute $\operatorname{grad} f(x)$. More generally, computing anything at a point $x$ may produce intermediate results that could be reused for other computations at $x$. Furthermore, it may happen that a solver will call your cost-related functions more than once at the same point $x$. For those cases, it may be beneficial to cache (to store) some of the previously computed objects.</p>
          <p>For that purpose, Manopt manages a database of <code>store</code> structures. For each visited point $x$, a <code>store</code> structure is stored in the database. Only the structures pertaining to the most recently used points are kept in memory (see the <code>options.storedepth</code> <a
              href="#solvers">option</a>). The database is indexed thanks to a hash of the point $x$, as provided by the <a
              href="#manifolds">manifold structure</a> in <code>M.hash</code>, so that a look-up in the database is quick to do.</p>
          <p>Whenever a solver calls, say, the <code>cost</code> function at some point $x$, the toolbox will search for a <code>store</code> structure pertaining to that $x$ in the database. If there is one and if the <code>cost</code> function admits <code>store</code> as an input and as an output, the <code>store</code> is passed to the <code>cost</code> function. The <code>cost</code> function then performs its duty and gets to modify the <code>store</code> structure at will: it is <em>your </em>structure, do whatever you fancy with it. Next time a function is called at the <em>same</em> point $x$ (say, the <code>grad</code> function), the <em>same</em> <code>store</code> structure will be passed along, modified, and stored again. As soon as the solver goes on to explore a new point $x'$, a <em>different</em> <code>store</code> structure is created and maintained in the same way. If the solver then decides to return to the previous $x$ and <code>options.storedepth</code> is larger than 2, we will still benefit from the previously stored work as the previous <code>store</code> structure will still be available. </p>
          <p>Here is an example of how we can modify the <a href="#firstexample">first example</a> to avoid redundant computations, using the caching mechanism:</p>
          <pre class="prettyprint lang-matlab linenums">problem.cost = @mycost;
function [f, store] = mycost(x, store)

    if ~isfield(store, 'Ax')
        store.Ax = A*x;
    end
    Ax = store.Ax;
    
    if ~isfield(store, 'f')
        store.f = -x'*Ax;
    end
    f = store.f;
    
end

problem.grad = @mygrad;
function [g, store] = mygrad(x, store)

    if ~isfield(store, 'Ax')
        [~, store] = mycost(x, store);
    end
    Ax = store.Ax;
    
    if ~isfield(store, 'g')
        store.g = manifold.egrad2rgrad(x, -2*Ax);
    end
    g = store.g;
    
end
</pre>
          <p>It is instructive to execute such code with <a href="http://blogs.mathworks.com/community/2010/02/01/speeding-up-your-program-through-profiling/">the profiler</a> activated and to look at how many times each instruction gets executed. You should find that line 5 in the code, which is where all the work happens, is executed exactly as often as it should be, and not more.</p>
          <div class="alert alert-info"><strong>Heads up!</strong> You should never assume that the gradient function, for example, will be called <em>after</em> the cost function (even though this is usually the case). Always check that the fields you will use in the <code>store</code> structure are populated; and if they are not, call the appropriate functions to make up for it, as in the example above. </div>
          <div class="alert alert-info"><strong>Good to know!</strong> Which variables should I store? As a rule of thumb, store the intermediate computation results which constitute the bottleneck in your computation. This can usually be determined by considering the asymptotic time complexity of each operation. Typically, matrix products of large size are involved in the slowest parts. If in doubt, the Matlab profiler is a tremendous tool to identify the bits of your code that need special attention. </div>
        </section>
        <section id="tools">
          <div class="page-header">
            <h1>Helpful tools</h1>
          </div>
          <p>A number of generically useful tools in the context of using Manopt are available in /<tt>manopt/tools</tt>. The <code>multitransp</code> / <code>multiprod</code> pair is code by <a
              href="http://www.mathworks.com/matlabcentral/fileexchange/8773-multiple-matrix-multiplications-with-array-expansion-enabled">Paolo de Leva</a> ; <code>multitrace</code> is a wrapper around <code>diagsum</code>, which is code by <a
              href="http://www.mathworks.com/matlabcentral/fileexchange/10062-multi-dimensional-matrix-product-outer-product-and-partial-trace">Wynton Moore</a>. </p>
          <table style="width: 100%;" class="table table-striped table-bordered">
            <thead>
              <tr>
                <td></td>
              <td>Call </td>
              <td>Description </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td></td>
            <td colspan="2" rowspan="1"><strong>Diagnostics tools</strong> </td>
          </tr>
          <tr>
            <td><a href="reference/manopt/tools/checkdiff.html"><i class="icon-book"></i></a></td>
          <td><nobr><code>checkdiff(problem, x, u)</code></nobr> </td>
          <td>Numerical check of the directional derivatives of the cost function. From a truncated Taylor expansion, we know that the following holds: $$f(\operatorname{Exp}_x(tu)) - \left[f(x) + t\cdot\operatorname{D}\!f(x)[u]\right] = \mathcal{O}(t^2).$$ Hence, in a log-log plot with $\log(t)$ on the abscissa, the error should behave as $\log(t^2) = 2\log(t)$, i.e., we should observe a slope of 2. This tool produces such a plot and tries to compute the slope of it (<em>tries</em> to, because numerical errors prevent the curve to have a slope of 2 everywhere even if directional derivatives are correct; so you should really just inspect the plot visually). If <code>x</code> and <code>u</code> are omitted, they are picked at random. </td>
        </tr>
        <tr>
          <td><a href="reference/manopt/tools/checkgradient.html"><i class="icon-book"></i></a></td>
        <td><nobr><code>checkgradient(problem, x, u)</code></nobr> </td>
        <td>Numerical check of the gradient of the cost function. Based on the statement that if the gradient exists, than it is the only tangent vector field that satisfies $$\langle \operatorname{grad} f(x), u\rangle_x = \operatorname{D}\!f(x)[u],$$ this tool calls <code>checkdiff</code> and it verifies that the gradient is indeed a tangent vector, by computing the norm of the difference between the gradient and its projection to the tangent space (if a projector is available). Of course, this should be zero. </td>
      </tr>
      <tr>
        <td><a href="reference/manopt/tools/checkhessian.html"><i class="icon-book"></i></a></td>
      <td><nobr><code>checkhessian(problem, x, u)</code></nobr> </td>
      <td>
        <p>Numerical check of the Hessian of the cost function. From a truncated Taylor expansion, we know that the following holds: $$f(\operatorname{Exp}_x(tu)) - \left[f(x) + t\cdot\operatorname{D}\!f(x)[u] + \frac{t^2}{2} \cdot \langle \operatorname{Hess} f(x)[u], u \rangle_x\right] = \mathcal{O}(t^3).$$ Hence, in a log-log plot with $\log(t)$ on the abscissa, the error should behave as $\log(t^3) = 3\log(t)$, i.e., we should observe a slope of 3. This tool produces such a plot and tries to compute the slope of it (<em>tries</em> to, because numerical errors prevent the curve to have a slope of 3 everywhere even if the derivatives are correct; so you should really just inspect the plot visually). If <code>x</code> and <code>u</code> are omitted, they are picked at random. The tool also verifies that the Hessian indeed returns a tangent vector, by computing the norm of the difference between $\operatorname{Hess} f(x)[u]$ and its projection to the tangent space (if a projector is available). Of course, this should be zero.</p>
        <p>The Hessian is a linear, symmetric operator from the tangent space at $x$ to itself. To verify symmetry, this tool generates two random tangent vectors $u_1$ and $u_2$ and computes the difference $$\langle \operatorname{Hess} f(x)[u_1], u_2 \rangle_x - \langle u_1,&#160; \operatorname{Hess} f(x)[u_2]\rangle_x,$$ which should be zero.</p>
      </td>
    </tr>
    <tr>
      <td><a href="reference/manopt/tools/plotprofile.html"><i class="icon-book"></i></a></td>
    <td><code>plotprofile(problem, x, d, t)</code></td>
    <td>Plots the cost function along a geodesic or a retraction path starting at $x$, along direction $d$. See <span
        style="font-family: monospace;">help plotprofile</span> for more information.</td>
  </tr>
  <tr>
    <td><a href="reference/manopt/tools/hessianspectrum.html"><i class="icon-book"></i></a></td>
  <td><code>hessianspectrum(problem, x, sqrtprec)</code></td>
  <td>
    <p>Computes the eigenvalues of the Hessian $H$ at $x$. If a preconditioner $P$ is specified in the problem structure, the eigenvalues of the preconditioned Hessian $HP$ are computed.</p>
    <p>This function relies on <code>M.vec</code> and <code>M.mat</code> to pass the computation to the built-in <code>eigs</code> function. For the eigenvalue problem to remain symmetric in the column-vector representation domain, we need <code>M.vec</code> and <code>M.mat</code> to be orthonormal, i.e., isometries (see <code>matvecareisometries</code> in the <a
        href="#manifolds">manifod section</a>). If they are not isometries, computations may take longer. Indeed, let $G$ denote the <code>M.vec</code> operator and $G^{-1}$ represents the <code>M.mat</code> operator (on the appropriate domain). Then, <code>eigs</code> will compute the spectrum of $GHG^{-1}$ or $GHPG^{-1}$, which are identical to, respectively, the spectra of $H$ and $HP$. This is only symmetric if there is no preconditioner and $G^T = G^{-1}$.</p>
    <p>If a preconditioner is used, the symmetry of the eigenvalue problem is lost. If <code>M.vec</code> and <code>M.mat</code> are isometries and the dimension of the manifold is large, it may be useful to restore symmetry by giving this tool a function handle for the square root of the preconditioner, $P^{1/2}$ (optional). Then, <code>eigs</code> is given the problem of computing the spectrum of $GP^{1/2}HP^{1/2}G^T$ (symmetric), which is equal to the spectrum of $HP$. If <code>sqrtprec</code> is provided, the preconditioner given in the problem structure is ignored.</p>
  </td>
</tr>
<tr>
  <td></td>
<td colspan="2" rowspan="1"><strong>Matrix utilities</strong> </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/multiscale.html"><i class="icon-book"></i></a></td>
<td><nobr><code>B = multiscale(scale, A)</code></nobr> </td>
<td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt> and a vector <code>scale</code> of length <tt>N</tt>, returns <code>B</code>, a 3D matrix of the same size as <code>A</code> such that <nobr><code>B(:, :, k) = scale(k) * A(:, :, k)</code></nobr> for each <code>k</code>. </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/multitrace.html"><i class="icon-book"></i></a></td>
<td><nobr><code>tr = multitrace(A)</code></nobr> </td>
<td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>, returns a column vector <code>tr</code> of length <tt>N</tt> such that <nobr><code>tr(k) = trace(A(:, :, k))</code></nobr> for each <code>k</code>. </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/multitransp.html"><i class="icon-book"></i></a></td>
<td><nobr><code>B = multitransp(A)</code></nobr> </td>
<td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt>, returns <code>B</code>, a 3D matrix of size <tt>mxnxN</tt> such that <nobr><code>B(:, :, k) = A(:, :, k).'</code></nobr> for each <code>k</code>. </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/multiprod.html"><i class="icon-book"></i></a></td>
<td><nobr><code>C = multiprod(A, B)</code></nobr> </td>
<td>For 3D matrices <code>A</code> of size <tt>nxpxN</tt> and B of size <tt>pxmxN</tt>, returns <code>C</code>, a 3D matrix of size <tt>nxmxN</tt> such that <nobr><code>C(:, :, k) = A(:, :, k) * B(:, :, k)</code></nobr> for each <code>k</code>. </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/multiskew.html"><i class="icon-book"></i></a></td>
<td><code>B = multiskew(A)</code></td>
<td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>, returns a 3D matrix <code>B</code> the same size as <code>A</code> such that each slice <code>B(:, :, i)</code> is the skew-symmetric part of the slice <code>A(:, :, i)</code>, that is, <code>(A(:, :, i)-A(:, :, i)')/2</code>.</td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/multisym.html"><i class="icon-book"></i></a></td>
<td><code>B = multisym(A)</code></td>
<td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>, returns a 3D matrix <code>B</code> the same size as <code>A</code> such that each slice <code>B(:, :, i)</code> is the symmetric part of the slice <code>A(:, :, i)</code>, that is, <code>(A(:, :, i)+A(:, :, i)')/2</code>.</td>
</tr>
<tr>
  <td></td>
<td colspan="2" rowspan="1"><strong>Manifold utilities</strong> </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/powermanifold.html"><i class="icon-book"></i></a></td>
<td><nobr><code>Mn = powermanifold(M, n)</code></nobr> </td>
<td>Given <code>M</code>, a structure representing a manifold $\mathcal{M}$, and <code>n</code>, an integer, returns <code>Mn</code>, a structure representing the manifold $\mathcal{M}^n$. The geometry is obtained by element-wise extension. Points and vectors on <code>Mn</code> are represented as cells of length <code>n</code>. </td>
</tr>
<tr>
  <td><a href="reference/manopt/tools/productmanifold.html"><i class="icon-book"></i></a></td>
<td><nobr><code>M = productmanifold(elements)</code></nobr> </td>
<td>Given <code>elements</code>, a structure with fields <code>A, B, C...</code> containing structures <code>Ma, Mb, Mc...</code> such that <code>Ma</code> is a structure representing a manifold $\mathcal{M}_A$ etc., returns <code>M</code>, a structure representing the manifold $\mathcal{M}_A \times \mathcal{M}_B \times \mathcal{M}_C \times \cdots$. The geometry is obtained by element-wise extension. Points and vectors are represented as structures with the same field names as <code>elements</code>. </td>
</tr>
</tbody>
</table>
<div class="alert alert-info"><strong>Heads up!</strong> When using the <code>checkhessian</code> tool, it is important to obtain <em>both</em> a slope of 3 <em>and</em> to pass the symmetry test. Indeed, the slope test ignores the skew-symmetric part of the Hessian, since $x^T A x = x^T \frac{A+A^T}{2} x$. As a result, if your code for the Hessian has a spurious skew-symmetric part, the slope test will be oblivious to it. </div>
</section>
<section id="reference">
  <div class="page-header">
    <h1>Reference</h1>
  </div>
  <p><a target="_blank" href="reference/index.html">A reference is available here</a>, to help navigate the source code of the toolbox. It was generated with <a
      href="http://www.artefact.tk/software/matlab/m2html/">m2html</a>. </p>
</section>
</div>
</div>
</div>
<!-- /container --><!-- Le javascript ================================================== --><!-- Placed at the end of the document so the pages load faster -->
<script type="text/javascript" src="bootstrap/js/jquery.min.js"></script>
<script type="text/javascript" src="bootstrap/js/bootstrap.js"></script>
<script type="text/javascript" src="bootstrap/js/prettify.js"></script>
<script type="text/javascript" src="bootstrap/js/lang-matlab.js"></script>
<!--
    <script type="text/javascript" src="http://mathcache.s3.amazonaws.com/replacemath.js"> </script>    <script type="text/javascript">replaceMath( document.body ); </script>    -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script> <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-37402854-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</body>
</html>
