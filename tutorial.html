<!DOCTYPE html>
<html lang="en">
  <head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <title>Manopt, tutorial</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Nicolas Boumal">
    <link href="favicon.ico" rel="icon" type="image/x-icon">
    <!-- Le styles -->
    <link href="bootstrap/css/bootstrap.css" rel="stylesheet">
    <style type="text/css">
body {
        padding-top: 80px;
        padding-bottom: 40px;
}
      thead {
        font-weight: bold;
      }
    </style>
    <link href="bootstrap/css/bootstrap-responsive.css" rel="stylesheet">
    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>    <![endif]-->
    <link href="bootstrap/css/prettify.css" type="text/css" rel="stylesheet">
    <link href="bootstrap/css/lang-matlab.css" type="text/css" rel="stylesheet">
  </head>
  <body onload="prettyPrint()" data-spy="scroll" data-target=".sidebar">
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner"> <a class="btn btn-navbar" data-toggle="collapse"
          data-target=".nav-collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span>
          <span class="icon-bar"></span> </a>
        <div class="container"> <a class="brand" href="index.html">Manopt</a>
          <div class="nav-collapse collapse">
            <ul class="nav">
              <li><a href="index.html"> Home</a></li>
              <li class="active"><a href="tutorial.html"> Tutorial</a></li>
              <li><a href="downloads.html"> Downloads</a></li>
              <li><a href="forum.html"> Forum</a></li>
              <li><a href="about.html"> About</a></li>
              <li><a href="#contactmodal" data-toggle="modal"> Contact</a></li>
            </ul>
          </div>
          <!--/.nav-collapse --> </div>
      </div>
    </div>
    <!-- Contact modal Begin -->
    <div id="contactmodal" class="modal hide fade" tabindex="-1" role="dialog" aria-labelledby="myModalLabel"
      aria-hidden="true">
      <div class="modal-header"> <button type="button" class="close" data-dismiss="modal"
          aria-hidden="true">&#215;</button>
        <h3 id="myModalLabel">To contact us</h3>
      </div>
      <div class="modal-body">
        <p>To discuss code, it is best to use the <a href="forum.html">forum</a>.</p>
        <p>For things not suitable for the forum, e-mail us at <a href="mailto:manopttoolbox@gmail.com">manopttoolbox@gmail.com</a>.</p>
        <p>We are happy to receive feedback and bug reports or requests for more
          features, to discuss the toolbox in general as well as its
          documentation and to help you use it.</p>
        <p>We would also love to know how you use the toolbox, and if you built
          nice manifold factories, solvers or tools that could benefit others.</p>
      </div>
      <div class="modal-footer"> <button class="btn" data-dismiss="modal" aria-hidden="true">Close</button>
      </div>
    </div>
    <!-- Contact modal End -->
    <div class="container">
      <div class="row">
        <div class="span3 sidebar" style="min-height: 1px">
          <!--Sidebar content-->
          <!-- class="nav nav-tabs nav-stacked mysidebar" -->
          <ul class="nav nav-list mysidebar" data-spy="affix">
            <li class="nav-header">Tutorial</li>
            <li><a href="#gettingstarted">Getting started</a></li>
            <li><a href="#firstexample">A first example</a></li>
            <li><a href="#manifolds">Manifolds</a></li>
            <li><a href="#solvers">Solvers</a></li>
            <li><a href="#costdescription">Describing the cost</a></li>
            <li><a href="#tools">Helpful tools</a></li>
            <li><a href="#core">Core tools</a></li>
            <li><a href="#reference">Reference</a></li>
          </ul>
        </div>
        <div class="span9">
          <!--Body content-->
          <section id="gettingstarted">
            <div class="page-header">
              <h1>Getting started with Manopt </h1>
            </div>
            <h3>Foreword</h3>
            <p><strong>With Manopt, you can solve optimization problems on
                manifolds</strong> using state-of-the-art algorithms, with
              minimal effort. The toolbox targets great flexibility in the
              problem description and comes with advanced features, such as
              caching.</p>
            <p>The toolbox architecture is based on a <strong>separation of the
                manifolds, the solvers and the problem descriptions</strong>.
              For basic use, one only needs to pick a manifold from the library,
              describe the cost function (and possible derivatives) on this
              manifold and pass it on to a solver. Accompanying tools help the
              user in common tasks such as numerically checking whether the cost
              function agrees with its derivatives up to the appropriate order
              etc.</p>
            <p><strong>This is a </strong><strong>prototyping toolbox</strong>,
              designed based on the idea that the costly part of solving an
              optimization problem is querying the cost function, and not the
              inner machinery of the solver. It is also work in progress: <strong>
                feedback and contributions are welcome</strong>!</p>
            <p><a href="reference/examples/index.html">Examples are available in
                the reference</a>. </p>
            <p>This short blog post gives an <a target="_blank" href="https://afonsobandeira.wordpress.com/2015/03/16/optimizing-in-smooth-waters-optimization-on-manifolds/">informal
                overview of optimization on manifolds</a>. It may be a good
              start to get a general feeling.</p>
            <p>It helps us to know our users. If you'd like to, please <a target="_blank"
                href="https://docs.google.com/forms/d/1U9Ntex_rWI8NfCLPP_b8uE5xDnKXgXG-HVvpHdq1PFo/viewform?usp=send_form">follow
                this link to be on our user list</a>. Thanks!</p>
            <h3>Download </h3>
            <p><a target="_blank" class="btn btn-primary" href="download.html">Download
                </a>&#160;&#160; The current version is 2.0 and was packaged on
              July 6th, 2015. The file is about 300 Kb.</p>
            <h3>Install</h3>
            <blockquote>
              <ol>
                <li>Unzip and copy the whole <tt>manopt</tt> directory you just
                  downloaded in a location of your choice on disk, say, in <tt>/my/directory/</tt>.</li>
                <li>Go to <tt>/my/directory/manopt/</tt> at the command prompt
                  and execute <code>importmanopt</code>. You may save this path
                  for your next Matlab sessions: follow the menu <tt>File
                    &#187; Set Path...</tt> and <span style="font-family: monospace;">save</span>.
                </li>
              </ol>
            </blockquote>
            <h3>Check</h3>
            <p> Go to <tt>/my/directory/manopt/checkinstall/</tt> and run the
              script <tt>basicexample.m</tt>. If there are no errors, you are
              done! Otherwise, feel free to <a href="#contactmodal">contact us</a>.
            </p>
          </section>
          <section id="firstexample">
            <div class="page-header">
              <h1>A first example</h1>
            </div>
            <h3>The math</h3>
            <p>In this first example, we will compute a dominant eigenvector of
              a symmetric matrix $A \in \mathbb{R}^{n\times n}$. Let $\lambda_1
              \geq \cdots \geq \lambda_n$ be its eigenvalues. The largest
              eigenvalue, $\lambda_1$, <a target="_blank" href="http://en.wikipedia.org/wiki/Rayleigh_quotient"
                rel="tooltip" title="Search for 'Rayleigh quotient' if need be.">is
                known to be</a> the optimal value for the following optimization
              problem:</p>
            <p>$$\max\limits_{x\in\mathbb{R}^n, x \neq 0} \frac{x^T A x}{x^T
              x}.$$</p>
            <p>This can be rewritten as follows:</p>
            <p>$$\min\limits_{x\in\mathbb{R}^n, \|x\| = 1} -x^T A x.$$</p>
            <p>The cost function and its gradient in $\mathbb{R}^n$ read:</p>
            <p>$$<br>
              \begin{align}<br>
              &#160;&#160;&#160; f(x) &amp; = -x^T A x,\\<br>
              &#160;&#160;&#160; \nabla f(x) &amp; = -2Ax.<br>
              \end{align}<br>
              $$</p>
            <p>The constraint on the vector $x$ requires that $x$ be of unit
              2-norm, that is, $x$ is a point on the sphere (one of the nicest
              manifolds):</p>
            <p>$$\mathbb{S}^{n-1} = \{x \in \mathbb{R}^n : x^Tx = 1\}.$$</p>
            <p>This is all the information we need to apply Manopt to our
              problem.</p>
            <p>Users interested in how optimization on manifolds works will be
              interested in the following too: the cost function is smooth on
              $\mathbb{S}^{n-1}$. Its Riemannian gradient on $\mathbb{S}^{n-1}$
              at $x$ is a tangent vector to the sphere at $x$. It can be
              computed as the projection from the usual gradient $\nabla f(x)$
              to that tangent space using the orthogonal projector
              $\mathrm{Proj}_x u = (I-xx^T)u$:</p>
            <p>$$\mathrm{grad}\,f(x) = \mathrm{Proj}_x \nabla f(x) =
              -2(I-xx^T)Ax.$$</p>
            <p>This is an example of a mathematical relationship between the
              Euclidean gradient $\nabla f$, which we often already know how to
              compute from calculus courses, and the Riemannian gradient
              $\mathrm{grad}\,f$, which is needed for the optimization.
              Fortunately, for most manifolds in Manopt the conversion happens
              behind the scenes via a function called <code>egrad2rgrad</code>
              and we only need to compute $\nabla f$.</p>
            <p>We will solve this simple optimization problem using Manopt to
              illustrate the most basic usage of the toolbox. For additional
              theory, see [AMS08], section 4.6.</p>
            <p>[AMS08] P.-A. Absil, R. Mahony and R. Sepulchre, <a target="_blank"
                href="http://press.princeton.edu/chapters/absil/">Optimization
                Algorithms on Matrix Manifolds</a> (open access), Princeton
              University Press, 2008.</p>
            <h3>The code</h3>
            <p>Solving this optimization problem using Manopt requires little
              code: </p>
            <!--  pre-scrollable -->
            <pre class="prettyprint lang-matlab linenums">% Generate random problem data.
n = 1000;
A = randn(n);
A = .5*(A+A.');

% Create the problem structure.
manifold = spherefactory(n);
problem.M = manifold;

% Define the problem cost function and its Euclidean gradient.
problem.cost  = @(x) -x'*(A*x);
problem.egrad = @(x) -2*A*x;

% Numerically check gradient consistency (optional).
checkgradient(problem);

% Solve.
[x, xcost, info, options] = trustregions(problem);

% Display some statistics.
figure;
semilogy([info.iter], [info.gradnorm], '.-');<br>xlabel('Iteration number');<br>ylabel('Norm of the gradient of f');</pre>
            <p>Let us look at the code bit by bit. First, we generate some data
              for our problem and execute these two lines:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:7">manifold = spherefactory(n);
problem.M = manifold;
</pre>
            <p>The call to <a href="reference/manopt/manifolds/sphere/spherefactory.html"><tt>spherefactory</tt></a>
              returns a structure describing the manifold $\mathbb{S}^{n-1}$,
              i.e., the sphere. This manifold corresponds to the constraint
              appearing in our optimization problem. For other constraints, take
              a look at the <a href="#manifolds">various supported manifolds</a>.
              The second instruction creates a structure named <code>problem</code>
              and sets the field <code>problem.M</code> to contain the manifold
              structure. The problem structure will be populated with everything
              a solver could need to know about the problem in order to solve
              it, such as the cost function and its gradient:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:11">problem.cost = @(x) -x'*(A*x);
problem.egrad = @(x) -2*A*x;
</pre>
            <p>The cost function (to be <em>minimized</em>: Manopt always
              minimizes) and its derivatives are specified as <a target="_blank"
                href="http://www.mathworks.nl/help/matlab/ref/function_handle.html">function
                handles</a>. Notice how the gradient was specified as the <em>Euclidean</em>
              gradient of $f$, i.e., $\nabla f(x) = -2Ax$ in the function <code>egrad</code>
              (mind the "e"). The conversion to the Riemannian gradient happens
              behind the scene. This is particularly useful when one is working
              with a more complicated manifold.</p>
            <p>An alternative to the definition of the gradient is to specify
              the Riemannian gradient directly, possibly calling Manopt's <code>egrad2rgrad</code>
              conversion tool explicitly:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:12">problem.grad = @(x) manifold.egrad2rgrad(x, -2*A*x);
</pre>
            <p>This is useful if an expression for the Riemannian gradient is
              known for example, and it is natural to use that explicitly. Mind
              the names: <code>problem.grad</code> is to specify the <em>Riemannian</em>
              gradient. If you want to specify the <em>Euclidean</em> gradient,
              the correct name is <code>problem.egrad</code>, with an "e". For
              day to day use, <code>egrad</code> is the often the preferred way
              to go.</p>
            <div class="alert alert-info"><strong>Tip!</strong> Notice that the
              functions <code>cost</code> <emph>and</emph> <code>egrad</code>
              <emph>both</emph> compute the product $Ax$, which is likely to be
              the most expensive operation for large scale problems. This is
              perfectly fine for prototyping, but not for a final version of the
              implementation. See the many ways of <a href="#costdescription">describing
                the cost function</a> for alternatives that alleviate redundant
              computations.</div>
            <p>The next instruction is not needed to solve the problem but often
              helps at the prototyping stage:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:15">checkgradient(problem);
</pre>
            <p>The <a href="reference/manopt/tools/checkgradient.html"><tt>checkgradient</tt></a>
              tool verifies numerically that the cost function and its gradient
              agree up to the appropriate order. See the <a href="#tools">tools
                section</a> for more details and more helpful tools offered by
              Manopt. This tool generates the following figure:</p>
            <p><img title="checkgradient figure" alt="checkgradient figure" src="tutorial-gradientcheck.png"></p>
            <p>The blue curve seems to have the same slope as the dashed line
              over a decent segment: that's what we want to see (also check the
              textual output). We now call a solver for our problem:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:18">[x, xcost, info, options] = trustregions(problem);
</pre>
            <p>This instruction calls <a href="reference/manopt/solvers/trustregions/trustregions.html"><tt>trustregions</tt></a>
              on our problem, without initial guess and without options
              structure. As a result, the solver will generate a random initial
              guess automatically and resort to the default values for all
              options. As a general feature in Manopt, all options are, well,
              optional. The returned values are <code>x</code> (usually a local
              minimizer of the cost function), <code>xcost</code> (the cost
              value attained by <code>x</code>), <code>info</code> (a
              struct-array containing information about the successive
              iterations performed by the solver) and <code>options</code> (a
              structure containing all options used and their values: take a
              peek to find out what you can parameterize). For more details and
              more solvers, see the <a href="#solvers">solvers</a> section.</p>
            <div class="alert alert-info">This call will issue a warning because
              the trust-regions algorithm normally requires the Hessian of the
              cost function, or an approximation of it, to be provided in the
              problem structure. When the Hessian is not provided, Manopt will
              approximate it using a finite differencing scheme on the gradient
              function and warn you about it. You may disable this warning by
              calling <code>warning('off', 'manopt:getHessian:approx');</code>.
            </div>
            <p>Finally, we access the contents of the struct-array <code>info</code>
              to display the convergence plot of our solver: </p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:22">semilogy([info.iter], [info.gradnorm], '.-');<br>xlabel('Iteration number');<br>ylabel('Norm of the gradient of f');
</pre>
            <p>This generates the following figure:</p>
            <p><img title="Gradient norm converging to zero" alt="Gradient norm converging to zero"
                src="tutorial-gradientnorm.png"></p>
            <p>For more information on what data is stored in <code>info</code>,
              see the <a href="#solvers">solvers</a> section.</p>
            <div class="alert alert-info"><strong>Heads up!</strong> Notice that
              we write <code>[info.xxx]</code> and not simply <code>info.xxx</code>,
              because <code>info</code> is a <emph>struct-array</emph>. Read
              this <a target="_blank" href="http://blogs.mathworks.com/loren/2007/04/19/vectorizing-access-to-an-array-of-structures/">MathWorks
                blog post</a> for further information.</div>
          </section>
          <section id="manifolds">
            <div class="page-header">
              <h1>Manifolds </h1>
            </div>
            <h3>General description <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"> </h3>
            <p>Manifolds in Manopt are represented as structures and are
              obtained by calling a factory. Built-in factories are located in <tt>/manopt/manifolds</tt>.
              Picking a manifold corresponds to specifying a search space for
              the decision variables. For the special (but common) case of a
              submanifold, the manifold represents a constraint on the decision
              variables (such as the sphere, which constrains vectors to have
              unit norm). In the case of a quotient manifold, the manifold
              captures an invariance in the cost function (such as the Grassmann
              manifold). Typically, points on the manifold as well as tangent
              vectors are represented by matrices, but they could be represented
              by structures, cells, etc.</p>
            <h3 id="manifoldslibrary">Available manifolds </h3>
            <p>Manopt comes with a number of implementations for generically
              useful manifolds. Of course, manifolds can also be user-defined.
              The best way to build your own is probably to read the code of
              some of the standard factories and to adapt what needs to be
              changed. If you develop an interesting manifold factory and would
              like to share it, be sure to let us know: we would love to add it
              to Manopt if it can be of interest to other users!</p>
            <!-- table-bordered table-condensed -->
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Set </td>
                  <td>Factory</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/euclidean/euclideanfactory.html">Euclidean
                      space</a> (<a href="reference/manopt/manifolds/euclidean/euclideancomplexfactory.html">complex</a>)
                  </td>
                  <td>$\mathbb{R}^{m\times n}$, $\mathbb{C}^{m\times n}$</td>
                  <td><code>euclideanfactory(m, n)</code><br>
                    <code>euclideancomplexfactory(m, n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/euclidean/symmetricfactory.html">Symmetric
                      matrices</a> </td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X = X^T\}^k$ </td>
                  <td><code>symmetricfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  target="_blank" href="reference/manopt/manifolds/euclidean/centeredmatrixfactory.html">Centered
                      matrices</a></td>
                  <td>$\{ X \in \mathbb{R}^{m\times n} : X\mathbf{1}_n = 0_m \}$</td>
                  <td><code>centeredmatrixfactory(m, n)</code></td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_sphere.html">Sphere</a> </td>
                  <td>$\{X\in\mathbb{R}^{n\times m} : \|X\|_\mathrm{F} = 1\}$ </td>
                  <td><code>spherefactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/sphere/spheresymmetricfactory.html">Symmetric
                      sphere</a></td>
                  <td>$\{X\in\mathbb{R}^{n\times n} : \|X\|_\mathrm{F} = 1, X =
                    X^T\}$ </td>
                  <td><code>spheresymmetricfactory(n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/sphere/spherecomplexfactory.html">Complex
                      sphere</a> </td>
                  <td>$\{X\in\mathbb{C}^{n\times m} : \|X\|_\mathrm{F} = 1\}$ </td>
                  <td><code>spherecomplexfactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_oblique.html">Oblique
                      manifold</a> </td>
                  <td>$\{X\in\mathbb{R}^{n\times m} : \|X_{:1}\| = \cdots =
                    \|X_{:m}\| = 1\}$ </td>
                  <td><code>obliquefactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/complexcircle/complexcirclefactory.html">Complex
                      circle</a> </td>
                  <td>$\{z\in\mathbb{C}^n : |z_1| = \cdots = |z_n| = 1\}$ </td>
                  <td><code>complexcirclefactory(n)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/stiefel/stiefelfactory.html">Stiefel
                      manifold </a></td>
                  <td>$\{X \in \mathbb{R}^{n \times p} : X^TX = I_p\}^k$ </td>
                  <td><code>stiefelfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/stiefel/stiefelcomplexfactory.html">Complex
                      Stiefel manifold </a></td>
                  <td>$\{X \in \mathbb{C}^{n \times p} : X^*X = I_p\}^k$ </td>
                  <td><code>stiefelcomplexfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/stiefel/stiefelgeneralizedfactory.html">Generalized
                      Stiefel manifold </a></td>
                  <td>$\{X \in \mathbb{R}^{n \times p} : X^TBX = I_p\}$ for some
                    $B \succ 0$</td>
                  <td><code>stiefelfactory(n, p, B)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/stiefel/stiefelstackedfactory.html">Stiefel
                      manifold, stacked </a></td>
                  <td>$\{X \in \mathbb{R}^{md \times k} : (XX^T)_{ii} = I_d\}$ </td>
                  <td><code>stiefelstackedfactory(m, d, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/grassmann/grassmannfactory.html">Grassmann
                      manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{R}^{n \times p},
                    X^TX = I_p\}^k$ </td>
                  <td><code>grassmannfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/grassmann/grassmanncomplexfactory.html">Complex
                      Grassmann manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{R}^{n \times p},
                    X^TBX = I_p\}^k$ </td>
                  <td><code>grassmanncomplexfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/grassmann/grassmanngeneralizedfactory.html">Generalized
                      Grassmann manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{R}^{n \times p},
                    X^TX = I_p\}$ for some $B \succ 0$</td>
                  <td><code>grassmannfactory(n, p, B)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_rotations.html">Rotation
                      group</a> </td>
                  <td>$\{R \in \mathbb{R}^{n \times n} : R^TR = I_n, \det(R) =
                    1\}^k$ </td>
                  <td><code>rotationsfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/euclidean/specialeuclideanfactory.html">Special
                      Euclidean group</a></td>
                  <td>$\{ (R, t) \in \mathbb{R}^{n \times n} \times \mathbb{R}^n
                    : R^TR = I_n, \det(R) = 1 \}^k$</td>
                  <td><code>specialeuclideanfactory(n, k)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/essential/essentialfactory.html">Essential
                      manifold</a></td>
                  <td>Epipolar constraint between projected points in two
                    perspective views, see <a target="_blank" href="https://fling.seas.upenn.edu/%7Etron">Roberto
                      Tron</a>'s page</td>
                  <td><code>essentialfactory(k, '(un)signed')</code></td>
                </tr>
                <tr>
                  <td>Fixed-rank </td>
                  <td>$\{X \in \mathbb{R}^{m \times n} : \operatorname{rank}(X)
                    = k\}$ </td>
                  <td> <code>fixedrankembeddedfactory(m, n, k)</code> <a target="_blank" href="reference/manopt/manifolds/fixedrank/fixedrankembeddedfactory.html">(ref)</a><br>
                    <code>fixedrankfactory_2factors(m, n, k)</code> <a href="manifold_documentation_fixedrank_2factors.html">(doc)</a><br>
                    <code>fixedrankfactory_2factors_preconditioned(m, n, k)</code>
                    <a target="_blank"  href="reference/manopt/manifolds/fixedrank/fixedrankfactory_2factors_preconditioned.html">(ref)</a><br>
                    <code>fixedrankfactory_2factors_subspace_projection(m, n, k)</code>
                    <a target="_blank" href="reference/manopt/manifolds/fixedrank/fixedrankfactory_2factors_subspace_projection.html">(ref)</a><br>
                    <code>fixedrankfactory_3factors(m, n, k)</code> <a target="_blank"  href="reference/manopt/manifolds/fixedrank/fixedrankfactory_3factors.html">(ref)</a><br>
                    <code>fixedrankMNquotientfactory(m, n, k)</code> <a target="_blank" href="reference/manopt/manifolds/fixedrank/fixedrankMNquotientfactory.html">(ref)</a></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/fixedranktensors/fixedrankfactory_tucker_preconditioned.html">Fixed-rank
                      tensor</a></td>
                  <td>Tensors of fixed multilinear rank in Tucker format</td>
                  <td><code>fixedrankfactory_tucker_preconditioned</code></td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_symfixedrank.html">Symmetric
                      positive semidefinite, fixed-rank</a> (<a target="_blank"
                      href="reference/manopt/manifolds/symfixedrank/symfixedrankYYcomplexfactory.html">complex</a>)</td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0,
                    \operatorname{rank}(X) = k\}$ </td>
                  <td><code>symfixedrankYYfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank"  href="reference/manopt/manifolds/symfixedrank/elliptopefactory.html">Symmetric
                      positive semidefinite, fixed-rank with unit diagonal</a></td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0,
                    \operatorname{rank}(X) = k, \operatorname{diag}(X) = 1\}$</td>
                  <td><code>elliptopefactory(n, k)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/symfixedrank/spectrahedronfactory.html">Symmetric
                      positive semidefinite, fixed-rank with unit trace</a></td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0,
                    \operatorname{rank}(X) = k, \operatorname{trace}(X) = 1\}$</td>
                  <td><code>spectrahedronfactory(n, k) </code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/multinomial/multinomialfactory.html">Multinomial
                      manifold</a> (strict simplex elements)</td>
                  <td>$\{ X \in \mathbb{R}^{n\times m} : M_{ij} &gt; 0 \forall
                    i,j \textrm{ and } M^T 1 = 1 \}$</td>
                  <td><code>multinomialfactory(n, m)</code></td>
                </tr>
              </tbody>
            </table>
            <p>Bear in mind that a set can often be turned into a Riemannian
              manifold in many different ways, by choosing one or another
              metric. Which metric is best for a specific application may vary.
              This is particularly true for the geometries of the fixed-rank
              matrices. The latter is a hot research topic right now and there
              is no better method yet than experimenting with various
              geometries.</p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need to
              work on a <emph>product</emph> of manifolds? For example, are you
              minimizing a function $f(X, Y)$ where $X$ has unit norm and $Y$ is
              orthonormal? Or a function $f(X_1, \ldots, X_n)$ where each $X_i$
              lives on a same manifold? Then make sure to check out <code>productmanifold</code>
              and <code>powermanifold</code> in the <a href="#tools">tools
                section</a>. </div>
            <h3>Manifold structure fields</h3>
            <p>A manifold structure has a number of fields, most of which
              contain function handles. Here is a list of things you might find
              in a structure <code>M</code> returned by a manifold factory:</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Field usage </td>
                  <td>Functionality </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Name </td>
                  <td><code>M.name()</code> </td>
                  <td>Returns a name for the manifold as a string. </td>
                </tr>
                <tr>
                  <td>Dimension </td>
                  <td><code>M.dim() </code></td>
                  <td>Returns the dimension of the manifold. </td>
                </tr>
                <tr>
                  <td>Metric </td>
                  <td><code>M.inner(x, u, v) </code></td>
                  <td>Computes $\langle u, v \rangle_x$. </td>
                </tr>
                <tr>
                  <td>Norm </td>
                  <td><code>M.norm(x, u) </code></td>
                  <td>Computes $\|u\|_x = \sqrt{\langle u, u \rangle_x}$</td>
                </tr>
                <tr>
                  <td>Distance </td>
                  <td><code>M.dist(x, y) </code></td>
                  <td>Computes $\operatorname{dist}(x, y)$, the Riemannian
                    distance. </td>
                </tr>
                <tr>
                  <td>Typical distance </td>
                  <td><code>M.typicaldist() </code></td>
                  <td>Returns the "scale" of the manifold. This is used by the
                    trust-regions solver for example, to determine default
                    initial and maximal trust-region radii.</td>
                </tr>
                <tr>
                  <td>Tangent space projector </td>
                  <td><code>M.proj(x, u) </code></td>
                  <td>Computes $\operatorname{Proj}_x u$, the orthogonal
                    projection of the vector $u$ from the ambient or total space
                    to the tangent space at $x$ or to the horizontal space at
                    $x$. </td>
                </tr>
                <tr>
                  <td>Euclidean to Riemannian gradient</td>
                  <td><nobr><code>M.egrad2rgrad(x, egrad)</code></nobr></td>
                  <td>For manifolds embedded in a Euclidean space, converts the
                    gradient of $f$ at $x$ seen as a function in that Euclidean
                    space to the Riemannian gradient of $f$ on the manifold.</td>
                </tr>
                <tr>
                  <td>Euclidean to Riemannian Hessian</td>
                  <td><code>M.ehess2rhess(x, egrad, ehess, u)</code> </td>
                  <td>Similarly to <code>egrad2rgrad</code>, converts the
                    Euclidean gradient and Hessian of $f$ at $x$ along a tangent
                    vector $u$ to the Riemannian Hessian of $f$ at $x$ along $u$
                    on the manifold. </td>
                </tr>
                <tr>
                  <td>Tangentialize</td>
                  <td><code>M.tangent(x, u)</code></td>
                  <td>Re-tangentializes a vector. The input is a vector in the
                    tangent vector representation, which possibly (for example
                    because of error accumulations) is not tangent anymore. The
                    output will be the "closest" tangent vector to the input. If
                    tangent vectors are represented in the ambient space, this
                    is equivalent to <code>proj</code>.</td>
                </tr>
                <tr>
                  <td>Tangent to ambient representation</td>
                  <td><code>M.tangent2ambient(x, u)</code></td>
                  <td>Tangent vectors are sometimes described differently from
                    their counterpart in the ambient space. This will return the
                    ambient space representation of a tangent vector $u$. Useful
                    when defining the Euclidean Hessian for example. </td>
                </tr>
                <tr>
                  <td>Exponential map </td>
                  <td><code>M.exp(x, u, t) </code></td>
                  <td>Computes $\operatorname{Exp}_x(tu)$, the point you reach
                    by following the vector $tu$ starting at $x$. </td>
                </tr>
                <tr>
                  <td>Retraction </td>
                  <td><code>M.retr(x, u, t) </code></td>
                  <td>Computes $\operatorname{Retr}_x(tu)$, where
                    $\operatorname{Retr}$ is a retraction: a cheaper proxy for
                    the exponential map. </td>
                </tr>
                <tr>
                  <td>Logarithmic map </td>
                  <td><code>M.log(x, y) </code></td>
                  <td>Computes $\operatorname{Log}_x(y)$, a tangent vector at
                    $x$ pointing toward $y$. </td>
                </tr>
                <tr>
                  <td>Random point </td>
                  <td><code>M.rand() </code></td>
                  <td>Computes a random point on the manifold. </td>
                </tr>
                <tr>
                  <td>Random vector </td>
                  <td><code>M.randvec(x) </code></td>
                  <td>Computes a random, unit-norm tangent vector in the tangent
                    space at $x$. </td>
                </tr>
                <tr>
                  <td>Zero vector </td>
                  <td><code>M.zerovec(x) </code></td>
                  <td>Returns the zero tangent vector at $x$. </td>
                </tr>
                <tr>
                  <td>Linear combination </td>
                  <td><code>M.lincomb(x, a1, u1, a2, u2) </code></td>
                  <td>Computes the tangent vector at $x$: $v = a_1 u_1 + a_2
                    u_2$, where $a_1, a_2$ are scalars and $u_1, u_2$ are
                    tangent vectors at $x$. The inputs $a_2, u_2$ are optional.
                  </td>
                </tr>
                <tr>
                  <td>Vector transport </td>
                  <td><code>M.transp(x, y, u) </code></td>
                  <td>Computes a tangent vector at $y$ that "looks like" the
                    tangent vector $u$ at $x$. </td>
                </tr>
                <tr>
                  <td>Pair mean </td>
                  <td><code>M.pairmean(x, y) </code></td>
                  <td>Computes the intrinsic mean of $x$ and $y$, that is, a
                    point that lies mid-way between $x$ and $y$ on the geodesic
                    arc joining them. </td>
                </tr>
                <tr>
                  <td>Hashing function </td>
                  <td><code>M.hash(x) </code></td>
                  <td>Computes a string that (almost) uniquely identifies the
                    point $x$ and that can serve as a field name for a
                    structure. (Not used since version 1.0.8)</td>
                </tr>
                <tr>
                  <td>Vector representation</td>
                  <td><code>M.vec(x, u)</code></td>
                  <td>Returns a <em>real </em>column-vector representation of
                    the tangent vector $u$. The length of the output is always
                    the same and at least <code>M.dim()</code>. This function
                    is linear and invertible on the tangent space at $x$.</td>
                </tr>
                <tr>
                  <td>Normal representation</td>
                  <td><code>M.mat(x, u_vec)</code></td>
                  <td>The inverse of the <code>vec</code> function: will return
                    a tangent vector representation from a column vector such
                    that <code>M.mat(x, M.vec(x, u)) = u</code>. </td>
                </tr>
                <tr>
                  <td>vec and mat isometry check</td>
                  <td><code>M.vecmatareisometries()</code></td>
                  <td>Returns true if <code>M.vec</code> is a linear isometry,
                    i.e., if for all tangent vectors $u,v$, <code>M.inner(x, u,
                      v) == M.vec(x, u).'*M.vec(x, v)</code>. Then, <code>M.mat</code>
                    is both the adjoint and the inverse of <code>M.vec</code>
                    (on the tangent space).</td>
                </tr>
              </tbody>
            </table>
            <p>Not all manifold factories populate all of these fields, but
              that's okay: for many purposes, only a subset of these functions
              are necessary. Notice that it is also very easy to add or replace
              fields in a manifold structure returned by a factory, which can be
              desirable to experiment with various retractions, vector
              transports, etc. If you find ways to improve the built-in
              geometries, <a href="#contactmodal">let us know</a>.</p>
          </section>
          <section id="solvers">
            <div class="page-header">
              <h1>Solvers </h1>
            </div>
            <h3>General description <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"> </h3>
            <p>Solvers, or optimization algorithms, are functions in Manopt.
              Built-in solvers are located in <span style="font-family: monospace;">/manopt/solvers</span>.
              In principle, all solvers admit the basic call format <code>x =
                mysolver(problem)</code>. The returned value <code>x</code>
              will be a point on the manifold <code>problem.M</code>. Depending
              on the properties of your problem and on the guarantees of the
              solver, <code>x</code> will be more or less close to a good
              minimizer of the cost function described in the <code>problem</code>
              structure. Bear in mind that we are dealing with usually
              nonconvex, and possibly nonsmooth or derivative-free optimization,
              so that it is in general not guaranteed that <code>x</code> will
              be a global minimizer of the cost. For smooth problems with
              gradient information though, most decent algorithms guarantee that
              <code>x</code> will be a critical point (typically a local
              minimizer, but even that is usually not guaranteed in all cases:
              this is a fundamental limitation of nonlinear optimization). </p>
            <div class="alert alert-info"><strong>Heads up!</strong> All
              provided solvers are <em>minimization</em> algorithms. If you
              want to <em>maximize </em>your objective function, multiply it
              by -1 (and accordingly for the derivatives of the objective
              function if needed), as we did in the <a href="#firstexample">first
                example</a>. </div>
            <p>In principle, all solvers also admit a more complete call format:
              <code>[x, xcost, info, options] = mysolver(problem, x0, options)</code>.
              The output <code>xcost</code> is the value of the cost function
              at the returned point <code>x</code>. The <code>info</code>
              struct-array is described below, and contains information
              collected at each iteration of the solver's progress. The <code>options</code>
              structure is returned too, so you can see what default values the
              solver used on top of the options you (possibly) specified. The
              input <code>x0</code> is an initial guess, or initial iterate,
              for the solver. It is typically a point on the manifold <code>problem.M</code>,
              but may be something else depending on the solver. It can be
              omitted by passing the empty matrix <code>[]</code> instead. The
              <code>options</code> structure is used to fine tune the behavior
              of the optimization algorithm. On top of hosting the algorithmic
              parameters, it manages the stopping criteria as well as what
              information needs to be displayed and / or logged during
              execution. </p>
            <h3>Available solvers </h3>
            <p>The toolbox is fairly young and comes with only a handful of
              solvers, the most trust-worthy being the trust-regions algorithm
              as it is a modification of the code of <a title="GenRTR, by Chris Baker, P.-A. Absil and Kyle Gallivan"
                href="http://www.math.fsu.edu/%7Ecbaker/genrtr/" target="_blank">GenRTR</a>.
              The toolbox was designed to accommodate many more solvers though,
              and we expect to propose BFGS-style solvers, stochastic gradient
              descents and many more in the future. In particular, we look
              forward to proposing algorithms for nonsmooth cost functions
              (which notably arise when L1 penalties are at play).</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Requires (benefits of) </td>
                  <td>Comment </td>
                  <td>Call</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="solver_documentation_trustregions.html">Trust-regions</a>
                  </td>
                  <td>Cost, gradient (Hessian, approximate Hessian,
                    preconditioner) </td>
                  <td>#1 choice for smooth optimization; uses <abbr title="Finite differences"
                      class="initialism">FD</abbr> of the gradient in the
                    absence of Hessian. </td>
                  <td><code>trustregions(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/steepestdescent/steepestdescent.html">Steepest-descent</a>
                  </td>
                  <td>Cost, gradient </td>
                  <td>Simple implementation of <abbr title="Gradient descent" class="initialism">GD</abbr>
                    ; the built-in line-search is backtracking based. </td>
                  <td><code>steepestdescent(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/conjugategradient/conjugategradient.html">Conjugate-gradient
                      </a></td>
                  <td>Cost, gradient (preconditioner) </td>
                  <td>Often performs better than steepest-descent. </td>
                  <td><code>conjugategradient(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/pso/pso.html">Particle
                      swarm (PSO) </a></td>
                  <td>Cost </td>
                  <td><abbr title="Derivative-free optimization" class="initialism">DFO</abbr>
                    based on a population of points. </td>
                  <td><code>pso(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/neldermead/neldermead.html">Nelder-Mead</a>
                  </td>
                  <td>Cost </td>
                  <td><abbr title="Derivative-free optimization" class="initialism">DFO</abbr>
                    based on a simplex; requires <code>M.pairmean</code>;
                    limited to (very) low-dimensional problems. </td>
                  <td><code>neldermead(...)</code> </td>
                </tr>
              </tbody>
            </table>
            <h3>The options structure </h3>
            <p>In Manopt, <em>all</em> options are optional. Standard options
              are assigned a default value at the toolbox level in <a href="reference/manopt/core/getGlobalDefaults.html"><tt>/manopt/core/getGlobalDefaults.m</tt></a>
              (it's a core tool, best not to edit it). Solvers then overwrite
              and complement these options with solver-specific fields. These
              options are in turn overwritten by the user-specified options, if
              any. Here is a list of commonly used options (see each solver's
              documentation for specific information):</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>options."..."</code>) </td>
                  <td>Value type </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Output and information
                      logging</strong> </td>
                </tr>
                <tr>
                  <td><code>verbosity</code></td>
                  <td>integer </td>
                  <td>Controls how much information a solver outputs during
                    execution ; 0: no output; 1 : output at init and at exit; 2:
                    light output at each iteration; more: all you can read. </td>
                </tr>
                <tr>
                  <td><code>debug</code></td>
                  <td>integer </td>
                  <td>If larger than 0, the solver may perform additional
                    computations for debugging purposes. </td>
                </tr>
                <tr>
                  <td><code>statsfun</code> </td>
                  <td>fun. handle </td>
                  <td>
                    <p><a id="statsfunhelp" name="statsfunhelp"></a>If you
                      specify a function handle with prototype <code>stats =
                        statsfun(problem, x, stats)</code>, it will be called
                      after each iteration completes. It receives the <code>problem</code>
                      structure, the current point <code>x</code> and the
                      statistics structure <code>stats</code> that will be
                      logged in the <code>info</code> struct-array at the
                      corresponding iteration number. This function gives you a
                      chance to modify the <code>stats</code> structure, hence
                      to add fields if you want to. Bear in mind that structures
                      in a struct-array must <em>all </em>have the same
                      fields, so that if <code>statsfun</code> adds a field to
                      a <code>stats</code> structure, it must do so for <em>all
                        </em>iterations. Time spent in <code>statsfun</code> is
                      discounted from execution time, as this is typically only
                      used for prototyping / debugging.</p>
                    <p>Example:</p>
                    <pre class="prettyprint lang-matlab linenums">options.statsfun = @mystatsfun;
function stats = mystatsfun(problem, x, stats)
    stats.x = x;
end</pre>
                    <p> This will log all the points visited during the
                      optimization process in the <code>info</code>
                      struct-array returned by the solver.</p>
                    <p>You may also provide a function handle with this calling
                      pattern: <code>stats = statsfun(problem, x, stats, store)</code>.
                      This additionally lets you access the data stored for that
                      particular iterate in the store structure. As of Manopt
                      1.0.8, this memory has an additional field: <code>store.shared</code>
                      (it can be read, but not edited here). This field contains
                      "permanent" memory, shared by all points <code>x</code>
                      visited so far.</p>
                    <p>An alternative is to use the <code>statsfunhelper</code>
                      tool, which is sometimes simpler (and allows to pass
                      inline functions). The example above simplifies to:</p>
                    <pre class="prettyprint lang-matlab linenums">options.statsfun = statsfunhelper('x', @(x) x);</pre>
                    <p>The helper can also be used to log more than one metric,
                      by passing it a structure. In the example below, <code>x_reference</code>
                      is a certain point on the manifold <code>problem.M</code>.
                      The stats structures will include fields <code>x</code>
                      and <code>dist_to_ref</code>. Notice how the function
                      handles can take different inputs. See the help for more
                      info.</p>
                    <pre class="prettyprint lang-matlab linenums">metrics.x = @(x) x;<br>metrics.dist_to_ref = @(problem, x) problem.M.dist(x, x_reference);<br>options.statsfun = statsfunhelper(metrics);</pre>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Stopping criteria</strong>
                  </td>
                </tr>
                <tr>
                  <td><code>maxiter</code></td>
                  <td>integer </td>
                  <td>Limits the number of iterations of the solver. </td>
                </tr>
                <tr>
                  <td><code>maxtime</code></td>
                  <td>double </td>
                  <td>Limits the <abbr title="Not taking into account time spent in statsfun.">execution
                      time</abbr> of the solver, in seconds. </td>
                </tr>
                <tr>
                  <td><code>maxcostevals</code></td>
                  <td>integer </td>
                  <td>Limits the number of evaluations of the cost function. </td>
                </tr>
                <tr>
                  <td><code>tolcost</code></td>
                  <td>double </td>
                  <td>Stop as soon as the cost drops below this tolerance. </td>
                </tr>
                <tr>
                  <td><code>tolgradnorm</code></td>
                  <td>double </td>
                  <td>Stop as soon as the norm of the gradient drops below this
                    tolerance. </td>
                </tr>
                <tr>
                  <td><code>stopfun</code> </td>
                  <td>fun. handle </td>
                  <td>
                    <p>If you specify a function handle with prototype <code>stopnow
                        = stopfun(problem, x, info, last)</code>, it will be
                      called after each iteration completes with the <code>problem</code>
                      structure, the current point <code>x</code> , the whole <code>info</code>
                      struct-array built so far and an index <code>last</code>
                      such that <code>info(last)</code> is the structure
                      pertaining to the current iteration (this is because <code>info</code>
                      is pre-allocated, so that <code>info(end)</code>
                      typically does <em>not</em> refer to the current
                      iteration). The return value is a Boolean. If <code>stopnow</code>
                      is returned as <tt>true</tt>, the solver will terminate.</p>
                    <p>Example:</p>
                    <pre class="prettyprint lang-matlab linenums">options.stopfun = @mystopfun;
function stopnow = mystopfun(problem, x, info, last)
    stopnow = (last &gt;= 3 &amp;&amp; info(last-2).cost - info(last).cost &lt; 1e-3);
end</pre>
                    <p> This will tell the solver to exit as soon as two
                      successive iterations combined have decreased the cost by
                      less than 10<sup>-3</sup>.</p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Line-search<a id="linesearchoptions">&#160;</a></strong>
                  </td>
                </tr>
                <tr>
                  <td><code>linesearch</code></td>
                  <td>fun. handle</td>
                  <td>
                    <p>Some solvers, such as <code>steepestdescent</code> and <code>conjugategradient</code>,
                      need to solve a line-search problem at each iteration.
                      That is, they need to (approximately) solve the
                      one-dimensional optimization problem:<br>
                      $$\min_{t\geq 0} \phi(t) = f(\operatorname{Retr}_x(td)),$$<br>
                      where $x$ is the current point on the manifold, $d$ is a
                      tangent vector at $x$ (the search direction),
                      $\operatorname{Retr}$ is the retraction on the manifold
                      and $f$ is the cost function. Assuming $d$ is a descent
                      direction, there exists $t &gt; 0$ such that $\phi(t) &lt;
                      \phi(0) = f(x)$. A line-search algorithm is conceived to
                      find such a real number $t$.</p>
                    <p>Manopt includes certain <a href="reference/manopt/solvers/linesearch/index.html">generic
                        purpose line-search algorithms</a>. To force the use of
                      one of them or of your own, specify this in the options
                      structure (not in the problem structure) as follows: <code>options.linesearch
                        = @linesearch_adaptive;</code> (for example). Each
                      line-search algorithm will accept its own options which
                      can be added in this same <code>options</code> structure.
                      See each line-search's help for details.</p>
                    <p>For certain problems, you may want to implement your own
                      line-search, typically in order to exploit structure
                      specific to the problem at hand. To this end, it is best
                      to start from an existing line-search function and to
                      adapt it. Alternatively (and perhaps more easily), you may
                      specify a <code>linesearch</code> function in the <code>problem</code>
                      structure (see the <a href="#linesearchproblem">cost
                        description section</a>) and use a line-search that will
                      use it, to incorporate the additional information you
                      supply there. Do not hesitate to ask for help on the forum
                      if you run into trouble here :).</p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Miscellaneous</strong> </td>
                </tr>
                <tr>
                  <td><code>storedepth</code></td>
                  <td>integer </td>
                  <td>Maximum number of <code>store</code> structures that may
                    be kept in memory (see the <a href="#costdescription">cost
                      description</a> section). </td>
                </tr>
              </tbody>
            </table>
            <p>Keep in mind that a specific solver may not use all of these
              options and may use additional options, which would then be
              described on the solver's documentation page. </p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need a
              problem-specific stopping criterion? Include a <code>stopfun</code>
              in your <code>options</code> structure. </div>
            <h3>The info struct-array </h3>
            <p>The various solvers will log information at each iteration about
              their progress. This information is returned in the output <code>info</code>,
              a struct-array, that is, an array of structures. Read this <a href="http://blogs.mathworks.com/loren/2007/04/19/vectorizing-access-to-an-array-of-structures/"
                target="_blank">MathWorks blog post</a> for help on dealing with
              this data container in Matlab. Here are the typical indicators
              that might be present in the <code>info</code> output:</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>[info."..."]</code>) </td>
                  <td>Value type </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><code>iter</code></td>
                  <td>integer </td>
                  <td>Iteration number (0 corresponds to the initial guess). </td>
                </tr>
                <tr>
                  <td><code>time</code> </td>
                  <td>double </td>
                  <td>Elapsed <abbr title="Not taking into account time spent in statsfun.">execution
                      time</abbr> until completion of the iterate, in seconds. </td>
                </tr>
                <tr>
                  <td><code>cost</code> </td>
                  <td>double </td>
                  <td>Attained value of the cost function. </td>
                </tr>
                <tr>
                  <td><code>gradnorm</code> </td>
                  <td>double </td>
                  <td>Attained value for the norm of the gradient. </td>
                </tr>
              </tbody>
            </table>
            <p>A specific solver may not populate all of these fields and may
              provide additional fields, which would then be described in the
              solver's documentation. </p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need to
              log problem-specific information at each iteration? Include a <code>statsfun</code>
              in your <code>options</code> structure.</div>
            <div class="alert alert-info"><strong>Heads up!</strong> The
              execution time is logged <em>without</em> incorporating time
              spent in <code>statsfun</code>, as it usually performs
              computations that are not needed to solve the optimization
              problem. If, however, you use information logged by <code>statsfun</code>
              for your <code>stopfun</code> criterion, and if this is important
              for your method (i.e., it is not just for convenience during
              prototyping), you should time the execution time of <code>statsfun</code>
              and add it to the <code>stats.time</code> field. </div>
          </section>
          <section id="costdescription">
            <div class="page-header">
              <h1>Describing the cost function</h1>
            </div>
            <h3>General philosophy <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"></h3>
            <p>An optimization problem in Manopt is represented as a <code>problem</code>
              structure. The latter must include a field <code>problem.M</code>
              which contains a structure describing a manifold, as obtained from
              <a href="#manifolds">a factory</a>. On top of this, the problem
              structure must include some fields that describe the cost function
              $f$ to be minimized and, possibly, its derivatives. </p>
            <p>The solvers will <em>not </em>query these function handles
              directly. Instead, they call core (internal) tools such as <code>getCost</code>,
              <code>getGradient</code>, <code>getHessian</code>, etc. These
              tools will consider the available fields in the problem structure
              and "do their best" to return the required object. </p>
            <p>As a result, we gain great flexibility in the cost function
              description. Indeed, as the needs grow during the life-cycle of
              the toolbox and new ways of describing the cost function become
              necessary, it suffices to update the core <code>get*</code> tools
              to take these new ways into account. We seldom have to modify the
              solvers.</p>
            <p>For now, there are only a few ways to describe the cost and its
              derivatives, but there will be more as the needs grow. </p>
            <h3>Cost describing fields </h3>
            <p> You may specify as many of the following fields as you wish in
              the <code>problem</code> structure. If you specify some function
              more than once (for example, if you define <code>diff</code> <em>and</em>
              <code>grad</code>, both of which could be used to compute
              directional derivatives), the toolbox does not specify which will
              be called (hence, it is better not to, or to be really sure about
              consistency). Probably, the toolbox would assume the code for <code>diff</code>
              is more efficient than the code for <code>grad</code> when only a
              directional derivative is needed, but there is no guarantee.
              Bottom line: they should be consistent (profile if need be).</p>
            <p>In the table below, each function admits three different calling
              patterns. The first one is the simplest and is perfectly fine for
              prototyping. The other calling patterns give explicit access to
              Manopt's caching system, which is documented below.</p>
            <div class="alert alert-info"><strong>Good to know!</strong> All
              function handles admit a store structure as extra argument for
              caching purposes, as explained in the next section. This is an
              optional feature. For prototyping, it is often easier to write a
              first version of the code without caching. </div>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>problem."..."</code>)</td>
                  <td>Prototype </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><code>cost</code> </td>
                  <td><code>f = cost(x)</code><br>
                    <nobr><code>[f, store] = cost(x, store)</code></nobr><br>
                    <nobr><code>f = cost(x, storedb, key)</code></nobr></td>
                  <td>$f = f(x)$ </td>
                </tr>
                <tr>
                  <td><code>grad</code> </td>
                  <td><code>g = grad(x)</code><br>
                    <nobr><code>[g, store] = grad(x, store)</code></nobr><br>
                    <nobr><code>g = grad(x, storedb, key)</code></nobr></td>
                  <td>$g = \operatorname{grad} f(x)$ </td>
                </tr>
                <tr>
                  <td><code>costgrad</code> </td>
                  <td><code>[f, g] = costgrad(x)</code><br>
                    <nobr><code>[f, g, store] = costgrad(x, store)</code></nobr><br>
                    <nobr><code>[f, g] = costgrad(x, storedb, key)</code></nobr>
                  </td>
                  <td>Computes both $f = f(x)$ and $g = \operatorname{grad}
                    f(x)$.</td>
                </tr>
                <tr>
                  <td><code>egrad</code> </td>
                  <td><code>eg = egrad(x)</code><br>
                    <nobr><code>[eg, store] = egrad(x, store)</code></nobr><br>
                    <nobr><code>eg = egrad(x, storedb, key)</code></nobr> </td>
                  <td>
                    <p>For submanifolds of a Euclidean space or quotient spaces
                      with a Euclidean total space, computes $eg = \nabla f(x)$,
                      the gradient of $f$ "as if" it were defined in that
                      Euclidean space. This will be passed to <code>M.egrad2rgrad</code>.</p>
                    <p>Function <code>egrad</code> involves automatic caching
                      for use with <code>ehess</code>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>hess</code> </td>
                  <td><code>h = hess(x, u)</code><br>
                    <nobr><code>[h, store] = hess(x, u, store)</code></nobr><br>
                    <nobr><code>h = hess(x, u, storedb, key)</code></nobr></td>
                  <td>$h = \operatorname{Hess} f(x)[u]$ </td>
                </tr>
                <tr>
                  <td><code>ehess</code> </td>
                  <td><code>eh = ehess(x, u)</code><br>
                    <nobr><code>[eh, store] = ehess(x, u, store)</code></nobr><br>
                    <nobr><code>eh = ehess(x, u, storedb, key)</code></nobr></td>
                  <td>
                    <p>For submanifolds of a Euclidean space or quotient spaces
                      with a Euclidean total space, computes $eh = \nabla^2
                      f(x)[u]$, the Hessian of $f$ along $u$ "as if" it were
                      defined in that Euclidean space. This will be passed to <code>M.ehess2rhess</code>
                      and thus requires the Euclidean gradient to be accessible
                      (<code>egrad</code>).</p>
                    <p>Function <code>egrad</code> involves automatic caching
                      for use with <code>ehess</code>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>diff</code> </td>
                  <td><code>d = diff(x, u)</code><br>
                    <nobr><code>[d, store] = diff(x, u, store)</code></nobr><br>
                    <nobr><code>d = diff(x, u, storedb, key)</code></nobr></td>
                  <td>$d = \operatorname{D}\! f(x)[u]$ </td>
                </tr>
                <tr>
                  <td><code>approxhess</code> </td>
                  <td><code>h = approxhess(x, u)</code><br>
                    <nobr><code>[h, store] = approxhess(x, u, store)</code></nobr><br>
                    <nobr><code>h = approxhess(x, u, storedb, key)</code></nobr>
                  </td>
                  <td>
                    <p>This can be any mapping from the tangent space at $x$ to
                      itself. Often, one would like for it to be a linear,
                      symmetric operator. Solvers asking for the Hessian when
                      one is not provided will automatically fall back to this
                      approximate Hessian. If it is not provided either, a
                      standard finite-difference approximation of the Hessian
                      based on the gradient is built-in.</p>
                    <p>See <a style="font-family: monospace;" href="reference/manopt/solvers/hessianapproximations/index.html">/solvers/hessianapproximations</a>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>precon</code> </td>
                  <td><code>v = precon(x, u)</code><br>
                    <nobr><code>[v, store] = precon(x, u, store)</code></nobr><br>
                    <nobr><code>v = precon(x, u, storedb, key)</code></nobr> </td>
                  <td>
                    <p>$v = \operatorname{Prec}(x)[u]$, where
                      $\operatorname{Prec}(x)$ is a preconditioner for the
                      Hessian $\operatorname{Hess} f(x)$, that is,
                      $\operatorname{Prec}(x)$ is a symmetric, positive-definite
                      linear operator (w.r.t. the Riemannian metric) on the
                      tangent space at $x$. Ideally, it is cheap to compute and
                      such that solving a linear system in
                      $\operatorname{Prec}^{1/2}(x) \circ \operatorname{Hess}
                      f(x) \circ \operatorname{Prec}^{1/2}(x)$ is easier than
                      without the preconditioner, i.e., it should approximate
                      the inverse of the Hessian.</p>
                    <p>See <a style="font-family: monospace;" href="reference/manopt/solvers/preconditioners/index.html">/solvers/preconditioners</a>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>sqrtprecon</code> </td>
                  <td><code>v = sqrtprecon(x, u)</code><br>
                    <nobr><code>[v, store] = sqrtprecon(x, u, store)</code></nobr><br>
                    <nobr><code>v = sqrtprecon(x, u, storedb, key)</code></nobr>
                  </td>
                  <td>$v = \operatorname{Prec}^{1/2}(x)[u]$, where
                    $\operatorname{Prec}^{1/2}(x)$ is an (operator) square root
                    of a preconditioner for the Hessian $\operatorname{Hess}
                    f(x)$, that is, $\operatorname{Prec}^{1/2}(x)$ is a
                    symmetric, positive-definite linear operator (w.r.t. the
                    Riemannian metric) on the tangent space at $x$, and applying
                    it twice should amount to applying $\operatorname{Prec}(x)$
                    once. Solvers typically use <code>precon</code> rather than
                    <code>sqrtprecon</code>, but some tools (such as <a style="font-family: monospace;"
                      href="reference/manopt/tools/hessianspectrum.html">hessianspectrum</a>)
                    can use <code>sqrtprecon</code> to speed up computations.</td>
                </tr>
                <tr>
                  <td><code>linesearch</code><a id="linesearchproblem"> </a></td>
                  <td><code>t = linesearch(x, u)</code><br>
                    <code>[t, store] = linesearch(x, u, store)</code><br>
                    <code>t = linesearch(x, u, storedb, key)</code></td>
                  <td>
                    <p>Given a point $x$ and a tangent vector $u$ at $x$, assume
                      $u$ is a descent direction. This means there exists $t
                      &gt; 0$ such that $\phi(t) &lt; \phi(0)$ with<br>
                      $$\phi(t) = f(\operatorname{Retr}_x(td)).$$<br>
                      Line-search algorithms, which are used by some solvers
                      such as <code>steepestdescent</code> and <code>conjugategradient</code>,
                      are designed to (approximately) minimize $\phi$ at each
                      iteration.</p>
                    <p>There are built-in, generic ways of doing this. If you
                      have additional structure in your problem that enables you
                      to take a good guess at what $t$ should be, than you can
                      specify it here, in this function handle. This (very much
                      optional) function should return a positive $t &gt; 0$
                      such that $t$ is a good guess of where to look for a
                      minimizer of $\phi$. The line-search algorithm (if it
                      decides to use this information) will start by looking at
                      the step $td$, and decide to accept it or not based on its
                      internal rules. See the <code>linesearch</code> <a href="#linesearchoptions">option
                        in the solver section</a> (options table) for details on
                      available line-search algorithms and how to pick one.<br>
                      <br>
                      See <span style="font-family: monospace;"><a href="reference/examples/low_rank_matrix_completion.html">low_rank_matrix_completion</a></span>
                      for an example from the literature.</p>
                  </td>
                </tr>
              </tbody>
            </table>
            <p> Here is one way to address the redundant computation of $Ax$
              that appeared in the <a href="file:///C:/Users/nicolas/manopt/web/tutorial.html#firstexample">first
                example</a>. Replace the cost and gradient description (code
              lines 11-12) with the following code (we chose to spell out the
              gradient projection, but that is not necessary):</p>
            <pre class="prettyprint lang-matlab linenums">problem.costgrad = @(x) mycostgrad(A, x);
function [f, g] = mycostgrad(A, x)
    Ax = A*x;
    f = -x'*Ax;
    if nargout == 2
        g = -2*(Ax + f*x);
    end
end
</pre>
            <p>Solvers that call subsequently for the cost and the gradient at
              the same point will be able to escape most redundant computations
              (e.g., <code>steepestdescent</code> and <code>conjugategradient</code>
              are good at this). This is not perfect though: when the Hessian is
              requested for example, we can't access our hard work (<code>trustregions</code>
              would not gain much for example). In the next section, we cover a
              more sophisticated way of sharing data between components of the
              cost description. </p>
            <h3><a id="cachingsystem" name="cachingsystem"></a>Caching: how to
              use the store structure </h3>
            <p>As demonstrated in the <a href="#firstexample">first example</a>,
              it is often the case that computing $f(x)$ produces intermediate
              results (such as the product $Ax$) that can be reused in order to
              compute $\operatorname{grad} f(x)$. More generally, computing
              anything at a point $x$ may produce intermediate results that
              could be reused for other computations at $x$. Furthermore, it may
              happen that a solver will call cost-related functions more than
              once at the same point $x$. For those cases, it may be beneficial
              to cache (to store) some of the previously computed objects, or
              intermediate calculations.</p>
            <p>For that purpose, Manopt manages a database of <code>store</code>
              structures, with a class called <a href="reference/manopt/core/StoreDB.html"><span
                  style="font-family: monospace;">StoreDB</span></a>. For each
              visited point $x$, a <code>store</code> structure is stored in
              the database. Only the structures pertaining to the most recently
              used points are kept in memory (see the <code>options.storedepth</code>
              <a href="#solvers">option</a>). StoreDB manages a counter, to
              number visited points on the manifold. In principle, each point
              $x$ receives a <code>key</code>. This key can be used to interact
              with the store associated to $x$.</p>
            <p>Whenever a solver calls, say, the <code>cost</code> function at
              some point $x$, the toolbox will search for a <code>store</code>
              structure pertaining to that $x$ in the database. If there is one
              and if the <code>cost</code> function admits <code>store</code>
              as an input and as an output, the <code>store</code> is passed to
              the <code>cost</code> function. The <code>cost</code> function
              then performs its duty and gets to modify the <code>store</code>
              structure at will: it is <em>your </em>structure, do whatever
              you fancy with it. Next time a function is called at the <em>same</em>
              point $x$ (say, the <code>grad</code> function), the <em>same</em>
              <code>store</code> structure will be passed along, modified, and
              stored again. As soon as the solver goes on to explore a new point
              $x'$, a <em>different</em> <code>store</code> structure is
              created and maintained in the same way. If the solver then decides
              to return to the previous $x$ and <code>options.storedepth</code>
              is larger than 2, we will still benefit from the previously stored
              work as the previous <code>store</code> structure will still be
              available.</p>
            <p>As of Manopt 1.0.8, the store structure also includes a field at
              <code>store.shared</code>. The contents of that field are shared
              among all visited points $x$. This makes a number of things
              possible that were not manageable before. One particular
              application is to use the shared memory to count certain
              operations (for example, to count how many times a certain matrix
              is applied to vectors, across all points and across all
              cost/grad/hess/precon/... capacities). Note that this memory is
              also readable from <code>statsfun</code> (see <a href="#statsfunhelp">statsfun
                documentation</a> and the <a href="reference/examples/maxcut.html">maxcut
                example</a>).</p>
            <p>When given access to <code>storedb</code> and a <code>key</code>
              associated to $x$ rather than to a specific store, the store of
              $x$ can be obtained as <code>store = storedb.getStore(key)</code>.
              Put the modified store back in the database with <code>storedb.set(store,
                key)</code>. Access the shared memory directly as <code>storedb.shared</code>,
              <em>not </em>via <code>store.shared</code>. This is important: <code>store</code>
              might have a <code>store.shared</code> field, but when <code>storedb</code>
              and <code>key</code> are explicitly used, <code>store.shared</code>
              will not be populated or read on get/set. Each point $x$ should be
              associated to a key, which is obtained by calling <code>storedb.getNewKey()</code>.
              From time to time, call <code>storedb.purge()</code> to reduce
              memory usage.</p>
            <div class="alert alert-info"><strong>Heads up!</strong> StoreDB is
              a <a target="_blank" href="http://fr.mathworks.com/help/matlab/matlab_oop/comparing-handle-and-value-classes.html">handle
                class</a>, which means its instances are passed by reference.
              This means when a storedb object is passed as input to a function,
              and that function modifies the storedb object, the calling
              function will see the changes too (without need to explicitly
              return the storedb object). Thus, each storedb object exists only
              <em>once</em> in memory. This makes for cleaner calling patterns
              and avoids unnecessary copies.</div>
            <p>Here is an example of how we can modify the <a href="#firstexample">first
                example</a> to avoid redundant computations, using the caching
              mechanism:</p>
            <pre class="prettyprint lang-matlab linenums">problem.cost = @mycost;
function [f, store] = mycost(x, store)

    if ~isfield(store, 'Ax')
        store.Ax = A*x;       % The store memory is associated to a specific x
    end
    Ax = store.Ax;
    
    if ~isfield(store, 'f')
        store.f = -x'*Ax;
    end
    f = store.f;
    
end

problem.grad = @mygrad;
function [g, store] = mygrad(x, store)

    % This could be placed in a separate function
    % to avoid code duplication.
    if ~isfield(store, 'Ax')
        [~, store] = mycost(x, store);
    end
    Ax = store.Ax;
    
    if ~isfield(store, 'g')
        store.g = manifold.egrad2rgrad(x, -2*Ax);
    end
    g = store.g;
    
end
</pre>
            <p>It is instructive to execute such code with <a target="_blank" href="http://blogs.mathworks.com/community/2010/02/01/speeding-up-your-program-through-profiling/">the
                profiler</a> activated and to look at how many times each
              instruction gets executed. You should find that line 5 in the
              code, which is where all the work happens, is executed exactly as
              often as it should be, and not more.</p>
            <div class="alert alert-info"><strong>Heads up!</strong> You should
              never assume that the gradient function, for example, will be
              called <em>after</em> the cost function (even though this is
              usually the case). Always check that the fields you will use in
              the <code>store</code> structure are populated; and if they are
              not, call the appropriate functions to make up for it, as in the
              example above. </div>
            <div class="alert alert-info"><strong>Good to know!</strong> Which
              variables should I store? As a rule of thumb, store the
              intermediate computation results which constitute the bottleneck
              in your computation. This can usually be determined by considering
              the asymptotic time complexity of each operation. Typically,
              matrix products of large size are involved in the slowest parts.
              When in doubt, the Matlab profiler is a tremendous tool to
              identify the code bits that need special attention.</div>
            <h3><a id="hessianapproxprecons" name="hessianapproxprecons"></a>Generic
              Hessian approximations and preconditioners</h3>
            If the Hessian is complicated or costly to compute, it may be
            advantageous to resort to an approximation for it. Likewise, if the
            Hessian is poorly conditioned, it may be advantageous to provide a
            preconditioner for it (a cheap, approximate and positive definite
            inverse of the Hessian). Manopt allows for the definition of generic
            Hessian approximations and generic preconditioners. The feature is
            working, but as this is work in progress we do not have many options
            to show yet. Check out these folders if you are interested:
            <ul>
              <li><a style="font-family: monospace;" href="reference/manopt/solvers/hessianapproximations/index.html">/solvers/hessianapproximations</a>.</li>
              <li><a style="font-family: monospace;" href="reference/manopt/solvers/preconditioners/index.html">/solvers/preconditioners</a>.</li>
            </ul>
          </section>
          <section id="tools">
            <div class="page-header">
              <h1>Helpful tools</h1>
            </div>
            <p>A number of generically useful tools in the context of using
              Manopt are available in <a href="reference/manopt/tools/index.html">/<tt>manopt/tools</tt></a>.
              The <code>multitransp</code> / <code>multiprod</code> pair is
              code by <a target="_blank" href="http://www.mathworks.com/matlabcentral/fileexchange/8773-multiple-matrix-multiplications-with-array-expansion-enabled">Paolo
                de Leva</a> ; <code>multitrace</code> is a wrapper around <code>diagsum</code>,
              which is code by <a target="_blank" href="http://www.mathworks.com/matlabcentral/fileexchange/10062-multi-dimensional-matrix-product-outer-product-and-partial-trace">Wynton
                Moore</a>. </p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td style="text-align: center;"> </td>
                <td>Call </td>
                <td>Description </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align: center;"> </td>
              <td colspan="2" rowspan="1"><strong>Diagnostics tools</strong> </td>
            </tr>
            <tr>
              <td style="text-align: center;"><a href="reference/manopt/tools/checkdiff.html"><i
                    class="icon-book">&#160;</i></a></td>
              <td><nobr><code>checkdiff(problem, x, u)</code></nobr> </td>
              <td>Numerical check of the directional derivatives of the cost
                function. From a truncated Taylor expansion, we know that the
                following holds: $$f(\operatorname{Exp}_x(tu)) - \left[f(x) +
                t\cdot\operatorname{D}\!f(x)[u]\right] = \mathcal{O}(t^2).$$
                Hence, in a log-log plot with $\log(t)$ on the abscissa, the
                error should behave as $\log(t^2) = 2\log(t)$, i.e., we should
                observe a slope of 2. This tool produces such a plot and tries
                to compute the slope of it (<em>tries</em> to, because numerical
                errors prevent the curve to have a slope of 2 everywhere even if
                directional derivatives are correct; so you should really just
                inspect the plot visually). If <code>x</code> and <code>u</code>
                are omitted, they are picked at random. </td>
            </tr>
            <tr>
              <td style="text-align: center;"><a href="reference/manopt/tools/checkgradient.html"><i
                    class="icon-book">&#160;</i></a></td>
              <td><nobr><code>checkgradient(problem, x, u)</code></nobr> </td>
              <td>Numerical check of the gradient of the cost function. Based on
                the statement that if the gradient exists, than it is the only
                tangent vector field that satisfies $$\langle
                \operatorname{grad} f(x), u\rangle_x =
                \operatorname{D}\!f(x)[u],$$ this tool calls <code>checkdiff</code>
                first, and it also verifies that the gradient is indeed a
                tangent vector, by computing the norm of the difference between
                the gradient and its projection to the tangent space (if a
                projector is available). Of course, this should be zero. </td>
            </tr>
            <tr>
              <td style="text-align: center;"><a href="reference/manopt/tools/checkhessian.html"><i
                    class="icon-book">&#160;</i></a></td>
              <td><nobr><code>checkhessian(problem, x, u)</code></nobr> </td>
              <td>
                <p>Numerical check of the Hessian of the cost function. From a
                  truncated Taylor expansion, we know that the following holds:
                  $$f(\operatorname{Exp}_x(tu)) - \left[f(x) +
                  t\cdot\operatorname{D}\!f(x)[u] + \frac{t^2}{2} \cdot \langle
                  \operatorname{Hess} f(x)[u], u \rangle_x\right] =
                  \mathcal{O}(t^3).$$ Hence, in a log-log plot with $\log(t)$ on
                  the abscissa, the error should behave as $\log(t^3) =
                  3\log(t)$, i.e., we should observe a slope of 3. This tool
                  produces such a plot and tries to compute the slope of it (<em>tries</em>
                  to, because numerical errors prevent the curve to have a slope
                  of 3 everywhere even if the derivatives are correct; so you
                  should really just inspect the plot visually). If <code>x</code>
                  and <code>u</code> are omitted, they are picked at random.
                  The tool also verifies that the Hessian indeed returns a
                  tangent vector, by computing the norm of the difference
                  between $\operatorname{Hess} f(x)[u]$ and its projection to
                  the tangent space (if a projector is available). Of course,
                  this should be zero.</p>
                <p>The Hessian is a linear, symmetric operator from the tangent
                  space at $x$ to itself. To verify symmetry, this tool
                  generates two random tangent vectors $u_1$ and $u_2$ and
                  computes the difference $$\langle \operatorname{Hess}
                  f(x)[u_1], u_2 \rangle_x - \langle u_1,&#160;
                  \operatorname{Hess} f(x)[u_2]\rangle_x,$$ which should be
                  zero.</p>
              </td>
            </tr>
            <tr>
              <td style="text-align: center;"><a href="reference/manopt/tools/plotprofile.html"><i
                    class="icon-book">&#160;</i></a></td>
              <td><code>plotprofile(problem, x, d, t)</code></td>
              <td>Plots the cost function along a geodesic or a retraction path
                starting at $x$, along direction $d$. See <span style="font-family: monospace;">help
                  plotprofile</span> for more information.</td>
            </tr>
            <tr>
              <td style="text-align: center;"><a href="reference/manopt/tools/surfprofile.html"><i
                    class="icon-book">&#160;</i></a></td>
              <td><code>surfprofile(problem, x, d1, d2, t1, t2)</code></td>
              <td>Plots the cost function, lifted and restricted to a
                2-dimensional subspace of the tangent space at $x$. See <span style="font-family: monospace;">help
                  surfprofile</span> for more information.</td>
            </tr>
            <tr>
              <td style="text-align: center;"> </td>
            <td colspan="2" rowspan="1"><strong>Cost analysis</strong></td>
          </tr>
          <tr>
            <td style="text-align: center;"><a href="reference/manopt/tools/hessianspectrum.html"><i
                  class="icon-book">&#160;</i></a></td>
            <td><code>lambdas = hessianspectrum(problem, x, useprecon, storedb,
                key)</code></td>
            <td>
              <p>Computes the eigenvalues of the Hessian $H$ at $x$. If a
                preconditioner $P$ is specified in the problem structure and <code>useprecon</code>
                is set to <code>'precon'</code>, the eigenvalues of the
                preconditioned Hessian $HP$ are computed.</p>
              <p>This function relies on <code>problem.M.vec</code> and <code>problem.M.mat</code>
                to pass the computation to the built-in <code>eigs</code>
                function. For the eigenvalue problem to remain symmetric in the
                column-vector representation domain, we need <code>M.vec</code>
                and <code>M.mat</code> to be orthonormal, i.e., isometries (see
                <code>matvecareisometries</code> in the <a href="#manifolds">manifod
                  section</a>). If they are not isometries, computations may
                take longer. Indeed, let $G$ denote the <code>M.vec</code>
                operator and let $G^{-1}$ represent the <code>M.mat</code>
                operator (on the appropriate domain). Then, <code>eigs</code>
                will compute the spectrum of $GHG^{-1}$ or $GHPG^{-1}$, which
                are identical to, respectively, the spectra of $H$ and $HP$.
                This is only symmetric if there is no preconditioner and $G^T =
                G^{-1}$.</p>
              <p>If a preconditioner is used, the symmetry of the eigenvalue
                problem is lost: $H$ and $P$ are symmetric, but $HP$ is not. If
                <code>M.vec</code> and <code>M.mat</code> are isometries and
                the dimension of the manifold is large, it may be useful to
                restore symmetry by giving this tool a function handle for the
                square root of the preconditioner, $P^{1/2}$ (optional). Then, <code>eigs</code>
                is given the problem of computing the spectrum of
                $GP^{1/2}HP^{1/2}G^T$ (symmetric), which is equal to the
                spectrum of $HP$. Typically, the square root of the
                preconditioner is given via <code>problem.sqrtprecon</code>
                (see <a href="#costdescription">cost description</a>).</p>
              <p><code>storedb</code> and <code>key</code> are optional (see <a
                  href="#cachingsystem">caching system</a>).</p>
            </td>
          </tr>
          <tr>
            <td style="text-align: center;"><a href="reference/manopt/tools/hessianextreme.html"><i
                  class="icon-book">&#160;</i></a></td>
            <td><code>[u, lambda] = hessianextreme(problem, x, side, u0,
                options, storedb, key)</code></td>
            <td>
              <p>Computes either an eigenvector / eigenvalue pair associated to
                a largest or to a smallest eigenvalue of the Hessian of the cost
                at <code>x</code>, for the cost as described in the <code>problem</code>
                structure. Choose an extreme side of the spectrum by setting <code>side</code>
                either to the <code>'min'</code> or to the <code>'max'</code>
                string. The (optional) parameters <code>u0</code> (initial
                guess for <code>u</code>) and <code>options</code> will be
                passed on to <code>manoptsolve</code>, then on to the Manopt
                solver that ultimately computes the eigenpair, by means of
                Rayleigh quotient optimization over the sphere in the tangent
                space at <code>x</code>.</p>
              <p><code>storedb</code> and <code>key</code> are optional (see <a
                  href="#cachingsystem">caching system</a>).</p>
            </td>
          </tr>
          <tr>
            <td style="text-align: center;"> </td>
          <td colspan="2" rowspan="1"><strong>Matrix utilities</strong> </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multiscale.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><nobr><code>B = multiscale(scale, A)</code></nobr> </td>
          <td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt> and a
            vector <code>scale</code> of length <tt>N</tt>, returns <code>B</code>,
            a 3D matrix of the same size as <code>A</code> such that <nobr><code>B(:,
                :, k) = scale(k) * A(:, :, k)</code></nobr> for each <code>k</code>.
          </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multitrace.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><nobr><code>tr = multitrace(A)</code></nobr> </td>
          <td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>, returns a
            column vector <code>tr</code> of length <tt>N</tt> such that <nobr><code>tr(k)
                = trace(A(:, :, k))</code></nobr> for each <code>k</code>. </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multisqnorm.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><nobr><code>sq = multisqnorm(A)</code></nobr> </td>
          <td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt>, returns a
            column vector <code>sq</code> of length <tt>N</tt> such that <nobr><code>sq(k)
                = norm(A(:, :, k), 'fro')^2</code></nobr> for each <code>k</code>.
          </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multitransp.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><nobr><code>B = multitransp(A)</code></nobr> </td>
          <td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt>, returns <code>B</code>,
            a 3D matrix of size <tt>mxnxN</tt> such that <nobr><code>B(:, :,
                k) = A(:, :, k).'</code></nobr> for each <code>k</code>. </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multihconj.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><nobr><code>B = multihconj(A)</code></nobr> </td>
          <td>For a complex 3D matrix <code>A</code> of size <tt>nxmxN</tt>,
            returns <code>B</code>, a complex 3D matrix of size <tt>mxnxN</tt>
            such that <nobr><code>B(:, :, k) = A(:, :, k)'</code></nobr> for
            each <code>k</code>. </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multiprod.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><nobr><code>C = multiprod(A, B)</code></nobr> </td>
          <td>For 3D matrices <code>A</code> of size <tt>nxpxN</tt> and B of
            size <tt>pxmxN</tt>, returns <code>C</code>, a 3D matrix of size <tt>nxmxN</tt>
            such that <nobr><code>C(:, :, k) = A(:, :, k) * B(:, :, k)</code></nobr>
            for each <code>k</code>. </td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multiskew.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><code>B = multiskew(A)</code></td>
          <td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>, returns a
            3D matrix <code>B</code> the same size as <code>A</code> such that
            each slice <code>B(:, :, i)</code> is the skew-symmetric part of
            the slice <code>A(:, :, i)</code>, that is, <code>(A(:, :, i)-A(:,
              :, i)')/2</code>.</td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multisym.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><code>B = multisym(A)</code></td>
          <td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>, returns a
            3D matrix <code>B</code> the same size as <code>A</code> such that
            each slice <code>B(:, :, i)</code> is the symmetric part of the
            slice <code>A(:, :, i)</code>, that is, <code>(A(:, :, i)+A(:, :,
              i).')/2</code>.</td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/multiherm.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><code>B = multiherm(A)</code></td>
          <td>For a complex 3D matrix <code>A</code> of size <tt>nxnxN</tt>,
            returns a complex 3D matrix <code>B</code> the same size as <code>A</code>
            such that each slice <code>B(:, :, i)</code> is the Hermitian part
            of the slice <code>A(:, :, i)</code>, that is, <code>(A(:, :,
              i)+A(:, :, i)')/2</code>.</td>
        </tr>
        <tr>
          <td style="text-align: center;"><a href="reference/manopt/tools/dfunm.html"><i
                class="icon-book">&#160;</i></a></td>
          <td><code>dfunm</code>, <code>dlogm</code>, <code>dexpm</code>, <code>dsqrtm</code></td>
          <td>Fr&#233;chet derivatives of the (built-in) matrix functions <code>logm</code>,
            <code>expm</code> and <code>sqrtm</code>.</td>
        </tr>
        <tr>
          <td style="text-align: center;"> </td>
        <td colspan="2" rowspan="1"><strong>Manifold utilities</strong> </td>
      </tr>
      <tr>
        <td style="text-align: center;"><a href="reference/manopt/tools/powermanifold.html"><i
              class="icon-book">&#160;</i></a></td>
        <td><nobr><code>Mn = powermanifold(M, n)</code></nobr> </td>
        <td>Given <code>M</code>, a structure representing a manifold
          $\mathcal{M}$, and <code>n</code>, an integer, returns <code>Mn</code>,
          a structure representing the manifold $\mathcal{M}^n$. The geometry is
          obtained by element-wise extension. Points and vectors on <code>Mn</code>
          are represented as cells of length <code>n</code>. </td>
      </tr>
      <tr>
        <td style="text-align: center;"><a href="reference/manopt/tools/productmanifold.html"><i
              class="icon-book">&#160;</i></a></td>
        <td><nobr><code>M = productmanifold(elements)</code></nobr> </td>
        <td>Given <code>elements</code>, a structure with fields <code>A, B,
            C...</code> containing structures <code>Ma, Mb, Mc...</code> such
          that <code>Ma</code> is a structure representing a manifold
          $\mathcal{M}_A$ etc., returns <code>M</code>, a structure
          representing the manifold $\mathcal{M}_A \times \mathcal{M}_B \times
          \mathcal{M}_C \times \cdots$. The geometry is obtained by element-wise
          extension. Points and vectors are represented as structures with the
          same field names as <code>elements</code>. </td>
      </tr>
      <tr>
        <td style="text-align: center;"><a href="reference/manopt/tools/tangentspherefactory.html"><i
              class="icon-book">&#160;</i></a></td>
        <td><code>N = tangentspherefactory(M, x)</code></td>
        <td>Given a manifold structure <code>M</code> and a point on that
          manifold <code>x</code>, returns a manifold structure <code>N</code>
          representing the unit sphere on the tangent space to <code>M</code>
          at <code>x</code>. This is notably used by the <a href="reference/manopt/tools/hessianextreme.html"><span
              style="font-family: monospace;">hessianextreme</span></a> tool.</td>
      </tr>
      <tr>
        <td style="text-align: center;"><a href="reference/manopt/tools/tangentspacefactory.html"><i
              class="icon-book">&#160;</i></a></td>
        <td><code>N = tangentspacefactory(M, x)</code></td>
        <td>Given a manifold structure <code>M</code> and a point on that
          manifold <code>x</code>, returns a manifold structure <code>N</code>
          representing the tangent space to <code>M</code> at <code>x</code>.
          This is notably used by the <a style="font-family: monospace;" href="reference/manopt/solvers/preconditioners/preconhessiansolve.html">preconhessiansolve</a>
          preconditioner.</td>
      </tr>
      <tr>
        <td style="text-align: center;"> </td>
      <td colspan="2" rowspan="1"><strong>Solver utilities</strong></td>
    </tr>
    <tr>
      <td style="text-align: center;"><a href="reference/manopt/tools/manoptsolve.html"><i
            class="icon-book">&#160;</i></a></td>
      <td><code>[x, cost, info, options] = manoptsolve(problem, x0, options)</code></td>
      <td>Gateway function to call a Manopt solver. You may specify which solver
        to call by setting <code>options.solver</code> to a function handle
        corresponding to a solver. Otherwise, a solver will be picked
        automatically. This is mainly useful when programming meta algorithms
        which need to solve a Manopt problem at some point, but one wants to
        leave the decision of which solver to use up to the final user.</td>
    </tr>
    <tr>
      <td style="text-align: center;"><a href="reference/manopt/tools/statsfunhelper.html"><i
            class="icon-book">&#160;</i></a></td>
      <td><code>statsfun = statsfunhelper(name, fun)</code><br>
        <code>statsfun = statsfunhelper(S)</code></td>
      <td>Helper function to place a function handle in the field <code>options.statsfun</code>.
        See the help about the statsfun option <a href="#statsfunhelp">earlier
          in this tutorial</a>, and/or the help for <a style="font-family: monospace;"
          href="reference/manopt/tools/statsfunhelper.html">statsfunhelper</a>
        from the command line.</td>
    </tr>
  </tbody>
</table>
<div class="alert alert-info"><strong>Heads up!</strong> When using the <code>checkhessian</code>
  tool, it is important to obtain <em>both</em> a slope of 3 <em>and</em> to
  pass the symmetry test. Indeed, the slope test ignores the skew-symmetric part
  of the Hessian, since $x^T A x = x^T \frac{A+A^T}{2} x$. As a result, if your
  code for the Hessian has a spurious skew-symmetric part, the slope test will
  be oblivious to it. </div>
</section>
<section id="core">
  <div class="page-header">
    <h1>Core tools (internals)</h1>
  </div>
  <p>Internally, Manopt uses a number of tools to manipulate problem structures,
    solvers and manifolds. These tools are listed here. One central tool was
    already documented in the <a href="#cachingsystem">caching system
      description</a>: the <a href="reference/manopt/core/StoreDB.html">StoreDB
      class</a>. Because the toolbox targets flexibility in the problem
    description, the cost, gradient, Hessian etc. can be specified in a number
    of different ways in a problem structure. Thus, to evaluate cost-related
    quantities, it is best to use the functions below, rather than to
    immediately use (for example) <code>problem.cost</code>. Use <a href="reference/manopt/core/getCost.html">getCost</a>
    instead.</p>
  <p>These tools are specifically useful for solver developers.</p>
  <p>The inputs <code>storedb</code> and <code>key</code> are usually
    optional. It is a good idea to pass them if they are available, as this
    allows for caching to be used.</p>
  <table style="width: 100%;" class="table table-striped table-bordered">
    <thead>
      <tr>
        <td style="text-align: center;"> </td>
      <td>Call </td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center;"> </td>
    <td colspan="1" rowspan="1"><strong>Cost evaluations (and cost-related
        quantities)</strong> </td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getCost.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>cost = getCost(problem, x, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getCostGrad.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>[cost, grad] = getCostGrad(problem, x, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getGradient.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>grad = getGradient(problem, x, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getEuclideanGradient.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>egrad = getEuclideanGradient(problem, x, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getDirectionalDerivative.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>diff = getDirectionalDerivative(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getHessian.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>hess = getHessian(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getHessianFD.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>hessfd = getHessianFD(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getApproxHessian.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>approxhess = getApproxHessian(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getLinesearch.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>t = getLinesearch(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getPrecon.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>Pd = getPrecon(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"><a href="reference/manopt/core/getSqrtPrecon.html"><i
          class="icon-book">&#160;</i></a></td>
    <td><code>sqrtPd = getSqrtPrecon(problem, x, d, storedb, key)</code></td>
  </tr>
  <tr>
    <td style="text-align: center;"> </td>
  <td colspan="1" rowspan="1"><strong>Cost-related availability checks (checks
      whether the user explicitly specified these)</strong></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetCost.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetCost(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetDirectionalDerivative.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetDirectionalDerivative(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetGradient.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetGradient(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetEuclideanGradient.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetEuclideanGradient(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetHessian.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetHessian(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetApproxHessian.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetApproxHessian(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetPrecon.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetPrecon(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetSqrtPrecon.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetSqrtPrecon(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/canGetLinesearch.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>candoit = canGetLinesearch(problem)</code></td>
</tr>
<tr>
  <td style="text-align: center;"></td>
<td colspan="1" rowspan="1"><strong>Solver helpers</strong></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/applyStatsfun.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>stats = applyStatsfun(problem, x, storedb, key, options, stats)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/stoppingcriterion.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>[stop, reason] = stoppingcriterion(problem, x, options, info, last)</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/getGlobalDefaults.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>opts = getGlobalDefaults()</code></td>
</tr>
<tr>
  <td style="text-align: center;"><a href="reference/manopt/core/mergeOptions.html"><i
        class="icon-book">&#160;</i></a></td>
  <td><code>opts = mergeOptions(opts1, opts2)</code></td>
</tr>
</tbody>
</table>
</section>
<section id="reference">
  <div class="page-header">
    <h1>Reference</h1>
  </div>
  <p><a target="_blank" href="reference/index.html">A reference is available
      here</a>, to help navigate the source code of the toolbox. It was
    generated with <a target="_blank" href="http://www.artefact.tk/software/matlab/m2html/">m2html</a>.
  </p>
</section>
</div>
</div>
</div>
<!-- /container --><!-- Le javascript ================================================== --><!-- Placed at the end of the document so the pages load faster -->
<script type="text/javascript" src="bootstrap/js/jquery.min.js"></script>
<script type="text/javascript" src="bootstrap/js/bootstrap.js"></script>
<script type="text/javascript" src="bootstrap/js/prettify.js"></script>
<script type="text/javascript" src="bootstrap/js/lang-matlab.js"></script>
<!--
    <script type="text/javascript" src="http://mathcache.s3.amazonaws.com/replacemath.js"> </script>    <script type="text/javascript">replaceMath( document.body ); </script>    -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-37402854-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</body>
</html>
